<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Multilevel Models | Adam Haber</title>
    <link>https://adamhaber.github.io/tags/multilevel-models/</link>
      <atom:link href="https://adamhaber.github.io/tags/multilevel-models/index.xml" rel="self" type="application/rss+xml" />
    <description>Multilevel Models</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 18 Nov 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://adamhaber.github.io/img/icon-192.png</url>
      <title>Multilevel Models</title>
      <link>https://adamhaber.github.io/tags/multilevel-models/</link>
    </image>
    
    <item>
      <title>Mr. P meets TFP - mixed effects model with post-stratification in TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/mrp/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/mrp/</guid>
      <description>&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ll:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learn an interesting method for generalizing inferences from a biased sample to a population of interest&lt;/li&gt;
&lt;li&gt;See why prior predictive checks are great&lt;/li&gt;
&lt;li&gt;Implement a simple mixed-effects model in TFP&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;p&gt;This post is a TFP port of Lauren Kennedy and Jonah Gabry&amp;rsquo;s excellent &lt;a href=&#34;http://mc-stan.org/rstanarm/articles/mrp.html&#34;&gt;MRP with rstanarm&lt;/a&gt; vignette. It describes a very interesting statistical method for generalizing inferences from a biased sample to a population of interest. The method is called multilevel regression with poststratification, or MRP if you prefer acronyms, or Mister P if you prefer statisticians jokes. Along the way, we&amp;rsquo;ll see why prior predictive checks are so nice and important, how to implement a mixed-effect model in TFP, and how to make predictions for smaller sub-populations.&lt;/p&gt;
&lt;p&gt;I chose to port the vignette because the problem MRP address - generalizing from a biased sample to a population - is so prevalent and important, that knowing what are the possible tools to handle it seemed valuable. I found that porting models from one language to another is an excellent way to learn the model, the problem, and the languages themselves, so it&amp;rsquo;s kind of a win-win-win and publishing it might also help others so why not.&lt;/p&gt;
&lt;p&gt;I strongly recommend reading the original vignette; the people who wrote it are much more knowledgeable than I am about this subject, and I also chose to focus on slightly different things so they&amp;rsquo;re not 100% overlapping. At the end of this post you can find links for further reading.&lt;/p&gt;
&lt;h3 id=&#34;imports-and-helper-functions---data-generation&#34;&gt;Imports and helper functions - data generation&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; collections &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; namedtuple
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; itertools &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; it
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.special &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; expit &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; inv_logit
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sem
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;98&lt;/span&gt;)

sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_palette(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;muted&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;legend.fontsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;figure.figsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: (&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;),
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;axes.labelsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;axes.titlesize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;xtick.labelsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ytick.labelsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;
}
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rcParams&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;update(params)
&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;config InlineBackend&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure_format &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;retina&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;the-data&#34;&gt;The data&lt;/h1&gt;
&lt;p&gt;The data we&amp;rsquo;ll work with is simulated data; this has the obvious advantage that we know the ground truth so we&amp;rsquo;ll be able to assess just how well our method generalizes to the population. The data describes the proportion of the population who would choose to adopt a cat over a dog, given the opportunity. Our outcome variable in this example is binary (cat/dog), but MRP is not restricted to such outcomes and can be used for discrete outcomes with more than two values, as well as continuous outcomes.&lt;/p&gt;
&lt;p&gt;These are the variables we&amp;rsquo;ll be working with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;)
income &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;They&amp;rsquo;re all categorical; we use zero-based indexing to enumerate them (instead of calling them &amp;lsquo;Male&amp;rsquo;, &amp;lsquo;Female&amp;rsquo; etc) because it&amp;rsquo;ll make all the indexing gymnastics in the actual implementation somewhat simpler.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;poststrat&lt;/code&gt; is a dataframe containing all $2\times3\times7\times3\times50=6300$ possible combinations of these variables:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;poststrat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    list(it&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;product(sex, eth, age, income, state)),
    columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;],
)
poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4675&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1749&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2460&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(6300, 5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below are the different proportions of the different variables &lt;em&gt;in the population&lt;/em&gt;. For example, 20% of the population are in the first age group, 10% are in the second, etc. For each combination of variables we&amp;rsquo;ll compute the number of people that share this specific combination by multiplying the total number of people in the population (assumed to be 250 million) with the different probabilities (this means we&amp;rsquo;re assuming the joint probability distribution factorizes, that is - that the different variables are independent).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;p_age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;])
p_sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.52&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.48&lt;/span&gt;])
p_eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;])
p_income &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.50&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.35&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.15&lt;/span&gt;])
p_state_tmp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(low&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, high&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)
p_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(p_state_tmp &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; p_state_tmp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum())

poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    &lt;span style=&#34;color:#ae81ff&#34;&gt;250e6&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_sex[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_eth[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_age[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_income[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_state[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We also assume that different groups have different probabilities of being included in the sample; in a way, that&amp;rsquo;s the entire point (if all groups had the same probability of being included in the sample then the sample was representative of the population). There&amp;rsquo;s a baseline probability of being in the sample, but it cancels out in the weighted average; what determines who is in our sample is &lt;code&gt;p_response_weighted&lt;/code&gt;, which is &lt;code&gt;p_response&lt;/code&gt; weighted by the number of people in each group:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;p_response_baseline &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;
p_response_sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2.8&lt;/span&gt;
p_response_eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4.7&lt;/span&gt; 
p_response_age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;18.9&lt;/span&gt;
p_response_inc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2.7&lt;/span&gt;
p_response_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;beta(a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, b&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)
p_response_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p_response_state &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; p_response_state&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()

p_response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    p_response_baseline
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_sex[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_eth[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_age[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_inc[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_state[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
)

p_response_weighted &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We now sample 1200 individuals from the entire population. This means we&amp;rsquo;re actually sampling rows from our &lt;code&gt;poststrat&lt;/code&gt; dataframe with different probabilities given by &lt;code&gt;p_response_weighted&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1200&lt;/span&gt;
people &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]), size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n, replace&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;p_response_weighted
)
sample &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[people]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()
sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;index&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;520&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;287&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2626&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;870&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;69&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1517&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;169&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4104&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now we&amp;rsquo;re getting to the thing we&amp;rsquo;ll actually measure in the sample (and then try to generalize to the population) - cat preference. Below are the coefficients of a regression model that determines the log-odds of cat preference, $\log\frac{P(\text{prefers cats})}{P(\text{prefers dogs})}$ for each group in the population. We&amp;rsquo;ll use these coefficients to compute the actual probability of cats preference for each group:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;coef_sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;])
coef_eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;])
coef_age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;])
coef_income &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;])
coef_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;insert(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
coef_age_sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vstack(
    [
        np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.23&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.43&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;]),
        np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.23&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.43&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;]),
    ]
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;true_pop &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inv_logit(
    coef_sex[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_eth[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_age[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_income[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_state[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_age_sex[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
)
true_pop&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cat_pref&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;6124&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.71095&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;177&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.549834&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;5755&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.331812&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2102&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.802184&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3931&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.524979&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We now use the computed probabilities to determine, for each individual in our sample, whether she&amp;rsquo;s a cats person or a dogs person. Note that this is still the fake data generation part; we&amp;rsquo;re not modelling anything yet.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;binomial(n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;][people], size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n)
sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;index&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cat_pref&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;671&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;906&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3062&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Just to get a glimpse of the problem Mr. P is trying to solve, the sample mean is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0.7083333333333334
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While the true mean in the population (which is a weighted sum of the per-group probabilities and the group sizes) is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;true_pop_pref &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sum(true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; sum(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;])
true_pop_pref
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0.5941253009200917
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So our sample overestimates cats-lovin&amp;rsquo; in the population by 18% - people who like cats also like taking surveys.&lt;/p&gt;
&lt;h2 id=&#34;visualizations&#34;&gt;Visualizations&lt;/h2&gt;
&lt;p&gt;To get a better understanding of the problem (unrepresentativeness of the sample), we&amp;rsquo;ll plot some summary statistics and see how they differ:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;f, ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;))

pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    dict(pop&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Series(p_age), sample&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;age&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_index() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; n))
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    dict(pop&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Series(p_eth), sample&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eth&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_index() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; n))
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], legend&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ethnicity&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    dict(
        pop&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Series(p_income), sample&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;income&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_index() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; n)
    )
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], legend&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    dict(pop&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Series(p_sex), sample&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sex&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_index() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; n))
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], legend&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_33_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;At least by eyeballing the charts, the differences seem substantial; for example, if there&amp;rsquo;s a big difference in cats preference between males and females, we expect to see a substantial difference between the cats preference in the sample and in the population.&lt;/p&gt;
&lt;p&gt;We can also plot how cats preference changes between different groups &lt;em&gt;within&lt;/em&gt; our sample - for example, is there a difference in cats preference between different age groups? (yes there is)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;f, axes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), sharey&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; key, ax &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip([&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], axes):
    sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(key)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;agg(dict(mean&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean, std&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sem))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(
        kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;key, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, yerr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;std&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax, legend&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False
    )
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_36_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;the-model&#34;&gt;The model&lt;/h1&gt;
&lt;p&gt;We now turn to the MR part of MRP - the multilevel regression part. More specifically, we&amp;rsquo;ll build a Bayesian multilevel logistic regression model of cats preference. Even more specifically, we&amp;rsquo;ll build what&amp;rsquo;s called a &amp;ldquo;mixed
effects&amp;rdquo; model. Mixed effects models are one of those places that, at least for me, the statisticians terminology is &lt;em&gt;extremely&lt;/em&gt; confusing; it also seems to be inconsistent between different academic fields.  I usually find it easier to look at the actual model specification to understand what&amp;rsquo;s going on:&lt;/p&gt;
&lt;p&gt;For each group $j\in\left[1,&amp;hellip;,6300\right]$ we model the probability of cats preference as&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\theta_j &amp;amp; = logit^{-1}(
\alpha +
X_{j}\beta&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\alpha_{\rm state[j]}^{\rm state}&lt;/li&gt;
&lt;li&gt;\alpha_{\rm age[j]}^{\rm age}&lt;/li&gt;
&lt;li&gt;\alpha_{\rm eth[j]}^{\rm eth}&lt;/li&gt;
&lt;li&gt;\alpha_{\rm inc[j]}^{\rm inc}
) \\\&lt;br&gt;
\alpha_{\rm state[j]}^{\rm state} &amp;amp; \sim N(0,\sigma^{\rm state}) \\\&lt;br&gt;
\alpha_{\rm age[j]}^{\rm age} &amp;amp; \sim N(0,\sigma^{\rm age})\\\&lt;br&gt;
\alpha_{\rm eth[j]}^{\rm eth} &amp;amp; \sim N(0,\sigma^{\rm eth})\\\&lt;br&gt;
\alpha_{\rm inc[j]}^{\rm inc} &amp;amp;\sim N(0,\sigma^{\rm inc}) \\\&lt;br&gt;
\sigma^{\rm state} &amp;amp; \sim {\rm HalfNormal}(1) \\\&lt;br&gt;
\sigma^{\rm age} &amp;amp; \sim {\rm HalfNormal}(1) \\\&lt;br&gt;
\sigma^{\rm eth} &amp;amp; \sim {\rm HalfNormal}(1) \\\&lt;br&gt;
\sigma^{\rm income} &amp;amp; \sim {\rm HalfNormal}(1) \\\&lt;br&gt;
\beta &amp;amp; \sim N(0,2.5) \\\&lt;br&gt;
\alpha &amp;amp; \sim N(0,10) \\\&lt;br&gt;
\end{align}
$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We&amp;rsquo;ve seen expressions like $\alpha_{\rm state[j]}^{\rm state}$ when we&amp;rsquo;ve implemented &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34;&gt;varying intercepts models&lt;/a&gt;. What makes this a &amp;ldquo;mixed effects&amp;rdquo; models is that $\beta$ is the same $\beta$ for all groups, while the different $\alpha^*$-s vary between groups. I&amp;rsquo;m sure there are subtleties and nuances that this doesn&amp;rsquo;t capture, but for me this is a simple-to-read, simple-to-implement explanation of mixed effects models.&lt;/p&gt;
&lt;p&gt;As for the model itself:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$X$ is a (binary) design matrix that holds indicators for sex, age and sex-age interactions - we&amp;rsquo;ll construct it in a second.&lt;/li&gt;
&lt;li&gt;$\alpha$ is an intercept term.&lt;/li&gt;
&lt;li&gt;$\beta$ is a coefficient vector.&lt;/li&gt;
&lt;li&gt;The different $\alpha^*$-s are per-group varying intercepts.&lt;/li&gt;
&lt;li&gt;The different $\sigma^*$-s are hyperpriors for variation between groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The priors on $\alpha,\beta$ are rstanarm&amp;rsquo;s default priors; I couldn&amp;rsquo;t find rstanarm&amp;rsquo;s default prior on the $\sigma^*$ so I chose to use a halfnormal(1) prior.&lt;/p&gt;
&lt;p&gt;Our design matrix $X$ will represent a one-hot-encoded representation of the sampled individuals sex, age, and sex-age interaction term. Here&amp;rsquo;s how it looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;factors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_dummies(sample[[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;category&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(
    [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
)
interactions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    factors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; factors[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values[:, None],
    columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1*age_{i+1}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)],
)
features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([factors, interactions], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_6&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_6&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(1200, 13)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make TF shape issues simpler, we convert it to a numpy array and transpose it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;imports-and-helper-functions---inference&#34;&gt;Imports and helper functions - inference&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfp
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; distributions &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; bijectors &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfb
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; arviz &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; az
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
dtype &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step_size_setter_fn&lt;/span&gt;(pkr, new_step_size):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_replace(
        inner_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_replace(step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;new_step_size)
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;factors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_dummies(sample[[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;category&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(
    [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
)
interactions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    factors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; factors[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values[:, None],
    columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1*age_{i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)],
)
features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([factors, interactions], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trace_fn&lt;/span&gt;(current_samp, pkr):

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;target_log_prob,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;leapfrogs_taken,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;has_divergence,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;energy,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_accept_ratio,
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;(experimental_compile&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;run_nuts&lt;/span&gt;(target_log_prob_fn, initial_states, bijectors_list):
    step_sizes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones_like(i) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; initial_states]
    kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TransformedTransitionKernel(
        tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nuts&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;NoUTurnSampler(target_log_prob_fn, step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;step_sizes),
        bijector&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bijectors_list,
    )

    kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DualAveragingStepSizeAdaptation(
        kernel,
        target_accept_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;dtype),
        num_adaptation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;800&lt;/span&gt;,
        step_size_setter_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;step_size_setter_fn,
        step_size_getter_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; pkr: pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step_size,
        log_accept_prob_getter_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; pkr: pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_accept_ratio,
    )

    &lt;span style=&#34;color:#75715e&#34;&gt;# Sampling from the chain.&lt;/span&gt;
    mcmc_trace, pkr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_chain(
        num_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;,
        num_burnin_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;,
        current_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[
            bijector&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(state)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; bijector, state &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(bijectors_list, initial_states)
        ],
        kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kernel,
        trace_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;trace_fn,
    )

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; mcmc_trace, pkr
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# using pymc3 naming conventions, with log_likelihood instead of lp so that ArviZ can compute loo and waic&lt;/span&gt;
sample_stats_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;log_likelihood&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;tree_size&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;diverging&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;energy&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;mean_tree_accept&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
]


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tfp_trace_to_arviz&lt;/span&gt;(tfp_trace, var_names&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, sample_stats_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sample_stats_name):

    samps, trace &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp_trace
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; var_names &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; None:
        var_names &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;var &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(x) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(samps))]

    sample_stats &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {k: v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k, v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(sample_stats_name, trace)}
    posterior &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
        name: tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(samp, [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name, samp &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(var_names, samps)
    }
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_dict(posterior&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;posterior, sample_stats&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sample_stats)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more details about calling TFP&amp;rsquo;s NUTS sampler, and the helper functions defined above, see &lt;a href=&#34;https://adamhaber.github.io/2019/10/21/Bayesian-golf-puttings,-NUTS,-and-optimizing-your-sampling-function-with-TensorFlow-Probability.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;first-implemetation&#34;&gt;First implemetation&lt;/h2&gt;
&lt;p&gt;We now turn to implement the whole model in TFP. Since there aren&amp;rsquo;t many complicated intermediate calculations, a &lt;code&gt;JointDistributionSequential&lt;/code&gt; is a reasonable choice for implementing the model. For a more detailed explanation on the different &lt;code&gt;JointDistribution&lt;/code&gt; alternatives, see &lt;a href=&#34;https://adamhaber.github.io/2019/10/21/Bayesian-golf-puttings,-NUTS,-and-optimizing-your-sampling-function-with-TensorFlow-Probability.html#model-1&#34;&gt;this post&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_state&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_state: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_state), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_eth&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_eth: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_eth), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_income&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_income: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_income), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_age&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_age: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_age), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# intercept&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# coeffs&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; coeffs, intercept, coef_age, sigma_age, coef_income, sigma_income, coef_eth, sigma_eth, coef_state: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(
            tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Binomial(
                total_count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
                logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;intercept[:, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_age, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                ),
            ),
            reinterpreted_batch_ndims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        ),
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The model description isn&amp;rsquo;t short, but it doesn&amp;rsquo;t contain anything we haven&amp;rsquo;t covered in previous posts. Let&amp;rsquo;s call &lt;code&gt;.sample&lt;/code&gt; and &lt;code&gt;.log_prob&lt;/code&gt; just to make sure everything works:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;[s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[TensorShape([4]),
 TensorShape([4, 50]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 7]),
 TensorShape([4]),
 TensorShape([4, 13]),
 TensorShape([4, 1200])]
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-121.06135 ,   21.950146,  -69.38415 , -224.08742 ], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So our model technically works&amp;hellip; but does it makes sense?&lt;/p&gt;
&lt;h2 id=&#34;prior-predictive-checks&#34;&gt;Prior predictive checks&lt;/h2&gt;
&lt;p&gt;Prior predictive checks are an extremely valuable technique to assess your model and your priors, before seeing any data. To learn more about PPCs (horrible acronym as the first P can also stand for &lt;em&gt;posterior&lt;/em&gt;), I highly recommend Michael Betancourt&amp;rsquo;s &lt;a href=&#34;https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html&#34;&gt;principled bayesian workflow&lt;/a&gt; case study.&lt;/p&gt;
&lt;p&gt;Anyway, let&amp;rsquo;s generate samples from our model, and use the samples to compute the logits (the linear expression within the &lt;code&gt;inv_logit&lt;/code&gt; function):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inits[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;][
    ::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    intercept[:, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_age, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Each chain gives us 1200 different numbers - the log-odds for cat preference for our 1200 sampled individuals. Let&amp;rsquo;s plot these four histograms:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, l &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(logits):
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(l, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;from chain {i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;rm logit}&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;left(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;theta_j&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;right)$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
lim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlim();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_67_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note that it&amp;rsquo;s OK that each color (each chain) is multimodal - this just means that we&amp;rsquo;re inferring different &amp;ldquo;types&amp;rdquo; of cats preference across groups.&lt;/p&gt;
&lt;p&gt;The problem with what we got is the &lt;em&gt;scale&lt;/em&gt; - having ${\rm logit}\left(\theta_j\right)=-15$ means $\theta_j=0.000000003&amp;hellip;$ which doesn&amp;rsquo;t really makes sense, even for a group that &lt;em&gt;really&lt;/em&gt; likes dogs. This implies that our priors are way too diffuse, the normal(0,10) being the primary suspect. So let&amp;rsquo;s make everything normal(0,1) and do this again:&lt;/p&gt;
&lt;h1 id=&#34;same-likelihood-better-priors&#34;&gt;Same likelihood, better priors&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_state&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_state: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_state), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_eth&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_eth: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_eth), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_income&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_income: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_income), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_age&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_age: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_age), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# intercept&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# coeffs&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; coeffs, intercept, coef_age, a, coef_income, b, coef_eth, c, coef_state: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(
            tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Binomial(
                total_count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
                logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;intercept[:, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_age, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                ),
            ),
            reinterpreted_batch_ndims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        ),
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inits[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;][
    ::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    intercept[:, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_age, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, l &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(logits):
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(l, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;from chain {i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;rm logit}&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;left(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;theta_j&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;right)$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlim(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;lim);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_74_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This makes much more sense. The variance between groups is still there but it doesn&amp;rsquo;t spread across several order of magnitude (that is, with this prior it&amp;rsquo;s no longer plausible that some groups love cats 10 million times more than other groups). This seems like a good starting point.&lt;/p&gt;
&lt;p&gt;Note that the overly wide priors are also very problematic, inference wise - running the same notebook with the first model returns all sorts of sampling problems (divergent transitions, bad mixing, random seed dependence etc) while the 2nd, more informed version does not.&lt;/p&gt;
&lt;h2 id=&#34;getting-the-shapes-right&#34;&gt;Getting the shapes right&lt;/h2&gt;
&lt;p&gt;This is, by far, the hardest thing for me when building a probablistic model with TFP. Knowing where to put &lt;code&gt;[...,],  tf.newaxis&lt;/code&gt; or &lt;code&gt;[None,]&lt;/code&gt; requires some trial and error - here are some checks to verify we got this right (after &lt;em&gt;a lot&lt;/em&gt; of failed attempts and some help from Junpeng Lao):&lt;/p&gt;
&lt;p&gt;First, we want to make sure the model can evaluate the log probability of its own samples, and that we get &lt;code&gt;n_chains&lt;/code&gt; different numbers:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(inits)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-619.5229 , -520.8101 , -460.97076, -609.21765], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, we want to make sure that all shapes of the different parameters in our samples are as we expect, which basically should be the number of chains in the first axis and the shape of whatever it is we&amp;rsquo;re sampling in the rest - or nothing, if it&amp;rsquo;s just a scalar:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;[s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; inits]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[TensorShape([4]),
 TensorShape([4, 50]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 7]),
 TensorShape([4]),
 TensorShape([4, 13]),
 TensorShape([4, 1200])]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main thing to look out for here are redundant extra dimensions (for example, &lt;code&gt;TensorShape([4, 1])&lt;/code&gt; instead of &lt;code&gt;TensorShape([4])&lt;/code&gt; - these will almost always cause broadcasting issues.&lt;/p&gt;
&lt;p&gt;Next, we want to add an extra axis for the data we condition on. Again, this is for broadcasting purposes - we want to make sure &lt;code&gt;tf&lt;/code&gt; &amp;ldquo;replicates&amp;rdquo; the data across different chains.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis, &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;TensorShape([1, 1200])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, the &lt;code&gt;log_prob&lt;/code&gt; function closure - we want to make sure our &lt;code&gt;log_prob&lt;/code&gt; function gets as inputs all the different parameters, concatenates them with the data we&amp;rsquo;re conditioning on, and then uses the original model &lt;code&gt;log_prob&lt;/code&gt; function to evaluate; practically, we want to verify that if we pass all the parameters (&lt;em&gt;without&lt;/em&gt; the conditioning data), we get &lt;code&gt;n_chains&lt;/code&gt; different numbers:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;lp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;x: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(
    list(x) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis, &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;]]
)
lp(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;inits[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1315.5156, -1436.2715, -1799.2578, -1901.1874], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;inference&#34;&gt;Inference&lt;/h2&gt;
&lt;p&gt;With sensible priors and TFP shape issues dealt with, we can proceed with actually runnning the sampler.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32, name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;initializer&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; inits
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace, kr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts(
    lp,
    inits[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],
    bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
    ],
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Always&lt;/em&gt; check your TF shapes:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;[s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; trace]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[TensorShape([1000, 4]),
 TensorShape([1000, 4, 50]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 3]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 3]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 7]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 13])]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This looks good; for arviz intergration purposes, we&amp;rsquo;ll add an extra axis for the parameters whose tensor shape is &lt;code&gt;TensorShape([1000, 4])&lt;/code&gt;, and then call our &lt;code&gt;tfp_trace_to_arviz&lt;/code&gt; helper function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace_ex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [s[&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; s &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; trace]
az_trace &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp_trace_to_arviz((trace_ex, kr))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary(az_trace)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hpd_3%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hpd_97%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mcse_mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mcse_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_bulk&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_tail&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r_hat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 0[0]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.056&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.153&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.779&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.338&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1771&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1806&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2668&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[0]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.016&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.607&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.173&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.155&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.011&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.009&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2822&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2235&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2843&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2538&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[1]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.025&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.505&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.997&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.927&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3978&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4013&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2918&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[2]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.477&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.463&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.362&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.38&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.007&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4207&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2794&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4232&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2521&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[3]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.764&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.896&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.017&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.013&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2102&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1745&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2132&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1908&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Sampling diagnostics look good; we have no divergent transitions, and $\hat{R}$ values are all close to 1:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary(az_trace)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r_hat&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;count    81.0
mean      1.0
std       0.0
min       1.0
25%       1.0
50%       1.0
75%       1.0
max       1.0
Name: r_hat, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We won&amp;rsquo;t go down the model-diagnostics-rabbit-hole now; we&amp;rsquo;re here to learn about Mister P.&lt;/p&gt;
&lt;h2 id=&#34;p-part&#34;&gt;P part&lt;/h2&gt;
&lt;p&gt;So far we&amp;rsquo;ve defined, critisized and fitted a multilevel logisitic regression model. Now comes the poststratification part. Poststratification is a technical and intimidating word; it basically means &amp;ldquo;adjusting the inferences from my sample to the population by using additional knowledge about proportions in the population&amp;rdquo;. To do so, we&amp;rsquo;ll:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Compute a design matrix $X$ for the population.&lt;/li&gt;
&lt;li&gt;Use our 4000 sampled parameters to compute 4000 different logits for each group in the population. This will yield a 4000x6300 matrix.&lt;/li&gt;
&lt;li&gt;For each row (representing a single draw from our posterior), we&amp;rsquo;ll compute the population mean as a weighted sum of per-group cat preference and group&amp;rsquo;s size. This will give us a vector of 4000 numbers.&lt;/li&gt;
&lt;li&gt;The mean of these 4000 numbers will be our estimate for the population mean.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;post_factors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_dummies(poststrat[[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;category&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(
    [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
)
post_interactions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    post_factors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; post_factors[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values[:, None],
    columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1*age_{i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)],
)
post_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([post_factors, post_interactions], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;intercept &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;]
coeffs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;]
coef_age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;]
coef_income &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
coef_eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
coef_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]

logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    intercept[&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(post_features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
)
posterior_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inv_logit(logits)
posterior_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posterior_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6300&lt;/span&gt;)
posterior_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(4000, 6300)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;poststrat_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posterior_prob &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;][:, None] &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
poststrat_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(4000, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So how good is MRP? We plot the histogram of our 4000 different estimates of the population mean, together with the estimate from the sample (dashed line) and the true mean:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(poststrat_prob, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(true_pop_pref, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;population mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sample mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_106_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can see that the posterior mean is much closer to the true mean - so MRP definitely helps!&lt;/p&gt;
&lt;h1 id=&#34;estimates-for-states&#34;&gt;Estimates for states&lt;/h1&gt;
&lt;p&gt;The nice thing about having a model is that we can use it to answer all sorts of different questions. For example, we can repeat the analysis we just did and estimate per-state means. We&amp;rsquo;re still computing the design matrix, logits etc as before but we&amp;rsquo;re constraining ourselves to one state at a time. For each state, we&amp;rsquo;ll compute the model&amp;rsquo;s mean and standard deviations, together with the true mean and the sample mean:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;state_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; namedtuple(
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state_data&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    [
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_sd&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sample_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;true_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    ],
)
states_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;):
    state_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(post_features[:, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;state &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; i)])
    state_poststrat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
    logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
        intercept[&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(
            trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;],
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32),
            axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        )
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(
            coef_income,
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32),
            axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        )
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(
            coef_eth,
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32),
            axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        )
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(
            coef_state,
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32),
            axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        )
    )
    posterior_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inv_logit(logits)
    posterior_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posterior_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, state_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    state_poststrat_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
        posterior_prob
        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;][:, None]
        &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; state_poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
    )
    states_data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(
        state_data(
            i,
            state_poststrat_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std(),
            state_poststrat_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(),
            sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(),
            np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(true_pop&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; state_poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;])
            &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(state_poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]),
            sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
        )
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;state_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(states_data)
state_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;model_state_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;model_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sample_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;true_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;N&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.116844&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.580393&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.596565&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0956771&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.583293&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.658961&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0817888&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.669766&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.823529&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.69817&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.145332&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.505946&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.553341&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0768275&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.493726&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.611111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.443913&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Graphically, this is how this looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;f, ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))
state_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(
    x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;true_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    yerr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_sd&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax,
    kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;scatter&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Model&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
)
state_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(
    x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;true_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sample_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax,
    kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;scatter&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;C1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Sample&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
)
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Cat preference&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_113_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can see that the model predictions of state-wise preferences (blue dots) are closer to the identity line compared to the orange dots (sample per-state mean preferences).&lt;/p&gt;
&lt;p&gt;Another interesting thing to see is how the model uncertainty (quantified by the standard deviation of the model predictions, per state) is related to sample size; we can see that the model is more confident (lower std) for states with higher N, which is what we would expect:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(state_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], state_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_sd&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_116_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary-and-further-reading&#34;&gt;Summary and further reading&lt;/h1&gt;
&lt;p&gt;This post was a code-oriented introduction to MRP, which is a very interesting technique that nicely leverages the built in advantages of multilevel models. We&amp;rsquo;ve also seen how taking a package&amp;rsquo;s priors for granted is not always a good idea, and how prior predictive checks can help us calibrate our priors and our beliefs.&lt;/p&gt;
&lt;p&gt;In case you want to learn more, other than Lauren and Jonah&amp;rsquo;s vignette, these are all excellent reads:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Austin Rochford&amp;rsquo;s &lt;a href=&#34;https://austinrochford.com/posts/2017-07-09-mrpymc3.html&#34;&gt;MRPyMC3&lt;/a&gt; tutorial&lt;/li&gt;
&lt;li&gt;Andrew Gelman&amp;rsquo;s post about Mister P&amp;rsquo;s &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2013/10/09/mister-p-whats-its-secret-sauce/&#34;&gt;secret sauce&lt;/a&gt;. Somewhat more technical and perhaps more political-science specific, but still interesting and relevant.&lt;/li&gt;
&lt;li&gt;Dan Simpson&amp;rsquo;s post on &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2019/08/22/multilevel-structured-regression-and-post-stratification/&#34;&gt;structured priors&lt;/a&gt; for MRP; this is somewhat more advanced, but Dan&amp;rsquo;s posts are always fun to read.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Varying Slopes Models and the CholeskyLKJ distribution in TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/varying-slopes/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/varying-slopes/</guid>
      <description>&lt;h4 id=&#34;tldr&#34;&gt;TL;DR&lt;/h4&gt;
&lt;p&gt;Covariance matrices allow us to capture parameter correlations in multivariate hierarchical models; sampling these using Hamiltonian Monte Carlo in Tensorflow Probability can be tricky and confusing; this post is about some of the math involved and how to get this right.&lt;/p&gt;
&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;p&gt;Hierarchical models allow us to account for variations between different groups in our data. Let&amp;rsquo;s say that, for some reason, we have &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34;&gt;different groups of tadpoles&lt;/a&gt; in different tanks and we want to model per-tank survival rates. Varying intercepts models allow us to fit different models to different tanks, while pooling together information &lt;em&gt;between&lt;/em&gt; tanks. The tanks are somewhat different (they&amp;rsquo;re not the same tank), so we allow their parameters to vary; but they&amp;rsquo;re also similar (they&amp;rsquo;re all tanks with tadpoles, not oranges or ships), so we can do some &amp;ldquo;transfer learning&amp;rdquo; between tanks.&lt;/p&gt;
&lt;p&gt;Varying &lt;em&gt;intercepts&lt;/em&gt; are already very powerful models. However, in many (most?) situations, the models we fit have more than just an intercept. Let&amp;rsquo;s say we have 3 groups in our data, and we want to fit a simple linear model for each group, but also to share information between groups. Each model has two parameters (a slope and an intercept), and we allow these to &lt;em&gt;vary&lt;/em&gt;. We can also allow them to &lt;em&gt;covary&lt;/em&gt;. For example, if higher slopes usually go with lower intercepts, we want to know that, and use that to improve our estimation of both.&lt;/p&gt;
&lt;p&gt;To capture this covariance amongst parameters, we&amp;rsquo;re going to need a covariance matrix.&lt;/p&gt;
&lt;h1 id=&#34;the-lkj-prior&#34;&gt;The LKJ prior&lt;/h1&gt;
&lt;p&gt;Every 2x2 covariance matrix can be decomposed as a product of a diagonal matrix of standard deviations $\sigma_\alpha,\sigma_\beta$ with a correlation matrix $\Sigma$, in the following form (same holds for higher dimensions):&lt;/p&gt;
&lt;p&gt;$$\mathbb{S} = \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right) \cdot \Sigma \cdot \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right)$$&lt;/p&gt;
&lt;p&gt;The decomposition is conceptually useful - it&amp;rsquo;s usually easier to think about the variances (which are single-parameter properties, and depend on things like unit of measurement and typical scale) separately from the correlation structure (a pairwise property). Technically, putting a prior on the variances isn&amp;rsquo;t very hard - we just need to make sure the variables are non-negative.&lt;/p&gt;
&lt;p&gt;A priori, it&amp;rsquo;s not obvious how to put a prior on correlation matrices. We can&amp;rsquo;t sample each matrix element by itself; correlation matrices have to be postitive definite, so their elements are somewhat &amp;ldquo;entangled&amp;rdquo; - the value in the $\left[i,j\right]$-th entry effects the element in the $\left[k,l\right]$-th entry. Luckily for us, in 2009, Lewandowski, Kurowicka, and Joe &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0047259X09000876&#34;&gt;published&lt;/a&gt; a method for generating random correlation matrices, aptly referred to as the LKJ distribution. Like other probablistic programming languages, TFP implements the LKJ distribution. It&amp;rsquo;s a distribution that gets two numbers as inputs - $N$, the dimension of the correlation matrix, and $\eta$, a concentration parameter that controls how plausible are large correlations; Larger $\eta$ mean correlations are more concentrated around zero &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# the necessary imports&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfp
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt 
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; matplotlib.patches &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Ellipse
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; distributions &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; bijectors &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfb
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;enable_eager_execution()

&lt;span style=&#34;color:#75715e&#34;&gt;# for plotting&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_palette(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;muted&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# for reproducibility&lt;/span&gt;
np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;324&lt;/span&gt;)
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_random_seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;234&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here&amp;rsquo;s how samples from different LKJ distributions look like. We sample 500 correltion matrices with $\eta=1$ and 500 matrices with $\eta=50$:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten(), bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linspace(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;), density&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eta=1$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten(), bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linspace(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;), density&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eta=50$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Correlation values&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;500 5x5 correlation matrices&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;problem-1---falling-off-the-manifold&#34;&gt;Problem #1 - falling off the manifold&lt;/h2&gt;
&lt;p&gt;So far so good - sampling correlation matrices seems straightforward. The problem starts when we want to use a Hamiltonian Monte Carlo (and we usually want to use Hamiltonian Monte Carlo) to sample from some larger model that contains an LKJ distribution. HMC allows us to generate samples from arbitrary joint distributions, not only from distributions for which we have explicit sampling methods. Here&amp;rsquo;s a toy example to illustrate the problem. The model is simply a single LKJ distribution within a &lt;code&gt;JointDistributionSequential&lt;/code&gt; object:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;),
    ]
)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&amp;lt;tf.Tensor: id=7897612, shape=(2, 2), dtype=float32, numpy=
 array([[ 1.        , -0.43337458],
        [-0.43337458,  1.        ]], dtype=float32)&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;model.sample()&lt;/code&gt; seems to work, so that&amp;rsquo;s encouraging. However, when we try to &amp;ldquo;naively&amp;rdquo; use an HMC sampler to generate samples from the model, things go wrong. We add a small helper function to avoid rewriting all the kernels everytime; see the &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34;&gt;previous post&lt;/a&gt; for explanations about the different function calls here.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sampleHMC&lt;/span&gt;(log_prob, inits, bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None):
    inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HamiltonianMonteCarlo(
        target_log_prob_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;log_prob,
        step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;,
        num_leapfrog_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
    )
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
        inner_kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TransformedTransitionKernel(inner_kernel, bijectors_list)
        
    adaptive_kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SimpleStepSizeAdaptation(
        inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inner_kernel,
        num_adaptation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;
    )
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_chain(
        num_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
        current_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inits,
        kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;adaptive_kernel,
        num_burnin_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
        trace_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;lkj_samps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(
    log_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; lkj: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([lkj]),
    inits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample()
)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
lkj_samps[:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;# we print the first 3 samples &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=8349304, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 28.062887,  81.77511 ],
        [-80.5103  , -68.75983 ]],

       [[ 65.458626,  72.01995 ],
        [-87.03769 , -59.71089 ]],

       [[104.11292 ,  85.66264 ],
        [-83.73789 , -60.2727  ]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we can already see the problem; these aren&amp;rsquo;t correlation matrices by any means. What&amp;rsquo;s happening here is that HMC, which operates in an unconstrained space of real numbers, &amp;ldquo;falls off&amp;rdquo; the correlation matrices manifold. The solution for this is what&amp;rsquo;s called a &lt;strong&gt;bijector&lt;/strong&gt;. Without getting into the gory mathematical details &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, a bijector can be thought of as a differentiable one-to-one mapping between the unconstrained space in which the HMC trajectories live, and the constrained manifold. HMC produces samples in the unconstrained space, and the appropriate bijector spits out a valid correlation matrix. For us, this bijector is &lt;code&gt;tfb.CorrelationCholesky()&lt;/code&gt;. Note that we need to pass a list of bijectors to the &lt;code&gt;TransformedTransitionKernel&lt;/code&gt; constructor; in this case, we&amp;rsquo;re passing just a single bijector:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;bij_lkj_samps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(
    log_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; lkj: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([lkj]),
    inits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(),
    bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CorrelationCholesky()]
)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
bij_lkj_samps[:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=9873388, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 1.        ,  0.        ],
        [-0.43139905,  0.90216124]],

       [[ 1.        ,  0.        ],
        [-0.43139905,  0.90216124]],

       [[ 1.        ,  0.        ],
        [-0.43139905,  0.90216124]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At first glance, these don&amp;rsquo;t look like correlation matrices either; that&amp;rsquo;s because they&amp;rsquo;re the &lt;em&gt;Cholesky factors&lt;/em&gt; of kosher correlation matrices.&lt;/p&gt;
&lt;h2 id=&#34;overthinking-box---cholesky-factors-3&#34;&gt;Overthinking box - Cholesky factors &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;p&gt;Every correlation matrix $\Sigma$ can be decomposed as a product of a lower triangular matrix $L$ and its transpose $L^T$. More formally, a lower triangular matrix $L$ is the Cholesky factor of some correlation matrix $\Sigma$ if and only if its diagonal elements are strictly positive and each of its rows has unit norm.&lt;/p&gt;
&lt;p&gt;Cholesky factors come up in many different places in statistics, machine learning, metric learning, computational linear algebra, etc. In the context of Monte Carlo simulations, Cholesky factors are used to generate correlated quantities (which we often want) from uncorrelated samples (which are easy to generate in the computer): If $z$ is a matrix of uncorrelated normally distributed numbers, and $L$ is the Cholesky factor of some correlation matrix $\Sigma$, then $Lz$ would have the correlation structure described by $\Sigma$.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a simple demonstration. We generate 1000 samples from a bivariate guassian with zero mean, unit variance and no correlation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MultivariateNormalDiag(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], scale_diag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We now define a correlation matrix between two variables with correlation -0.85. We compute its Cholesky factor, multiply it with the original (uncorrelated) data, and voila:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;M &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;constant([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;],[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
L &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cholesky(M)
Lz &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; L&lt;span style=&#34;color:#a6e22e&#34;&gt;@z&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(z[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], z[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$z$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(Lz[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], Lz[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$Lz$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;upper right&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can see that the two components of $Lz$ are negatively correlated, as expected. More quantitatively, here&amp;rsquo;s the correlation matrix for the cholesky-tranformed data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;correlation(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(Lz))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=9873636, shape=(2, 2), dtype=float32, numpy=
array([[ 0.9999995 , -0.8532509 ],
       [-0.8532509 ,  0.99999976]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;problem-2---the-wrong-log_prob&#34;&gt;Problem #2 - the wrong log_prob&lt;/h2&gt;
&lt;p&gt;So the bijector solves the constrained-unconstrained problem, and HMC can run smoothly. But things are trickier than that (and the sampler won&amp;rsquo;t tell you that). The HMC sampler works with the log probability function of the model. If we have an LKJ distribution somewhere in our model, than for every sample, HMC computes the &lt;code&gt;log_prob&lt;/code&gt; of the correlation matrix according to LKJ. But LKJ is a distribution over correlation matrices, not Cholesky factors of correlation matrices, which is the output of our bijector! So we end up computing the wrong &lt;code&gt;log_prob&lt;/code&gt;, which means we&amp;rsquo;re not sampling from the model we think we&amp;rsquo;re sampling. So what can we do?&lt;/p&gt;
&lt;p&gt;Solution number 1 is to make sure our cholesky-factors-of-correlation-matrices become correlation matrices before we compute their &lt;code&gt;log_prob&lt;/code&gt; according to LKJ. To do so, we need two more bijectors: &lt;code&gt;tfb.CholeskyOuterProduct&lt;/code&gt;, which maps $L$ to $LL^T$, and &lt;code&gt;tfb.Chain&lt;/code&gt; which, surprisingly, chains (composes) the two bijectors:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;chained_bij_samps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(
    &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; lkj: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([lkj]), 
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(), 
    bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Chain([tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CholeskyOuterProduct(), tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CorrelationCholesky()])]
)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
chained_bij_samps[:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=12661134, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 1.        , -0.21354356],
        [-0.21354356,  1.        ]],

       [[ 1.        , -0.21354356],
        [-0.21354356,  1.        ]],

       [[ 1.        ,  0.01905983],
        [ 0.01905983,  1.0000001 ]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This looks good. And this time it actually is - this is doing what we think it&amp;rsquo;s doing. But this is cumbersome, and not very readable. Even worse, when we&amp;rsquo;ll pass these correlations matrices to a multivariate gaussian (the usual case), it&amp;rsquo;ll compute their cholesky factors anyway (check out the &lt;a href=&#34;https://github.com/tensorflow/probability/blob/4dd589ba945db902d28dbb75dc0a795706814d45/tensorflow_probability/python/distributions/mvn_full_covariance.py#L189&#34;&gt;source code&lt;/a&gt;, as well as the depracation warning above it). So we end up sampling cholesky factors, tranforming them back to correlation matrices just to compute their cholesky factors again&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;enter-choleskylkj&#34;&gt;Enter CholeskyLKJ&lt;/h2&gt;
&lt;p&gt;Since &lt;code&gt;tfp-nightly-0.9.0.dev20190830&lt;/code&gt; (a daily-built version that contains the newest changes that have yet to made it into the latest stable release), we have a better option - the &lt;code&gt;CholeskyLKJ&lt;/code&gt; distribution. Unlike LKJ, this is a distribution over &lt;em&gt;cholesky factors&lt;/em&gt; of correlation matrices - so no need to go back and forth, or to chain bijectors&amp;hellip; It&amp;rsquo;s faster, numerically stabler, and it is by the &lt;a href=&#34;https://mc-stan.org/docs/2_19/functions-reference/cholesky-lkj-correlation-distribution.html&#34;&gt;book&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To use it, we just need a single &lt;code&gt;tfb.CorrelationCholesky()&lt;/code&gt; bijector:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CholeskyLKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;),
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;cholesky_lkj_samps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(
    &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; lkj: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([lkj]),
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(),
    bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CorrelationCholesky()]
)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
cholesky_lkj_samps[:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=14269238, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 1.        ,  0.        ],
        [ 0.20048861,  0.97969604]],

       [[ 1.        ,  0.        ],
        [-0.19122852,  0.9815455 ]],

       [[ 1.        ,  0.        ],
        [ 0.18798688,  0.9821716 ]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;a-simple-use-case&#34;&gt;A simple use case&lt;/h1&gt;
&lt;p&gt;We&amp;rsquo;ve covered the technicalities of sampling correlation matrices (and their Cholesky factors) with TFP. To get a more complete picture of how these are actually used, let&amp;rsquo;s see an example. We&amp;rsquo;re sticking with McElreath and Statistical Rethinking; this time we&amp;rsquo;re reproducing the caf waiting times example.&lt;/p&gt;
&lt;h2 id=&#34;fake-data&#34;&gt;Fake data&lt;/h2&gt;
&lt;p&gt;Unlike the tadpoles example, this time we&amp;rsquo;re going to model fake data (aka synthetic data). This may sound strange, but it&amp;rsquo;s actually a &lt;em&gt;very&lt;/em&gt; useful skill, and it&amp;rsquo;s considered by many to be pretty much the first step in a Bayesian data analysis workflow (see &lt;a href=&#34;https://khakieconomics.github.io/2017/04/30/An-easy-way-to-simulate-fake-data-in-stan.html&#34;&gt;here&lt;/a&gt;). The reason is that unlike in a &amp;ldquo;real data analysis&amp;rdquo;, when you&amp;rsquo;re generating fake data, you &lt;em&gt;know&lt;/em&gt; the true underlying data generating process; making sure you can recover its parameters is a very important sanity check. It also helps in verifying the model is correctly specified and that the MCMC sampler does what you think it does, which is good.&lt;/p&gt;
&lt;p&gt;The data we&amp;rsquo;re generating describes the waiting times in 20 different cafs. Each caf has a different average waiting times in the morning and in the afternoon. The average morning waiting time is the intercept, and the difference between afternoon and morning average waiting times is the slope. The intercepts and slopes for each of the 20 cafs are sampled from a (surprise surprise) correlated bivariate Gaussian distribution.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;##### Inputs needed to generate the covariance matrix between intercepts and slopes #####&lt;/span&gt;


a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3.5&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# average morning wait time&lt;/span&gt;
b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# average difference afternoon wait time&lt;/span&gt;
sigma_a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# standard deviation in the (caf-specific) intercepts&lt;/span&gt;
sigma_b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# standard deviation in the (caf-specific) slopes&lt;/span&gt;
rho &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# correlation between intercepts and slopes&lt;/span&gt;

mu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [a,b] &lt;span style=&#34;color:#75715e&#34;&gt;# the mean of our gaussian distribution&lt;/span&gt;
sigmas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [sigma_a,sigma_b] &lt;span style=&#34;color:#75715e&#34;&gt;# vector of standard deviations&lt;/span&gt;
corr_matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,rho], [rho,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]]) &lt;span style=&#34;color:#75715e&#34;&gt;# correlation matrix&lt;/span&gt;
cov_matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;diag(sigmas)&lt;span style=&#34;color:#a6e22e&#34;&gt;@corr_matrix&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@np.diag&lt;/span&gt;(sigmas)  &lt;span style=&#34;color:#75715e&#34;&gt;# the covariance matrix of our gaussian distribution &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After setting the true parameters, we&amp;rsquo;re generating 20 samples of cafs:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_cafs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 20 cafs overall&lt;/span&gt;

caf_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multivariate_normal(mu ,cov_matrix,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_cafs) 
caf_intercept &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; caf_params[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#75715e&#34;&gt;# intercepts are in the first column&lt;/span&gt;
caf_slopes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; caf_params[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#75715e&#34;&gt;# slopes are in the second&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And compute the actual per-caf morning and afternoon waiting times, in 10 different visits. Below is a sample of 10 rows from our dataframe (which has 200 data points overall - 10 visits in 20 cafs):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_visits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 10 visits per caf&lt;/span&gt;

afternoon &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tile([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], n_visits &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; n_cafs&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# alternate values for mornings and afternoons in the data frame&lt;/span&gt;
caf_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(n_cafs),n_visits) &lt;span style=&#34;color:#75715e&#34;&gt;# data for each caf are consecutive rows in the data frame&lt;/span&gt;

mu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; caf_intercept[caf_id] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; caf_slopes[caf_id] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; afternoon &lt;span style=&#34;color:#75715e&#34;&gt;# the regression equation for the mean waiting time&lt;/span&gt;
sigma &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# standard deviation of waiting time within cafs&lt;/span&gt;
wait &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(mu, sigma, n_visits &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; n_cafs) &lt;span style=&#34;color:#75715e&#34;&gt;# generate instances of waiting times&lt;/span&gt;
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(dict(caf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; caf_id, afternoon &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; afternoon, wait &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wait))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_string(index&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt; caf  afternoon      wait
    8          1  2.175858
    9          0  2.364313
    9          1  1.744504
   14          0  3.716937
    3          1  1.419163
    0          1  1.959044
    5          0  1.045913
    4          0  1.083699
   17          1  2.796278
   15          1  3.430852
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;the-model&#34;&gt;The model&lt;/h2&gt;
&lt;p&gt;We specify in math (and latex) the model described above:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
W_i &amp;amp; \sim \text{Normal}(\alpha_{caf[i]}+\beta_{caf[i]}\cdot \text{AFTERNOON}_i,\sigma) \\\&lt;br&gt;
\binom{\alpha_{caf}}{\beta_{caf}} &amp;amp; \sim \text{MVNormal}\left(\binom{\alpha}{\beta},\mathbb{S}\right) \\\&lt;br&gt;
\mathbb{S} &amp;amp; = \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right) \cdot LL^T \cdot \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right)  \\\&lt;br&gt;
\alpha &amp;amp; \sim \text{Normal}(5,2) \\\&lt;br&gt;
\beta &amp;amp; \sim \text{Normal}(-1,0.5) \\\&lt;br&gt;
\sigma_{\alpha},\sigma_{\beta} &amp;amp; \sim \text{Exp}(1) \\\&lt;br&gt;
\sigma &amp;amp; \sim \text{Exp}(1) \\\&lt;br&gt;
L &amp;amp; \sim \text{CholeskyLKJ}(2,2) \\\&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CholeskyLKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# rho, the prior for the correlation matrix between intercepts and slopes&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exponential(rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),sample_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#75715e&#34;&gt;# sigma, prior std for the waiting time&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exponential(rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),sample_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_caf, prior of stds for intercepts and slopes (vector of 2)&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(loc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;), sample_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),   &lt;span style=&#34;color:#75715e&#34;&gt;# b, the prior mean for the slopes&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(loc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), sample_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),   &lt;span style=&#34;color:#75715e&#34;&gt;# a, the prior mean for the intercepts&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; a,b,sigma_caf,sigma,chol_rho : tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample( &lt;span style=&#34;color:#75715e&#34;&gt;# per-caf intercepts and slopes&lt;/span&gt;
            tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MultivariateNormalTriL(
                loc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([a,b],axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
                scale_tril &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LinearOperatorDiag(sigma_caf)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(chol_rho)
            ),
            sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_cafs
        ),
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; mvn, a, b, sigma_caf, sigma : tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(  &lt;span style=&#34;color:#75715e&#34;&gt;#per-caf waiting times&lt;/span&gt;
            tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(
                loc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(mvn[:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],caf_id,axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(mvn[:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],caf_id,axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;afternoon,
                scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sigma
            ),
            reinterpreted_batch_ndims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        )
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Couple of non-trivial things in the model above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MultivariateNormalTriL&lt;/code&gt;: we&amp;rsquo;ve mentioned that a covariance matrix can be specified as $\Lambda L L^T\Lambda$ where $\Lambda$ is a diagonal matrix of standard deviations and $L$ is the cholesky factor of the correlation matrix. &lt;code&gt;MultivariateNormalTriL&lt;/code&gt; is a parametrization of a multivariate normal distribution whose covariance matrix is specificied using the lower triangular matrix $\Lambda L$.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LinearOperatorDiag&lt;/code&gt;: this turns a &lt;code&gt;sigma-caf&lt;/code&gt; vector of length 2 to a 2x2 diagonal matrix; very similar to &lt;code&gt;tf.diag&lt;/code&gt;, but handles all the batching semantics for us.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tf.gather&lt;/code&gt;: this takes each intercept (in the case of &lt;code&gt;mvn[:,:,0]&lt;/code&gt;) and slope (in the case of &lt;code&gt;mvn[:,:,1]&lt;/code&gt; and tiles it 10 times, so overall we get a loc vector of size 200, with which we generate 200 different waiting times, 10 per caf.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We now declare the &lt;code&gt;target_log_prob&lt;/code&gt; function for the HMC kernel, and initial values for 4 different chains. Like before, we throw away the last sample (predicted waiting times); we want to plug the waiting times from the data into the likelihood, instead.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
log_prob_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; rho, sigma, sigma_caf, b, a, mvn : model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([rho, sigma, sigma_caf, b, a, mvn ,wait])
init_rho, init_sigma, init_sigma_caf, init_b, init_a, init_mvn, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These initial values are used to specify the shape of the initial values we actually pass, specified below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;init_rho &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stack([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n_chains)])
init_sigma &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones_like(init_sigma)
init_sigma_caf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones_like(init_sigma_caf)
init_b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(init_b)
init_a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(init_a)
init_mvn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(init_mvn)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We define the list of bijectors. Note that since standard deviations are non-negative, their support is constrained, and we need a bijector here, as well. The appropriate bijector in this case is &lt;code&gt;tfb.Exp&lt;/code&gt;. Once we specificed a bijectors list, we need to match a bijector for any distribution in our &lt;code&gt;JointDistributionSequential&lt;/code&gt; object; since the support of &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; and &lt;code&gt;mvn&lt;/code&gt; is unconstrained, we simply use an identity transformation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CorrelationCholesky(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;states &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(log_prob_fn,
                [init_rho, init_sigma, init_sigma_caf, init_b, init_a, init_mvn],
                bijectors_list)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;[s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; states]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[TensorShape([Dimension(500), Dimension(4), Dimension(2), Dimension(2)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(1)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(2)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(1)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(1)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(20), Dimension(2)])]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Shapes look alright. To see the posterior distribution of covariance values, we move back from Cholesky factors to correlation matrices, and multiply by the inferred sigmas (the zeroth axis is the number of samples, first is the number of the chain, so we transpose the second and third axes):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;rhos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; states[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.transpose&lt;/span&gt;(states[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Same as above, we create diagonal matrices from our sampled &lt;code&gt;sigma_alpha&lt;/code&gt;, &lt;code&gt;sigma_beta&lt;/code&gt; values:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sigmas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; states[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
diag_sigmas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LinearOperatorDiag(sigmas)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inferred_covs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(diag_sigmas&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(rhos),diag_sigmas)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (row_idx,col_idx), title &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip([(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;),(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)],[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma_{&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;alpha}$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Covariance&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma_{&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;beta}$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;131&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;row_idx&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;col_idx)
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(inferred_covs[:,:,row_idx,col_idx]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten(), label &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Posterior&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(cov_matrix[row_idx,col_idx],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;True value&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(title)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can also compare empirical waiting times with sampled waiting times:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;morning_wait_emp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;afternoon == 0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;caf&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;wait&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
afternoon_wait_emp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;afternoon == 1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;caf&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;wait&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;morning_wait_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(states[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:,:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
afternoon_wait_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(states[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:,:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; morning_wait_pred
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And we get the shrinkage that decorates Statistical Rethinking&amp;rsquo;s front cover:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))
ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;111&lt;/span&gt;)
vals, vecs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eigh(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cov(morning_wait_emp, afternoon_wait_emp))
theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;degrees(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arctan2(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;vecs[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]))
w, h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(vals)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; contour_line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;):
    ell &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Ellipse(xy&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(morning_wait_emp), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(afternoon_wait_emp)),
                  width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;w&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;contour_line, height&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;h&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;contour_line,
                  angle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;theta, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
    ell&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_facecolor(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;none&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
    ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_artist(ell)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(morning_wait_emp,afternoon_wait_emp,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Empirical&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(morning_wait_pred,afternoon_wait_pred, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;MCMC&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(morning_wait_emp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(),afternoon_wait_emp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(),marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,s&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Grand Mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; a,b,c,d &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(morning_wait_emp, afternoon_wait_emp,  morning_wait_pred, afternoon_wait_pred):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arrow(a,b,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(c&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;a),&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(d&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;b), head_width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;, alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Morning wait&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Afternoon wait&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;4.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Formally, the distribution is defined as: $\text{LKJ}\left(\Sigma\vert\eta\right)\propto\det\left(\Sigma\right)^{\left(\eta-1\right)}$. Intuitively, the correlation matrix defines an ellipsoid in $N$ dimensions, and its determinant is the volume of the ellipsoid. So, higher correlations -&amp;gt; tighter ellipsoid -&amp;gt; smaller volume -&amp;gt; smaller determinant -&amp;gt; more likely for small $\eta$ and less likely for large $\eta$. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Sigrid Keydana did an excellent job explaining TFP bijectors, and specifcally the intuition behind the jacobian correction, in &lt;a href=&#34;https://blogs.rstudio.com/tensorflow/posts/2019-04-05-bijectors-flows/&#34;&gt;this&lt;/a&gt; post. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Overthinking boxes are specific (usually mathematical) dive-ins in Statistical Rethinking. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>A Tutorial on Varying Intercepts Models with TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/varying-intercepts/</link>
      <pubDate>Mon, 08 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/varying-intercepts/</guid>
      <description>&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;p&gt;This post is about building varying intercepts models using TensorFlow Probability (&amp;ldquo;TFP&amp;rdquo;). It&amp;rsquo;s basically my attempt to translate Sigrid Keydana&amp;rsquo;s wonderful &lt;a href=&#34;https://blogs.rstudio.com/tensorflow/posts/2019-05-06-tadpoles-on-tensorflow/&#34;&gt;blog post&lt;/a&gt; from R to Python. I&amp;rsquo;m doing this for a couple of reasons: First, I&amp;rsquo;ve played with TFP before, was quite impressed by its performance and flexibility, and wanted to learn more about it; Second, I wanted to start blogging, and this seemed like an easy start; Last, TFP is rather new, and there aren&amp;rsquo;t a whole lot of resources and tutorials about it - so this might even prove useful to someone, someday.&lt;/p&gt;
&lt;p&gt;Sigrid dedicated her post to &lt;a href=&#34;https://twitter.com/rlmcelreath&#34;&gt;Richard McElreath&lt;/a&gt; and his book; I&amp;rsquo;d like to join her on that. I was looking for a good introduction to Bayesian stats for quite some time. BDA3 was too technical for me at that point, Kruschke&amp;rsquo;s was excellent but didn&amp;rsquo;t really dive into the more sophisticated topics I wanted to learn. Statistical Rethinking was spot on - interesting, fun to read, and super helpful. It&amp;rsquo;s very code-oriented, and has already been re-written in pure stan, brms, pymc3, julia and probably many others.&lt;/p&gt;
&lt;p&gt;Stats-wise, this post is going to be about varying intercepts models, which are perhaps the simplest kind of a multilevel model. The main idea behind them - called partial pooling - is simple and beautiful, but here I want to focus on the code, not the stats; for a nice introductory demo, check out &lt;a href=&#34;http://mfviz.com/hierarchical-models/&#34;&gt;this&lt;/a&gt; beautiful visualization, or &lt;a href=&#34;http://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/&#34;&gt;this&lt;/a&gt; one. Better yet, get a copy of Statistical Rethinking and read the original. :-)&lt;/p&gt;
&lt;h1 id=&#34;the-data&#34;&gt;The data&lt;/h1&gt;
&lt;p&gt;We&amp;rsquo;re given data about 48 different tanks containing tadpoles (pre-frogs). Each tank has a &lt;code&gt;density&lt;/code&gt; (the initial number of tadpoles in it), a categorical feature &lt;code&gt;pred&lt;/code&gt; (whether the tank contained a predator or not), a categorical feature &lt;code&gt;size&lt;/code&gt; (big tank or small tank), the number of surviving tadpoles &lt;code&gt;surv&lt;/code&gt; and the proportion of surviving tadpoles &lt;code&gt;propsurv&lt;/code&gt; (which is simply &lt;code&gt;surv&lt;/code&gt;/&lt;code&gt;density&lt;/code&gt;). The original data came with the book&amp;rsquo;s R package; Luckily, it&amp;rsquo;s hosted in Osvaldo Martin&amp;rsquo;s &lt;a href=&#34;https://github.com/aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3&#34;&gt;repo&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;https://raw.githubusercontent.com/aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3/master/Data/reedfrogs.csv&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;Tank&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;density&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;pred&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;surv&lt;/th&gt;
&lt;th&gt;propsurv&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td&gt;0.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Tank densities are either 10, 25 or 35.&lt;/p&gt;
&lt;h1 id=&#34;the-model&#34;&gt;The model&lt;/h1&gt;
&lt;p&gt;Our goal is to compute the probability of survival in each of the tanks. &lt;code&gt;propsurv&lt;/code&gt; is one way to do this, which is straightforward and intuitive - simply compute the per-tank ratio of surviving tadpoles. But this doesn&amp;rsquo;t make much sense, especially if you consider the small sample sizes - if I&amp;rsquo;d give you a tank with &lt;code&gt;density=1&lt;/code&gt;, would you feel comfortable with saying that the probability of survival is either 0% (&lt;code&gt;surv=0&lt;/code&gt;) or 100% (&lt;code&gt;surv=1&lt;/code&gt;)? Probably not.&lt;/p&gt;
&lt;p&gt;A different approach would be to ignore between-tanks variations, and assume all tanks have exactly the same probability of survival. Our best estimate is then the ratio of all the surviving tadpoles (in all tanks, combined) - or &lt;code&gt;sum(surv)/sum(density)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A varying intercept model is somewhat in between - it assumes each tank has its own probability of survival, but that all these probabilities are coming from some distribution over &amp;ldquo;probabilities of survival&amp;rdquo;. This is how it looks like:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{\alpha} &amp;amp; \sim \text{Normal}(0,1.5) \\\&lt;br&gt;
\sigma &amp;amp; \sim \text{Exponential}(1) \\\&lt;br&gt;
\text{logit}\left(p_i\right) &amp;amp; \sim \text{Normal}\left(\bar{\alpha},\sigma\right) \\\&lt;br&gt;
s_i &amp;amp; \sim \text{Binomial}(n_i,p_i) \\\&lt;br&gt;
\end{align}
$$&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s all this? In short - we assume the logits of the survival probabilities are sampled from some normal distribution, whose parameters (often called &amp;ldquo;hyperparameters&amp;rdquo;) we&amp;rsquo;re trying to infer. &lt;code&gt;a_bar&lt;/code&gt; is the mean of this normal distribution, and we put a generic weakly informative prior on it - normal(0,1.5). &lt;code&gt;sigma&lt;/code&gt; is the standard deviation of this normal distribution, and we put an exponential prior on it. After sampling these two numbers, we plug them into the logits distribution, sample 48 different logit values, transform them to probabilities and sample 48 survival predictions from the binomial distributions (one per tank).  Now to the code itself. We begin with the necessary imports:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfp
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt 
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
tfd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distributions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For ease-of-use, we&amp;rsquo;re using TensorFlow in Eager mode, which allows a more interactive and iterative workflow.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;enable_eager_execution()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;some-tfps-pre-requisites&#34;&gt;Some TFP&amp;rsquo;s pre-requisites&lt;/h2&gt;
&lt;p&gt;Before we start implementing the model itself, we need to cover some of the basic terminology around a &lt;code&gt;TensorFlow Distribution&lt;/code&gt;. For the purposes of this introductory post, you can think of a distribution as an object with the following two methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sample()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;log_prob()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both are pretty straightforward - &lt;code&gt;sample()&lt;/code&gt; allows you to generate samples from a given distribution; &lt;code&gt;log_prob()&lt;/code&gt; allows you to calculate the log-probability of a given value(s). There are other methods, of course, but these are the important ones for us.
There are two more attributes we need to mention:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;event_shape&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch_shape&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These were, at least for me, quite confusing (despite their pretty good &lt;a href=&#34;https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Distributions_Tutorial.ipynb&#34;&gt;docs&lt;/a&gt;). &lt;code&gt;event_shape&lt;/code&gt; is the simpler of the two - if I have some joint probability distribution over N random variables, its &lt;code&gt;event_shape&lt;/code&gt; is N. For example, a bivariate gaussian would have an event shape of 2.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;batch_shape&lt;/code&gt; is trickier: TFP allows you to create a single Distribution object, which actually contains multiple, independent distributions. For example, &lt;code&gt;tfd.Bernoulli(probs=[.3, .5, .7])&lt;/code&gt; is a Distribution object composed of 3 different Bernoulli random variables (RVs) with probabilities of success .3, .5 and .7. The number of the independent distributions contained in this single object is its &lt;code&gt;batch_shape&lt;/code&gt;. Why do this? My best guess is that it gives TFP the ability to make use of the underlying TF infrastructure, in which batching (and broadcasting along a batch dimension) is a fundamental operation. We&amp;rsquo;ll get back to this in the code below.&lt;/p&gt;
&lt;p&gt;Now we&amp;rsquo;ll go ahead and define the model itself using TFP&amp;rsquo;s &lt;code&gt;JointDistributionSequential&lt;/code&gt; API:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, scale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exponential(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;),
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma, a_bar: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;a_bar, scale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sigma),sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]),
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; l: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Binomial(total_count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;density&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;float32&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;), logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;l),
                                  reinterpreted_batch_ndims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The main workhorse here is &lt;code&gt;tfd.JointDistributionSequential&lt;/code&gt;, which is very similar to &lt;code&gt;Sequential&lt;/code&gt; in Keras or PyTorch. It&amp;rsquo;s an object composed of list of Distribution-making functions (&lt;code&gt;tfd.Distribution&lt;/code&gt;s or Python callables that return a &lt;code&gt;tfd.Distribution&lt;/code&gt;). The idea of sequentially stacking distributions, and adding the dependencies between them (the fact that the values sampled from &lt;code&gt;tfd.Normal&lt;/code&gt; and &lt;code&gt;tfd.Exponential&lt;/code&gt; are &amp;lsquo;fed&amp;rsquo; into the 3rd distribution as its mean and standard deviation) is simple and intuitive, and fits nicely in the hierarchical modeling workflow; the code above is basically a 1-to-1 translation of the model specification.&lt;/p&gt;
&lt;p&gt;The tricky parts here are TFP&amp;rsquo;s &lt;code&gt;Sample&lt;/code&gt; and &lt;code&gt;Independent&lt;/code&gt;. What are these, then?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Sample&lt;/code&gt; - The third function receives the hyper-parameters &lt;code&gt;sigma&lt;/code&gt; and &lt;code&gt;a_bar&lt;/code&gt;, and should return one number per tank, drawn from a &lt;code&gt;normal(a_bar,sigma)&lt;/code&gt;. &lt;code&gt;tfd.Sample&lt;/code&gt; allows us to draw samples from the product distribution of all these 48 Gaussians; each sample from &lt;code&gt;Sample&lt;/code&gt; is a vector of 48 (uncorrelated) numbers, all with the same mean &lt;code&gt;a_bar&lt;/code&gt; and standard deviation &lt;code&gt;sigma&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Independent&lt;/code&gt; - the third distribution returns a vector of 48 numbers. If we simply write &lt;code&gt;tfd.Binomial(total_count=df.density.astype(&#39;float32&#39;), logits=l)&lt;/code&gt;, we&amp;rsquo;ll get a distribution with a &lt;code&gt;batch_shape&lt;/code&gt; of 48 and an &lt;code&gt;event_shape&lt;/code&gt; (), representing a scalar output. Wrapping this with &lt;code&gt;tfd.Independent&lt;/code&gt; transforms this output to be of &lt;code&gt;batch_shape&lt;/code&gt; () and &lt;code&gt;event_shape&lt;/code&gt; 48, representing a vector output, like we want it to be.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another possibly-confusing issue here is the order of the parameters in the lambda expressions. The first parameter is the output of the previous distribution in the list, the second parameter is the output of the previous-previous distribution, etc&amp;hellip; This is why they third distribution gets &lt;code&gt;sigma&lt;/code&gt; before &lt;code&gt;a_bar&lt;/code&gt; despite the fact &lt;code&gt;sigma&lt;/code&gt; is defined &lt;em&gt;after&lt;/em&gt; &lt;code&gt;a_bar&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I found this API somewhat different than the &amp;ldquo;natural&amp;rdquo; way to think about the problem; however, if this ends up with  superior performance, it&amp;rsquo;s probably worth the learning curve for a wide enough range of problems.&lt;/p&gt;
&lt;h1 id=&#34;sampling-from-a-model&#34;&gt;Sampling from a model&lt;/h1&gt;
&lt;p&gt;The model&amp;rsquo;s &lt;code&gt;sample()&lt;/code&gt; method gets a &lt;code&gt;sample_shape&lt;/code&gt; argument which determines the shape of the generated sample. This, in turn, will be used to tell the MCMC sampler how many chains to run in parallel.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;

initial_a, initial_s, initial_logits, init_surv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; m&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Since we&amp;rsquo;ve asked for 4 chains, &lt;code&gt;m.sample()&lt;/code&gt; returns 4 samples from the &lt;code&gt;a_bar&lt;/code&gt; hyperprior and 4 samples from the &lt;code&gt;sigma&lt;/code&gt; hyperprior; these, in turn, generate 4 new normal distributions, from which we sample 4x48 logit values. These values are then &amp;ldquo;pushed forward&amp;rdquo;, generating 4x48 samples from the binomial survival distributions. These survival predictions can (and probably should) be used to perform prior predictive checks, but we don&amp;rsquo;t need them to define the sampler, itself.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;initial_a&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, initial_s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, initial_logits&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, init_surv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(TensorShape([Dimension(4)]),
 TensorShape([Dimension(4)]),
 TensorShape([Dimension(4), Dimension(48)]),
 TensorShape([Dimension(4), Dimension(48)]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we create the sampler object. This step is composed of 3 different TFP objects. The first is the Hamiltonian Monte Carlo transition kernel, which uses the model&amp;rsquo;s &lt;code&gt;.log_prob()&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HamiltonianMonteCarlo(
    target_log_prob_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x,y,z : m&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([x,y,z,df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;surv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;float32&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)]),
    step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;,
    num_leapfrog_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that we&amp;rsquo;re not using the model&amp;rsquo;s &lt;code&gt;.log_prob()&lt;/code&gt; &lt;em&gt;as is&lt;/em&gt;; instead, we make sure that the log-probability is always computed with respect to the actual, observed survival data. This is the purpose of the &lt;code&gt;lambda&lt;/code&gt; function above. For the other two required parameters, I&amp;rsquo;m using the ones from Sigrid&amp;rsquo;s post.&lt;/p&gt;
&lt;p&gt;The second part is the &lt;code&gt;SimpleStepSizeAdaptation&lt;/code&gt; object, which takes the kernel defined above and returns a new kernel with dynamic step size adaptation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SimpleStepSizeAdaptation(
    inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inner_kernel,
    target_accept_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;,
    num_adaptation_steps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Lastly, the sampling function. This object takes as input the initial states (and through them, number of chains to run), number of burnin steps, number of steps to run after burnin, a kernel (our augmented HMC kernel), and a trace function, which determines what kind of intermediate results we want to save. After sampling ends (this can take a while, depending on the complexity of your model), the function returns the samples (and traced results). Here I&amp;rsquo;ve decided not to save intermediate results, at all; the simple diagnostics I&amp;rsquo;m interested in can be computed from the samples themselves.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;a_bars, sigmas, logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_chain(
    current_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[
        tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(initial_a), 
        tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones_like(initial_s),
        initial_logits
    ],
    num_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
    num_burnin_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
    kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kernel,
    trace_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s have a look at the output shapes:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;a_bars&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, sigmas&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, logits&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(TensorShape([Dimension(500), Dimension(4)]),
 TensorShape([Dimension(500), Dimension(4)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(48)]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sampler returned 500 samples per chain per parameter - exactly what we want.&lt;/p&gt;
&lt;p&gt;TFP provides standard MCMC diagnostics, such as effective sample size per logit parameter (we average over chains):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;effective_sample_size(logits),axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=1643926, shape=(48,), dtype=float32, numpy=
array([ 39.01448 ,  27.656044,  64.033554,  23.641933,  38.67304 ,
        43.81818 ,  27.42485 ,  56.60047 ,  86.46597 ,  53.400955,
        62.463234,  68.98154 ,  71.84833 ,  85.98772 ,  53.90014 ,
        45.368874,  57.142807,  64.70456 ,  80.501144,  30.96955 ,
        51.123882,  90.971016,  83.67827 , 133.95776 , 147.53087 ,
       237.56706 , 124.73306 , 213.96054 , 255.63586 , 127.86496 ,
       169.16728 , 222.58665 ,  57.26799 ,  62.313004,  59.934887,
       140.44281 , 126.62906 ,  44.229973,  80.57881 , 100.344055,
       102.71631 , 307.0775  , 298.0421  , 298.77765 , 275.2672  ,
       241.8357  , 134.39154 , 334.7177  ], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And R-hat values:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;potential_scale_reduction(logits)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=1643986, shape=(48,), dtype=float32, numpy=
array([1.0393666, 1.0419586, 1.014595 , 1.0326122, 1.0066991, 1.0365033,
       1.1032237, 1.0193528, 1.0026469, 1.03286  , 1.0212902, 1.0046616,
       1.0046593, 1.0190336, 1.0491707, 1.0185002, 1.0236404, 1.0240865,
       1.0135043, 1.0091226, 1.0240618, 1.0212263, 1.0040884, 1.0057993,
       1.0115193, 1.0074626, 1.0053723, 1.0013644, 1.0038955, 1.0128344,
       1.0199273, 1.0040274, 1.1276014, 1.0033313, 1.0127679, 1.0017091,
       1.0118763, 1.0570774, 1.04308  , 1.0189458, 1.0144566, 1.0009695,
       1.0063009, 1.0008804, 1.0011569, 1.0057343, 1.0079254, 1.0071955],
      dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can easily inspect the traceplots of the hyperparameters (each color stands for a different chain):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;121&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(a_bars&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(),alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;122&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(sigmas&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(),alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_34_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We get nicely mixed chains, which is good. We can also plot the posterior distributions of the logits for the different tanks:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n_chains):
        sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kdeplot(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(logits[:,j,i]))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_36_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here, each subplot corresponds to one tank, and different colors represent different chains. Just by eye-balling the posteriors, we can see a lot of variability between tanks; this is obvious when we compute posterior survival probabilities themselves:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;ps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sigmoid(logits)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]):
    current_ps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ps[:,:,i]
    pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;errorbar(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[i],y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[current_ps&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()],
                     yerr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([current_ps&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;quantile(current_ps,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;),
                                    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;quantile(current_ps,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.75&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;current_ps&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
                     fmt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;o&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
    act &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(i,df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;propsurv&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Tank number&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Survival probability&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axhline(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;surv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;density&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(),lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; density_change &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;density&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;diff())[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:]:
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(density_change,ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend([pred,act],[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;50&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; Prediction Interval&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;propsurv&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_38_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The black dots are the posterior mean probabilities, the errorbars represent the interquartile range, the red dots are &lt;code&gt;propsurv&lt;/code&gt; (the no-pooling estimate), and the blue horizontal line is the grand mean (the complete-pooling estimate). Vertical lines split the tanks to densities 10, 25 and 35. We can see that, as expected, posterior probabilities are shrunk towards the grand mean. We can also plot the difference between the posterior means and &lt;code&gt;propsurv&lt;/code&gt;, to observe that shrinkage is indeed larger when the sample size is smaller:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]):
    current_ps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ps[:,:,i]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(i,(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;propsurv&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;current_ps&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()),c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axhline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; density_change &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;density&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;diff())[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:]:
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(density_change,ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Tank number&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Shrinkage&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_40_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h1&gt;
&lt;p&gt;TFP certainly has a different feel to it compared to other probabilistic programming frameworks like PyMC3 or Stan; specifically, the introduction of batching semantics, and the complexity of the API that is exposed, are very different and pose a real learning curve. The slope, I guess, depends on one&amp;rsquo;s background.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
