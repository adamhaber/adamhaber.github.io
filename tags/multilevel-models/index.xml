<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Multilevel Models | Adam Haber</title>
    <link>https://adamhaber.github.io/tags/multilevel-models/</link>
      <atom:link href="https://adamhaber.github.io/tags/multilevel-models/index.xml" rel="self" type="application/rss+xml" />
    <description>Multilevel Models</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 18 Nov 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://adamhaber.github.io/img/icon-192.png</url>
      <title>Multilevel Models</title>
      <link>https://adamhaber.github.io/tags/multilevel-models/</link>
    </image>
    
    <item>
      <title>Mr. P meets TFP - mixed effects model with post-stratification in TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/mrp/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/mrp/</guid>
      <description>

&lt;h2 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learn an interesting method for generalizing inferences from a biased sample to a population of interest&lt;/li&gt;
&lt;li&gt;See why prior predictive checks are great&lt;/li&gt;
&lt;li&gt;Implement a simple mixed-effects model in TFP&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;

&lt;p&gt;This post is a TFP port of Lauren Kennedy and Jonah Gabry&amp;rsquo;s excellent &lt;a href=&#34;http://mc-stan.org/rstanarm/articles/mrp.html&#34; target=&#34;_blank&#34;&gt;MRP with rstanarm&lt;/a&gt; vignette. It describes a very interesting statistical method for generalizing inferences from a biased sample to a population of interest. The method is called multilevel regression with poststratification, or MRP if you prefer acronyms, or Mister P if you prefer statisticians jokes. Along the way, we&amp;rsquo;ll see why prior predictive checks are so nice and important, how to implement a mixed-effect model in TFP, and how to make predictions for smaller sub-populations.&lt;/p&gt;

&lt;p&gt;I chose to port the vignette because the problem MRP address - generalizing from a biased sample to a population - is so prevalent and important, that knowing what are the possible tools to handle it seemed valuable. I found that porting models from one language to another is an excellent way to learn the model, the problem, and the languages themselves, so it&amp;rsquo;s kind of a win-win-win and publishing it might also help others so why not.&lt;/p&gt;

&lt;p&gt;I strongly recommend reading the original vignette; the people who wrote it are much more knowledgeable than I am about this subject, and I also chose to focus on slightly different things so they&amp;rsquo;re not 100% overlapping. At the end of this post you can find links for further reading.&lt;/p&gt;

&lt;h3 id=&#34;imports-and-helper-functions-data-generation&#34;&gt;Imports and helper functions - data generation&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from collections import namedtuple
import numpy as np
import itertools as it
import pandas as pd
from scipy.special import expit as inv_logit
from scipy.stats import sem
import seaborn as sns
import matplotlib.pyplot as plt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.random.seed(98)

sns.set_palette(&amp;quot;muted&amp;quot;)
params = {
    &#39;legend.fontsize&#39;: &#39;x-large&#39;,
    &#39;figure.figsize&#39;: (9, 6),
    &#39;axes.labelsize&#39;: &#39;x-large&#39;,
    &#39;axes.titlesize&#39;:&#39;x-large&#39;,
    &#39;xtick.labelsize&#39;:&#39;x-large&#39;,
    &#39;ytick.labelsize&#39;:&#39;x-large&#39;
}
plt.rcParams.update(params)
%config InlineBackend.figure_format = &#39;retina&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;the-data&#34;&gt;The data&lt;/h1&gt;

&lt;p&gt;The data we&amp;rsquo;ll work with is simulated data; this has the obvious advantage that we know the ground truth so we&amp;rsquo;ll be able to assess just how well our method generalizes to the population. The data describes the proportion of the population who would choose to adopt a cat over a dog, given the opportunity. Our outcome variable in this example is binary (cat/dog), but MRP is not restricted to such outcomes and can be used for discrete outcomes with more than two values, as well as continuous outcomes.&lt;/p&gt;

&lt;p&gt;These are the variables we&amp;rsquo;ll be working with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sex = range(2)
eth = range(3)
age = range(7)
income = range(3)
state = range(50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;They&amp;rsquo;re all categorical; we use zero-based indexing to enumerate them (instead of calling them &amp;lsquo;Male&amp;rsquo;, &amp;lsquo;Female&amp;rsquo; etc) because it&amp;rsquo;ll make all the indexing gymnastics in the actual implementation somewhat simpler.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;poststrat&lt;/code&gt; is a dataframe containing all $2\times3\times7\times3\times50=6300$ possible combinations of these variables:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;poststrat = pd.DataFrame(
    list(it.product(sex, eth, age, income, state)),
    columns=[&amp;quot;sex&amp;quot;, &amp;quot;eth&amp;quot;, &amp;quot;age&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;state&amp;quot;],
)
poststrat.sample(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4675&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1749&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;49&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2460&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;poststrat.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(6300, 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below are the different proportions of the different variables &lt;em&gt;in the population&lt;/em&gt;. For example, 20% of the population are in the first age group, 10% are in the second, etc. For each combination of variables we&amp;rsquo;ll compute the number of people that share this specific combination by multiplying the total number of people in the population (assumed to be 250 million) with the different probabilities (this means we&amp;rsquo;re assuming the joint probability distribution factorizes, that is - that the different variables are independent).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p_age = np.array([0.2, 0.1, 0.2, 0.2, 0.10, 0.1, 0.1])
p_sex = np.array([0.52, 0.48])
p_eth = np.array([0.5, 0.2, 0.3])
p_income = np.array([0.50, 0.35, 0.15])
p_state_tmp = np.random.uniform(low=10, high=20, size=50)
p_state = np.array(p_state_tmp / p_state_tmp.sum())

poststrat[&amp;quot;N&amp;quot;] = (
    250e6
    * p_sex[poststrat[&amp;quot;sex&amp;quot;]]
    * p_eth[poststrat[&amp;quot;eth&amp;quot;]]
    * p_age[poststrat[&amp;quot;age&amp;quot;]]
    * p_income[poststrat[&amp;quot;income&amp;quot;]]
    * p_state[poststrat[&amp;quot;state&amp;quot;]]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We also assume that different groups have different probabilities of being included in the sample; in a way, that&amp;rsquo;s the entire point (if all groups had the same probability of being included in the sample then the sample was representative of the population). There&amp;rsquo;s a baseline probability of being in the sample, but it cancels out in the weighted average; what determines who is in our sample is &lt;code&gt;p_response_weighted&lt;/code&gt;, which is &lt;code&gt;p_response&lt;/code&gt; weighted by the number of people in each group:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p_response_baseline = 0.01
p_response_sex = np.array([2, 0.8]) / 2.8
p_response_eth = np.array([1, 1.2, 2.5]) / 4.7 
p_response_age = np.array([1, 0.4, 1, 1.5, 3, 5, 7]) / 18.9
p_response_inc = np.array([1, 0.9, 0.8]) / 2.7
p_response_state = np.random.beta(a=1, b=1, size=50)
p_response_state = p_response_state / p_response_state.sum()

p_response = (
    p_response_baseline
    * p_response_sex[poststrat[&amp;quot;sex&amp;quot;]]
    * p_response_eth[poststrat[&amp;quot;eth&amp;quot;]]
    * p_response_age[poststrat[&amp;quot;age&amp;quot;]]
    * p_response_inc[poststrat[&amp;quot;income&amp;quot;]]
    * p_response_state[poststrat[&amp;quot;state&amp;quot;]]
)

p_response_weighted = poststrat[&amp;quot;N&amp;quot;] * p_response / (poststrat[&amp;quot;N&amp;quot;] * p_response).sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now sample 1200 individuals from the entire population. This means we&amp;rsquo;re actually sampling rows from our &lt;code&gt;poststrat&lt;/code&gt; dataframe with different probabilities given by &lt;code&gt;p_response_weighted&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n = 1200
people = np.random.choice(
    np.arange(poststrat.shape[0]), size=n, replace=True, p=p_response_weighted
)
sample = poststrat.drop(&amp;quot;N&amp;quot;, axis=1).iloc[people].reset_index()
sample.sample(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;index&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;520&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;287&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2626&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;870&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;69&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1517&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;169&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4104&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now we&amp;rsquo;re getting to the thing we&amp;rsquo;ll actually measure in the sample (and then try to generalize to the population) - cat preference. Below are the coefficients of a regression model that determines the log-odds of cat preference, $\log\frac{P(\text{prefers cats})}{P(\text{prefers dogs})}$ for each group in the population. We&amp;rsquo;ll use these coefficients to compute the actual probability of cats preference for each group:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;coef_sex = np.array([0, -0.3])
coef_eth = np.array([0, 0.6, 0.9])
coef_age = np.array([0, -0.2, -0.3, 0.4, 0.5, 0.7, 0.8, 0.9])
coef_income = np.array([0, -0.2, 0.6])
coef_state = np.insert(np.random.normal(0, 1, 49).round(1), 0, 0)
coef_age_sex = np.vstack(
    [
        np.array([0, 0.1, 0.23, 0.3, 0.43, 0.5, 0.6]),
        np.array([0, -0.1, -0.23, -0.5, -0.43, -0.5, -0.6]),
    ]
).T
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;true_pop = poststrat.drop(&amp;quot;N&amp;quot;, axis=1)
true_pop[&amp;quot;cat_pref&amp;quot;] = inv_logit(
    coef_sex[true_pop[&amp;quot;sex&amp;quot;]]
    + coef_eth[true_pop[&amp;quot;eth&amp;quot;]]
    + coef_age[true_pop[&amp;quot;age&amp;quot;]]
    + coef_income[true_pop[&amp;quot;income&amp;quot;]]
    + coef_state[true_pop[&amp;quot;state&amp;quot;]]
    + coef_age_sex[true_pop[&amp;quot;age&amp;quot;], true_pop[&amp;quot;sex&amp;quot;]]
)
true_pop.sample(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cat_pref&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;6124&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.71095&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;177&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.549834&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;5755&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.331812&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2102&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.802184&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3931&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.524979&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We now use the computed probabilities to determine, for each individual in our sample, whether she&amp;rsquo;s a cats person or a dogs person. Note that this is still the fake data generation part; we&amp;rsquo;re not modelling anything yet.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sample[&amp;quot;cat_pref&amp;quot;] = np.random.binomial(n=1, p=true_pop[&amp;quot;cat_pref&amp;quot;][people], size=n)
sample.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;index&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cat_pref&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;671&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;906&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3062&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Just to get a glimpse of the problem Mr. P is trying to solve, the sample mean is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sample[&amp;quot;cat_pref&amp;quot;].mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.7083333333333334
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While the true mean in the population (which is a weighted sum of the per-group probabilities and the group sizes) is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;true_pop_pref = sum(true_pop[&amp;quot;cat_pref&amp;quot;] * poststrat[&amp;quot;N&amp;quot;]) / sum(poststrat[&amp;quot;N&amp;quot;])
true_pop_pref
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.5941253009200917
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So our sample overestimates cats-lovin&amp;rsquo; in the population by 18% - people who like cats also like taking surveys.&lt;/p&gt;

&lt;h2 id=&#34;visualizations&#34;&gt;Visualizations&lt;/h2&gt;

&lt;p&gt;To get a better understanding of the problem (unrepresentativeness of the sample), we&amp;rsquo;ll plot some summary statistics and see how they differ:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f, ax = plt.subplots(1, 4, figsize=(12, 3))

pd.DataFrame(
    dict(pop=pd.Series(p_age), sample=(sample.age.value_counts().sort_index() / n))
).plot(kind=&amp;quot;bar&amp;quot;, ax=ax[0], title=&amp;quot;age&amp;quot;)
pd.DataFrame(
    dict(pop=pd.Series(p_eth), sample=(sample.eth.value_counts().sort_index() / n))
).plot(kind=&amp;quot;bar&amp;quot;, ax=ax[1], legend=False, title=&amp;quot;ethnicity&amp;quot;)
pd.DataFrame(
    dict(
        pop=pd.Series(p_income), sample=(sample.income.value_counts().sort_index() / n)
    )
).plot(kind=&amp;quot;bar&amp;quot;, ax=ax[2], legend=False, title=&amp;quot;income&amp;quot;)
pd.DataFrame(
    dict(pop=pd.Series(p_sex), sample=(sample.sex.value_counts().sort_index() / n))
).plot(kind=&amp;quot;bar&amp;quot;, ax=ax[3], legend=False, title=&amp;quot;sex&amp;quot;)
plt.tight_layout()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_33_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At least by eyeballing the charts, the differences seem substantial; for example, if there&amp;rsquo;s a big difference in cats preference between males and females, we expect to see a substantial difference between the cats preference in the sample and in the population.&lt;/p&gt;

&lt;p&gt;We can also plot how cats preference changes between different groups &lt;em&gt;within&lt;/em&gt; our sample - for example, is there a difference in cats preference between different age groups? (yes there is)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f, axes = plt.subplots(1, 4, figsize=(12, 3), sharey=True)
for key, ax in zip([&amp;quot;age&amp;quot;, &amp;quot;eth&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;sex&amp;quot;], axes):
    sample.groupby(key)[&amp;quot;cat_pref&amp;quot;].agg(dict(mean=np.mean, std=sem)).reset_index().plot(
        kind=&amp;quot;bar&amp;quot;, x=key, y=&amp;quot;mean&amp;quot;, yerr=&amp;quot;std&amp;quot;, ax=ax, legend=False
    )
    plt.ylim(0, 1)
plt.tight_layout()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_36_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;the-model&#34;&gt;The model&lt;/h1&gt;

&lt;p&gt;We now turn to the MR part of MRP - the multilevel regression part. More specifically, we&amp;rsquo;ll build a Bayesian multilevel logistic regression model of cats preference. Even more specifically, we&amp;rsquo;ll build what&amp;rsquo;s called a &amp;ldquo;mixed
effects&amp;rdquo; model. Mixed effects models are one of those places that, at least for me, the statisticians terminology is &lt;em&gt;extremely&lt;/em&gt; confusing; it also seems to be inconsistent between different academic fields.  I usually find it easier to look at the actual model specification to understand what&amp;rsquo;s going on:&lt;/p&gt;

&lt;p&gt;For each group $j\in\left[1,&amp;hellip;,6300\right]$ we model the probability of cats preference as&lt;/p&gt;

&lt;p&gt;$$
\begin{align}
\theta_j &amp;amp; = logit^{-1}(
\alpha +
X_{j}\beta
+ \alpha_{\rm state[j]}^{\rm state}
+ \alpha_{\rm age[j]}^{\rm age}
+ \alpha_{\rm eth[j]}^{\rm eth}
+ \alpha_{\rm inc[j]}^{\rm inc}
) \\&lt;br /&gt;
\alpha_{\rm state[j]}^{\rm state} &amp;amp; \sim N(0,\sigma^{\rm state}) \\&lt;br /&gt;
\alpha_{\rm age[j]}^{\rm age} &amp;amp; \sim N(0,\sigma^{\rm age})\\&lt;br /&gt;
\alpha_{\rm eth[j]}^{\rm eth} &amp;amp; \sim N(0,\sigma^{\rm eth})\\&lt;br /&gt;
\alpha_{\rm inc[j]}^{\rm inc} &amp;amp;\sim N(0,\sigma^{\rm inc}) \\&lt;br /&gt;
\sigma^{\rm state} &amp;amp; \sim {\rm HalfNormal}(1) \\&lt;br /&gt;
\sigma^{\rm age} &amp;amp; \sim {\rm HalfNormal}(1) \\&lt;br /&gt;
\sigma^{\rm eth} &amp;amp; \sim {\rm HalfNormal}(1) \\&lt;br /&gt;
\sigma^{\rm income} &amp;amp; \sim {\rm HalfNormal}(1) \\&lt;br /&gt;
\beta &amp;amp; \sim N(0,2.5) \\&lt;br /&gt;
\alpha &amp;amp; \sim N(0,10) \\&lt;br /&gt;
\end{align}
$$&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve seen expressions like $\alpha_{\rm state[j]}^{\rm state}$ when we&amp;rsquo;ve implemented &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34; target=&#34;_blank&#34;&gt;varying intercepts models&lt;/a&gt;. What makes this a &amp;ldquo;mixed effects&amp;rdquo; models is that $\beta$ is the same $\beta$ for all groups, while the different $\alpha^*$-s vary between groups. I&amp;rsquo;m sure there are subtleties and nuances that this doesn&amp;rsquo;t capture, but for me this is a simple-to-read, simple-to-implement explanation of mixed effects models.&lt;/p&gt;

&lt;p&gt;As for the model itself:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$X$ is a (binary) design matrix that holds indicators for sex, age and sex-age interactions - we&amp;rsquo;ll construct it in a second.&lt;/li&gt;
&lt;li&gt;$\alpha$ is an intercept term.&lt;/li&gt;
&lt;li&gt;$\beta$ is a coefficient vector.&lt;/li&gt;
&lt;li&gt;The different $\alpha^*$-s are per-group varying intercepts.&lt;/li&gt;
&lt;li&gt;The different $\sigma^*$-s are hyperpriors for variation between groups.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The priors on $\alpha,\beta$ are rstanarm&amp;rsquo;s default priors; I couldn&amp;rsquo;t find rstanarm&amp;rsquo;s default prior on the $\sigma^*$ so I chose to use a halfnormal(1) prior.&lt;/p&gt;

&lt;p&gt;Our design matrix $X$ will represent a one-hot-encoded representation of the sampled individuals sex, age, and sex-age interaction term. Here&amp;rsquo;s how it looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;factors = pd.get_dummies(sample[[&amp;quot;sex&amp;quot;, &amp;quot;age&amp;quot;]].astype(&amp;quot;category&amp;quot;)).drop(
    [&amp;quot;sex_0&amp;quot;, &amp;quot;age_0&amp;quot;], axis=1
)
interactions = pd.DataFrame(
    factors.drop(&amp;quot;sex_1&amp;quot;, axis=1).values * factors[&amp;quot;sex_1&amp;quot;].values[:, None],
    columns=[f&amp;quot;sex_1*age_{i+1}&amp;quot; for i in range(6)],
)
features = pd.concat([factors, interactions], axis=1)
features.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_6&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_6&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;features.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(1200, 13)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make TF shape issues simpler, we convert it to a numpy array and transpose it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;features = features.values.T
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;imports-and-helper-functions-inference&#34;&gt;Imports and helper functions - inference&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow_probability import distributions as tfd
from tensorflow_probability import bijectors as tfb
import arviz as az
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n_chains = 4
dtype = tf.float32
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def step_size_setter_fn(pkr, new_step_size):
    return pkr._replace(
        inner_results=pkr.inner_results._replace(step_size=new_step_size)
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;factors = pd.get_dummies(sample[[&amp;quot;sex&amp;quot;, &amp;quot;age&amp;quot;]].astype(&amp;quot;category&amp;quot;)).drop(
    [&amp;quot;sex_0&amp;quot;, &amp;quot;age_0&amp;quot;], axis=1
)
interactions = pd.DataFrame(
    factors.drop(&amp;quot;sex_1&amp;quot;, axis=1).values * factors[&amp;quot;sex_1&amp;quot;].values[:, None],
    columns=[f&amp;quot;sex_1*age_{i}&amp;quot; for i in range(6)],
)
features = pd.concat([factors, interactions], axis=1).values.T
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def trace_fn(current_samp, pkr):

    return (
        pkr.inner_results.inner_results.target_log_prob,
        pkr.inner_results.inner_results.leapfrogs_taken,
        pkr.inner_results.inner_results.has_divergence,
        pkr.inner_results.inner_results.energy,
        pkr.inner_results.inner_results.log_accept_ratio,
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@tf.function(experimental_compile=True)
def run_nuts(target_log_prob_fn, initial_states, bijectors_list):
    step_sizes = [1e-2 * tf.ones_like(i) for i in initial_states]
    kernel = tfp.mcmc.TransformedTransitionKernel(
        tfp.mcmc.nuts.NoUTurnSampler(target_log_prob_fn, step_size=step_sizes),
        bijector=bijectors_list,
    )

    kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(
        kernel,
        target_accept_prob=tf.cast(0.8, dtype=dtype),
        num_adaptation_steps=800,
        step_size_setter_fn=step_size_setter_fn,
        step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,
        log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio,
    )

    # Sampling from the chain.
    mcmc_trace, pkr = tfp.mcmc.sample_chain(
        num_results=1000,
        num_burnin_steps=1000,
        current_state=[
            bijector.forward(state)
            for bijector, state in zip(bijectors_list, initial_states)
        ],
        kernel=kernel,
        trace_fn=trace_fn,
    )

    return mcmc_trace, pkr
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# using pymc3 naming conventions, with log_likelihood instead of lp so that ArviZ can compute loo and waic
sample_stats_name = [
    &amp;quot;log_likelihood&amp;quot;,
    &amp;quot;tree_size&amp;quot;,
    &amp;quot;diverging&amp;quot;,
    &amp;quot;energy&amp;quot;,
    &amp;quot;mean_tree_accept&amp;quot;,
]


def tfp_trace_to_arviz(tfp_trace, var_names=None, sample_stats_name=sample_stats_name):

    samps, trace = tfp_trace
    if var_names is None:
        var_names = [&amp;quot;var &amp;quot; + str(x) for x in range(len(samps))]

    sample_stats = {k: v.numpy().T for k, v in zip(sample_stats_name, trace)}
    posterior = {
        name: tf.transpose(samp, [1, 0, 2]).numpy()
        for name, samp in zip(var_names, samps)
    }
    return az.from_dict(posterior=posterior, sample_stats=sample_stats)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For more details about calling TFP&amp;rsquo;s NUTS sampler, and the helper functions defined above, see &lt;a href=&#34;https://adamhaber.github.io/2019/10/21/Bayesian-golf-puttings,-NUTS,-and-optimizing-your-sampling-function-with-TensorFlow-Probability.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;first-implemetation&#34;&gt;First implemetation&lt;/h2&gt;

&lt;p&gt;We now turn to implement the whole model in TFP. Since there aren&amp;rsquo;t many complicated intermediate calculations, a &lt;code&gt;JointDistributionSequential&lt;/code&gt; is a reasonable choice for implementing the model. For a more detailed explanation on the different &lt;code&gt;JointDistribution&lt;/code&gt; alternatives, see &lt;a href=&#34;https://adamhaber.github.io/2019/10/21/Bayesian-golf-puttings,-NUTS,-and-optimizing-your-sampling-function-with-TensorFlow-Probability.html#model-1&#34; target=&#34;_blank&#34;&gt;this post&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = tfd.JointDistributionSequential(
    [
        tfd.HalfNormal(1),  # sigma_state
        lambda sigma_state: tfd.Sample(tfd.Normal(0, sigma_state), sample_shape=50),
        tfd.HalfNormal(1),  # sigma_eth
        lambda sigma_eth: tfd.Sample(tfd.Normal(0, sigma_eth), sample_shape=3),
        tfd.HalfNormal(1),  # sigma_income
        lambda sigma_income: tfd.Sample(tfd.Normal(0, sigma_income), sample_shape=3),
        tfd.HalfNormal(1),  # sigma_age
        lambda sigma_age: tfd.Sample(tfd.Normal(0, sigma_age), sample_shape=7),
        tfd.Normal(0, 10),  # intercept
        tfd.Sample(tfd.Normal(0, 2.5), sample_shape=13),  # coeffs
        lambda coeffs, intercept, coef_age, sigma_age, coef_income, sigma_income, coef_eth, sigma_eth, coef_state: tfd.Independent(
            tfd.Binomial(
                total_count=1,
                logits=intercept[:, tf.newaxis]
                + coeffs @ tf.cast(features, tf.float32)
                + tf.squeeze(
                    tf.gather(coef_age, tf.cast(sample[&amp;quot;age&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_income, tf.cast(sample[&amp;quot;income&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_eth, tf.cast(sample[&amp;quot;eth&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_state, tf.cast(sample[&amp;quot;state&amp;quot;], tf.int32), axis=-1)
                ),
            ),
            reinterpreted_batch_ndims=1,
        ),
    ]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The model description isn&amp;rsquo;t short, but it doesn&amp;rsquo;t contain anything we haven&amp;rsquo;t covered in previous posts. Let&amp;rsquo;s call &lt;code&gt;.sample&lt;/code&gt; and &lt;code&gt;.log_prob&lt;/code&gt; just to make sure everything works:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[s.shape for s in model.sample(n_chains)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[TensorShape([4]),
 TensorShape([4, 50]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 7]),
 TensorShape([4]),
 TensorShape([4, 13]),
 TensorShape([4, 1200])]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.log_prob(model.sample(n_chains))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-121.06135 ,   21.950146,  -69.38415 , -224.08742 ], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So our model technically works&amp;hellip; but does it makes sense?&lt;/p&gt;

&lt;h2 id=&#34;prior-predictive-checks&#34;&gt;Prior predictive checks&lt;/h2&gt;

&lt;p&gt;Prior predictive checks are an extremely valuable technique to assess your model and your priors, before seeing any data. To learn more about PPCs (horrible acronym as the first P can also stand for &lt;em&gt;posterior&lt;/em&gt;), I highly recommend Michael Betancourt&amp;rsquo;s &lt;a href=&#34;https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html&#34; target=&#34;_blank&#34;&gt;principled bayesian workflow&lt;/a&gt; case study.&lt;/p&gt;

&lt;p&gt;Anyway, let&amp;rsquo;s generate samples from our model, and use the samples to compute the logits (the linear expression within the &lt;code&gt;inv_logit&lt;/code&gt; function):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inits = model.sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state = inits[1:10][
    ::-1
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;logits = (
    intercept[:, tf.newaxis]
    + coeffs @ tf.cast(features, tf.float32)
    + tf.squeeze(tf.gather(coef_age, tf.cast(sample[&amp;quot;age&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_income, tf.cast(sample[&amp;quot;income&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_eth, tf.cast(sample[&amp;quot;eth&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_state, tf.cast(sample[&amp;quot;state&amp;quot;], tf.int32), axis=-1))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each chain gives us 1200 different numbers - the log-odds for cat preference for our 1200 sampled individuals. Let&amp;rsquo;s plot these four histograms:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i, l in enumerate(logits):
    sns.distplot(l, bins=30, label=f&amp;quot;from chain {i}&amp;quot;)
plt.legend()
plt.xlabel(&amp;quot;${\\rm logit}\\left(\\theta_j\\right)$&amp;quot;)
lim = plt.xlim();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_67_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that it&amp;rsquo;s OK that each color (each chain) is multimodal - this just means that we&amp;rsquo;re inferring different &amp;ldquo;types&amp;rdquo; of cats preference across groups.&lt;/p&gt;

&lt;p&gt;The problem with what we got is the &lt;em&gt;scale&lt;/em&gt; - having ${\rm logit}\left(\theta_j\right)=-15$ means $\theta_j=0.000000003&amp;hellip;$ which doesn&amp;rsquo;t really makes sense, even for a group that &lt;em&gt;really&lt;/em&gt; likes dogs. This implies that our priors are way too diffuse, the normal(0,10) being the primary suspect. So let&amp;rsquo;s make everything normal(0,1) and do this again:&lt;/p&gt;

&lt;h1 id=&#34;same-likelihood-better-priors&#34;&gt;Same likelihood, better priors&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = tfd.JointDistributionSequential(
    [
        tfd.HalfNormal(1),  # sigma_state
        lambda sigma_state: tfd.Sample(tfd.Normal(0, sigma_state), sample_shape=50),
        tfd.HalfNormal(1),  # sigma_eth
        lambda sigma_eth: tfd.Sample(tfd.Normal(0, sigma_eth), sample_shape=3),
        tfd.HalfNormal(1),  # sigma_income
        lambda sigma_income: tfd.Sample(tfd.Normal(0, sigma_income), sample_shape=3),
        tfd.HalfNormal(1),  # sigma_age
        lambda sigma_age: tfd.Sample(tfd.Normal(0, sigma_age), sample_shape=7),
        tfd.Normal(0, 1),  # intercept
        tfd.Sample(tfd.Normal(0, 1), sample_shape=13),  # coeffs
        lambda coeffs, intercept, coef_age, a, coef_income, b, coef_eth, c, coef_state: tfd.Independent(
            tfd.Binomial(
                total_count=1,
                logits=intercept[:, tf.newaxis]
                + coeffs @ tf.cast(features, tf.float32)
                + tf.squeeze(
                    tf.gather(coef_age, tf.cast(sample[&amp;quot;age&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_income, tf.cast(sample[&amp;quot;income&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_eth, tf.cast(sample[&amp;quot;eth&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_state, tf.cast(sample[&amp;quot;state&amp;quot;], tf.int32), axis=-1)
                ),
            ),
            reinterpreted_batch_ndims=1,
        ),
    ]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inits = model.sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state = inits[1:10][
    ::-1
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;logits = (
    intercept[:, tf.newaxis]
    + coeffs @ tf.cast(features, tf.float32)
    + tf.squeeze(tf.gather(coef_age, tf.cast(sample[&amp;quot;age&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_income, tf.cast(sample[&amp;quot;income&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_eth, tf.cast(sample[&amp;quot;eth&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_state, tf.cast(sample[&amp;quot;state&amp;quot;], tf.int32), axis=-1))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i, l in enumerate(logits):
    sns.distplot(l, bins=30, label=f&amp;quot;from chain {i}&amp;quot;)
plt.legend()
plt.xlabel(&amp;quot;${\\rm logit}\\left(\\theta_j\\right)$&amp;quot;)
plt.xlim(*lim);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_74_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This makes much more sense. The variance between groups is still there but it doesn&amp;rsquo;t spread across several order of magnitude (that is, with this prior it&amp;rsquo;s no longer plausible that some groups love cats 10 million times more than other groups). This seems like a good starting point.&lt;/p&gt;

&lt;p&gt;Note that the overly wide priors are also very problematic, inference wise - running the same notebook with the first model returns all sorts of sampling problems (divergent transitions, bad mixing, random seed dependence etc) while the 2nd, more informed version does not.&lt;/p&gt;

&lt;h2 id=&#34;getting-the-shapes-right&#34;&gt;Getting the shapes right&lt;/h2&gt;

&lt;p&gt;This is, by far, the hardest thing for me when building a probablistic model with TFP. Knowing where to put &lt;code&gt;[...,],  tf.newaxis&lt;/code&gt; or &lt;code&gt;[None,]&lt;/code&gt; requires some trial and error - here are some checks to verify we got this right (after &lt;em&gt;a lot&lt;/em&gt; of failed attempts and some help from Junpeng Lao):&lt;/p&gt;

&lt;p&gt;First, we want to make sure the model can evaluate the log probability of its own samples, and that we get &lt;code&gt;n_chains&lt;/code&gt; different numbers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.log_prob(inits)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-619.5229 , -520.8101 , -460.97076, -609.21765], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Second, we want to make sure that all shapes of the different parameters in our samples are as we expect, which basically should be the number of chains in the first axis and the shape of whatever it is we&amp;rsquo;re sampling in the rest - or nothing, if it&amp;rsquo;s just a scalar:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[s.shape for s in inits]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[TensorShape([4]),
 TensorShape([4, 50]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 7]),
 TensorShape([4]),
 TensorShape([4, 13]),
 TensorShape([4, 1200])]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main thing to look out for here are redundant extra dimensions (for example, &lt;code&gt;TensorShape([4, 1])&lt;/code&gt; instead of &lt;code&gt;TensorShape([4])&lt;/code&gt; - these will almost always cause broadcasting issues.&lt;/p&gt;

&lt;p&gt;Next, we want to add an extra axis for the data we condition on. Again, this is for broadcasting purposes - we want to make sure &lt;code&gt;tf&lt;/code&gt; &amp;ldquo;replicates&amp;rdquo; the data across different chains.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tf.cast(sample[&amp;quot;cat_pref&amp;quot;], tf.float32)[tf.newaxis, ...].shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;TensorShape([1, 1200])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, the &lt;code&gt;log_prob&lt;/code&gt; function closure - we want to make sure our &lt;code&gt;log_prob&lt;/code&gt; function gets as inputs all the different parameters, concatenates them with the data we&amp;rsquo;re conditioning on, and then uses the original model &lt;code&gt;log_prob&lt;/code&gt; function to evaluate; practically, we want to verify that if we pass all the parameters (&lt;em&gt;without&lt;/em&gt; the conditioning data), we get &lt;code&gt;n_chains&lt;/code&gt; different numbers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;lp = lambda *x: model.log_prob(
    list(x) + [tf.cast(sample[&amp;quot;cat_pref&amp;quot;], tf.float32)[tf.newaxis, ...]]
)
lp(*inits[:-1])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1315.5156, -1436.2715, -1799.2578, -1901.1874], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;inference&#34;&gt;Inference&lt;/h2&gt;

&lt;p&gt;With sensible priors and TFP shape issues dealt with, we can proceed with actually runnning the sampler.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inits = [
    tf.random.uniform(s.shape, -2, 2, tf.float32, name=&amp;quot;initializer&amp;quot;) for s in inits
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace, kr = run_nuts(
    lp,
    inits[:-1],
    bijectors_list=[
        tfb.Exp(),
        tfb.Identity(),
        tfb.Exp(),
        tfb.Identity(),
        tfb.Exp(),
        tfb.Identity(),
        tfb.Exp(),
        tfb.Identity(),
        tfb.Identity(),
        tfb.Identity(),
    ],
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Always&lt;/em&gt; check your TF shapes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[s.shape for s in trace]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[TensorShape([1000, 4]),
 TensorShape([1000, 4, 50]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 3]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 3]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 7]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 13])]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This looks good; for arviz intergration purposes, we&amp;rsquo;ll add an extra axis for the parameters whose tensor shape is &lt;code&gt;TensorShape([1000, 4])&lt;/code&gt;, and then call our &lt;code&gt;tfp_trace_to_arviz&lt;/code&gt; helper function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace_ex = [s[..., tf.newaxis] if len(s.shape) == 2 else s for s in trace]
az_trace = tfp_trace_to_arviz((trace_ex, kr))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;az.summary(az_trace).head(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hpd_3%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hpd_97%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mcse_mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mcse_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_bulk&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_tail&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r_hat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 0[0]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.056&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.153&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.779&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.338&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1771&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1806&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2668&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[0]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.016&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.607&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.173&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.155&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.011&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.009&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2822&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2235&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2843&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2538&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[1]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.025&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.505&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.997&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.927&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3978&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4013&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2918&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[2]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.477&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.463&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.362&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.38&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.007&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4207&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2794&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4232&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2521&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[3]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.764&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.896&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.017&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.013&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2102&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1745&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2132&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1908&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Sampling diagnostics look good; we have no divergent transitions, and $\hat{R}$ values are all close to 1:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;az.summary(az_trace)[&amp;quot;r_hat&amp;quot;].describe()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;count    81.0
mean      1.0
std       0.0
min       1.0
25%       1.0
50%       1.0
75%       1.0
max       1.0
Name: r_hat, dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We won&amp;rsquo;t go down the model-diagnostics-rabbit-hole now; we&amp;rsquo;re here to learn about Mister P.&lt;/p&gt;

&lt;h2 id=&#34;p-part&#34;&gt;P part&lt;/h2&gt;

&lt;p&gt;So far we&amp;rsquo;ve defined, critisized and fitted a multilevel logisitic regression model. Now comes the poststratification part. Poststratification is a technical and intimidating word; it basically means &amp;ldquo;adjusting the inferences from my sample to the population by using additional knowledge about proportions in the population&amp;rdquo;. To do so, we&amp;rsquo;ll:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Compute a design matrix $X$ for the population.&lt;/li&gt;
&lt;li&gt;Use our 4000 sampled parameters to compute 4000 different logits for each group in the population. This will yield a 4000x6300 matrix.&lt;/li&gt;
&lt;li&gt;For each row (representing a single draw from our posterior), we&amp;rsquo;ll compute the population mean as a weighted sum of per-group cat preference and group&amp;rsquo;s size. This will give us a vector of 4000 numbers.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The mean of these 4000 numbers will be our estimate for the population mean.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;post_factors = pd.get_dummies(poststrat[[&amp;quot;sex&amp;quot;, &amp;quot;age&amp;quot;]].astype(&amp;quot;category&amp;quot;)).drop(
[&amp;quot;sex_0&amp;quot;, &amp;quot;age_0&amp;quot;], axis=1
)
post_interactions = pd.DataFrame(
post_factors.drop(&amp;quot;sex_1&amp;quot;, axis=1).values * post_factors[&amp;quot;sex_1&amp;quot;].values[:, None],
columns=[f&amp;quot;sex_1*age_{i}&amp;quot; for i in range(6)],
)
post_features = pd.concat([post_factors, post_interactions], axis=1).values.T
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;intercept = trace[8]
coeffs = trace[9]
coef_age = trace[7]
coef_income = trace[5]
coef_eth = trace[3]
coef_state = trace[1]

logits = (
intercept[..., tf.newaxis]
+ coeffs @ tf.cast(post_features, tf.float32)
+ tf.gather(trace[7], tf.cast(poststrat[&amp;quot;age&amp;quot;], tf.int32), axis=-1)
+ tf.gather(coef_income, tf.cast(poststrat[&amp;quot;income&amp;quot;], tf.int32), axis=-1)
+ tf.gather(coef_eth, tf.cast(poststrat[&amp;quot;eth&amp;quot;], tf.int32), axis=-1)
+ tf.gather(coef_state, tf.cast(poststrat[&amp;quot;state&amp;quot;], tf.int32), axis=-1)
)
posterior_prob = inv_logit(logits)
posterior_prob = posterior_prob.reshape(-1, 6300)
posterior_prob.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(4000, 6300)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;poststrat_prob = posterior_prob @ poststrat[&amp;quot;N&amp;quot;][:, None] / poststrat[&amp;quot;N&amp;quot;].sum()
poststrat_prob.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(4000, 1)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So how good is MRP? We plot the histogram of our 4000 different estimates of the population mean, together with the estimate from the sample (dashed line) and the true mean:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sns.distplot(poststrat_prob, bins=100)
plt.axvline(true_pop_pref, label=&amp;quot;population mean&amp;quot;, lw=3, c=&amp;quot;k&amp;quot;)
plt.axvline(sample[&amp;quot;cat_pref&amp;quot;].mean(), label=&amp;quot;sample mean&amp;quot;, lw=3, ls=&amp;quot;--&amp;quot;, c=&amp;quot;k&amp;quot;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_106_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can see that the posterior mean is much closer to the true mean - so MRP definitely helps!&lt;/p&gt;

&lt;h1 id=&#34;estimates-for-states&#34;&gt;Estimates for states&lt;/h1&gt;

&lt;p&gt;The nice thing about having a model is that we can use it to answer all sorts of different questions. For example, we can repeat the analysis we just did and estimate per-state means. We&amp;rsquo;re still computing the design matrix, logits etc as before but we&amp;rsquo;re constraining ourselves to one state at a time. For each state, we&amp;rsquo;ll compute the model&amp;rsquo;s mean and standard deviations, together with the true mean and the sample mean:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;state_data = namedtuple(
    &amp;quot;state_data&amp;quot;,
    [
        &amp;quot;state&amp;quot;,
        &amp;quot;model_state_sd&amp;quot;,
        &amp;quot;model_state_pref&amp;quot;,
        &amp;quot;sample_state_pref&amp;quot;,
        &amp;quot;true_state_pref&amp;quot;,
        &amp;quot;N&amp;quot;,
    ],
)
states_data = []

for i in range(50):
    state_features = np.squeeze(post_features[:, np.where(poststrat.state == i)])
    state_poststrat = poststrat.query(f&amp;quot;state=={i}&amp;quot;)
    logits = (
        intercept[..., tf.newaxis]
        + coeffs @ tf.cast(state_features, tf.float32)
        + tf.gather(
            trace[7],
            tf.cast(state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;age&amp;quot;], tf.int32),
            axis=-1,
        )
        + tf.gather(
            coef_income,
            tf.cast(state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;income&amp;quot;], tf.int32),
            axis=-1,
        )
        + tf.gather(
            coef_eth,
            tf.cast(state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;eth&amp;quot;], tf.int32),
            axis=-1,
        )
        + tf.gather(
            coef_state,
            tf.cast(state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;state&amp;quot;], tf.int32),
            axis=-1,
        )
    )
    posterior_prob = inv_logit(logits)
    posterior_prob = posterior_prob.reshape(-1, state_features.shape[1])
    state_poststrat_prob = (
        posterior_prob
        @ state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;N&amp;quot;][:, None]
        / state_poststrat[&amp;quot;N&amp;quot;].sum()
    )
    states_data.append(
        state_data(
            i,
            state_poststrat_prob.std(),
            state_poststrat_prob.mean(),
            sample.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;cat_pref&amp;quot;].mean(),
            np.sum(true_pop.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;cat_pref&amp;quot;] * state_poststrat[&amp;quot;N&amp;quot;])
            / np.sum(state_poststrat[&amp;quot;N&amp;quot;]),
            sample.query(f&amp;quot;state=={i}&amp;quot;).shape[0],
        )
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;state_df = pd.DataFrame(states_data)
state_df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;model_state_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;model_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sample_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;true_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;N&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.116844&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.580393&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.596565&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0956771&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.583293&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.658961&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0817888&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.669766&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.823529&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.69817&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.145332&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.505946&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.553341&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0768275&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.493726&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.611111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.443913&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Graphically, this is how this looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f, ax = plt.subplots(figsize=(6, 6))
state_df.plot(
    x=&amp;quot;true_state_pref&amp;quot;,
    y=&amp;quot;model_state_pref&amp;quot;,
    yerr=&amp;quot;model_state_sd&amp;quot;,
    ax=ax,
    kind=&amp;quot;scatter&amp;quot;,
    label=&amp;quot;Model&amp;quot;,
)
state_df.plot(
    x=&amp;quot;true_state_pref&amp;quot;,
    y=&amp;quot;sample_state_pref&amp;quot;,
    ax=ax,
    kind=&amp;quot;scatter&amp;quot;,
    c=&amp;quot;C1&amp;quot;,
    label=&amp;quot;Sample&amp;quot;,
)
ax.plot([0, 1], [0, 1], c=&amp;quot;k&amp;quot;)
f.tight_layout()
plt.ylabel(&amp;quot;Cat preference&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_113_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that the model predictions of state-wise preferences (blue dots) are closer to the identity line compared to the orange dots (sample per-state mean preferences).&lt;/p&gt;

&lt;p&gt;Another interesting thing to see is how the model uncertainty (quantified by the standard deviation of the model predictions, per state) is related to sample size; we can see that the model is more confident (lower std) for states with higher N, which is what we would expect:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.scatter(state_df[&amp;quot;N&amp;quot;], state_df[&amp;quot;model_state_sd&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_116_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;summary-and-further-reading&#34;&gt;Summary and further reading&lt;/h1&gt;

&lt;p&gt;This post was a code-oriented introduction to MRP, which is a very interesting technique that nicely leverages the built in advantages of multilevel models. We&amp;rsquo;ve also seen how taking a package&amp;rsquo;s priors for granted is not always a good idea, and how prior predictive checks can help us calibrate our priors and our beliefs.&lt;/p&gt;

&lt;p&gt;In case you want to learn more, other than Lauren and Jonah&amp;rsquo;s vignette, these are all excellent reads:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Austin Rochford&amp;rsquo;s &lt;a href=&#34;https://austinrochford.com/posts/2017-07-09-mrpymc3.html&#34; target=&#34;_blank&#34;&gt;MRPyMC3&lt;/a&gt; tutorial&lt;/li&gt;
&lt;li&gt;Andrew Gelman&amp;rsquo;s post about Mister P&amp;rsquo;s &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2013/10/09/mister-p-whats-its-secret-sauce/&#34; target=&#34;_blank&#34;&gt;secret sauce&lt;/a&gt;. Somewhat more technical and perhaps more political-science specific, but still interesting and relevant.&lt;/li&gt;
&lt;li&gt;Dan Simpson&amp;rsquo;s post on &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2019/08/22/multilevel-structured-regression-and-post-stratification/&#34; target=&#34;_blank&#34;&gt;structured priors&lt;/a&gt; for MRP; this is somewhat more advanced, but Dan&amp;rsquo;s posts are always fun to read.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Varying Slopes Models and the CholeskyLKJ distribution in TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/varying-slopes/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/varying-slopes/</guid>
      <description>

&lt;h4 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h4&gt;

&lt;p&gt;Covariance matrices allow us to capture parameter correlations in multivariate hierarchical models; sampling these using Hamiltonian Monte Carlo in Tensorflow Probability can be tricky and confusing; this post is about some of the math involved and how to get this right.&lt;/p&gt;

&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;

&lt;p&gt;Hierarchical models allow us to account for variations between different groups in our data. Let&amp;rsquo;s say that, for some reason, we have &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34; target=&#34;_blank&#34;&gt;different groups of tadpoles&lt;/a&gt; in different tanks and we want to model per-tank survival rates. Varying intercepts models allow us to fit different models to different tanks, while pooling together information &lt;em&gt;between&lt;/em&gt; tanks. The tanks are somewhat different (they&amp;rsquo;re not the same tank), so we allow their parameters to vary; but they&amp;rsquo;re also similar (they&amp;rsquo;re all tanks with tadpoles, not oranges or ships), so we can do some &amp;ldquo;transfer learning&amp;rdquo; between tanks.&lt;/p&gt;

&lt;p&gt;Varying &lt;em&gt;intercepts&lt;/em&gt; are already very powerful models. However, in many (most?) situations, the models we fit have more than just an intercept. Let&amp;rsquo;s say we have 3 groups in our data, and we want to fit a simple linear model for each group, but also to share information between groups. Each model has two parameters (a slope and an intercept), and we allow these to &lt;em&gt;vary&lt;/em&gt;. We can also allow them to &lt;em&gt;covary&lt;/em&gt;. For example, if higher slopes usually go with lower intercepts, we want to know that, and use that to improve our estimation of both.&lt;/p&gt;

&lt;p&gt;To capture this covariance amongst parameters, we&amp;rsquo;re going to need a covariance matrix.&lt;/p&gt;

&lt;h1 id=&#34;the-lkj-prior&#34;&gt;The LKJ prior&lt;/h1&gt;

&lt;p&gt;Every 2x2 covariance matrix can be decomposed as a product of a diagonal matrix of standard deviations $\sigma_\alpha,\sigma_\beta$ with a correlation matrix $\Sigma$, in the following form (same holds for higher dimensions):&lt;/p&gt;

&lt;p&gt;$$\mathbb{S} = \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right) \cdot \Sigma \cdot \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right)$$&lt;/p&gt;

&lt;p&gt;The decomposition is conceptually useful - it&amp;rsquo;s usually easier to think about the variances (which are single-parameter properties, and depend on things like unit of measurement and typical scale) separately from the correlation structure (a pairwise property). Technically, putting a prior on the variances isn&amp;rsquo;t very hard - we just need to make sure the variables are non-negative.&lt;/p&gt;

&lt;p&gt;A priori, it&amp;rsquo;s not obvious how to put a prior on correlation matrices. We can&amp;rsquo;t sample each matrix element by itself; correlation matrices have to be postitive definite, so their elements are somewhat &amp;ldquo;entangled&amp;rdquo; - the value in the $\left[i,j\right]$-th entry effects the element in the $\left[k,l\right]$-th entry. Luckily for us, in 2009, Lewandowski, Kurowicka, and Joe &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0047259X09000876&#34; target=&#34;_blank&#34;&gt;published&lt;/a&gt; a method for generating random correlation matrices, aptly referred to as the LKJ distribution. Like other probablistic programming languages, TFP implements the LKJ distribution. It&amp;rsquo;s a distribution that gets two numbers as inputs - $N$, the dimension of the correlation matrix, and $\eta$, a concentration parameter that controls how plausible are large correlations; Larger $\eta$ mean correlations are more concentrated around zero &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# the necessary imports
import tensorflow as tf
import tensorflow_probability as tfp
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt 
import numpy as np
from matplotlib.patches import Ellipse
from tensorflow_probability import distributions as tfd
from tensorflow_probability import bijectors as tfb
tf.compat.v1.enable_eager_execution()

# for plotting
sns.set_palette(&amp;quot;muted&amp;quot;)

# for reproducibility
np.random.seed(324)
tf.random.set_random_seed(234)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s how samples from different LKJ distributions look like. We sample 500 correltion matrices with $\eta=1$ and 500 matrices with $\eta=50$:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.hist(tfd.LKJ(5,1).sample(500).numpy().flatten(), bins=np.linspace(-0.99,0.99), density=True, label=&amp;quot;$\eta=1$&amp;quot;)
plt.hist(tfd.LKJ(5,50).sample(500).numpy().flatten(), bins=np.linspace(-0.99,0.99), density=True, label=&amp;quot;$\eta=50$&amp;quot;)
plt.xlabel(&amp;quot;Correlation values&amp;quot;)
plt.title(&amp;quot;500 5x5 correlation matrices&amp;quot;)
plt.legend()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;problem-1-falling-off-the-manifold&#34;&gt;Problem #1 - falling off the manifold&lt;/h2&gt;

&lt;p&gt;So far so good - sampling correlation matrices seems straightforward. The problem starts when we want to use a Hamiltonian Monte Carlo (and we usually want to use Hamiltonian Monte Carlo) to sample from some larger model that contains an LKJ distribution. HMC allows us to generate samples from arbitrary joint distributions, not only from distributions for which we have explicit sampling methods. Here&amp;rsquo;s a toy example to illustrate the problem. The model is simply a single LKJ distribution within a &lt;code&gt;JointDistributionSequential&lt;/code&gt; object:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model =  tfd.JointDistributionSequential(
    [
        tfd.LKJ(2,2),
    ]
)
model.sample()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[&amp;lt;tf.Tensor: id=7897612, shape=(2, 2), dtype=float32, numpy=
 array([[ 1.        , -0.43337458],
        [-0.43337458,  1.        ]], dtype=float32)&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;model.sample()&lt;/code&gt; seems to work, so that&amp;rsquo;s encouraging. However, when we try to &amp;ldquo;naively&amp;rdquo; use an HMC sampler to generate samples from the model, things go wrong. We add a small helper function to avoid rewriting all the kernels everytime; see the &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt; for explanations about the different function calls here.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def sampleHMC(log_prob, inits, bijectors_list = None):
    inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(
        target_log_prob_fn=log_prob,
        step_size=0.1,
        num_leapfrog_steps=3
    )
    if bijectors_list is not None:
        inner_kernel = tfp.mcmc.TransformedTransitionKernel(inner_kernel, bijectors_list)
        
    adaptive_kernel = tfp.mcmc.SimpleStepSizeAdaptation(
        inner_kernel=inner_kernel,
        num_adaptation_steps=400
    )
    return tfp.mcmc.sample_chain(
        num_results=500,
        current_state=inits,
        kernel=adaptive_kernel,
        num_burnin_steps=500,
        trace_fn=None
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;lkj_samps = sampleHMC(
    log_prob=lambda lkj: model.log_prob([lkj]),
    inits=model.sample()
)[0]
lkj_samps[:3]  # we print the first 3 samples 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=8349304, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 28.062887,  81.77511 ],
        [-80.5103  , -68.75983 ]],

       [[ 65.458626,  72.01995 ],
        [-87.03769 , -59.71089 ]],

       [[104.11292 ,  85.66264 ],
        [-83.73789 , -60.2727  ]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we can already see the problem; these aren&amp;rsquo;t correlation matrices by any means. What&amp;rsquo;s happening here is that HMC, which operates in an unconstrained space of real numbers, &amp;ldquo;falls off&amp;rdquo; the correlation matrices manifold. The solution for this is what&amp;rsquo;s called a &lt;strong&gt;bijector&lt;/strong&gt;. Without getting into the gory mathematical details &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, a bijector can be thought of as a differentiable one-to-one mapping between the unconstrained space in which the HMC trajectories live, and the constrained manifold. HMC produces samples in the unconstrained space, and the appropriate bijector spits out a valid correlation matrix. For us, this bijector is &lt;code&gt;tfb.CorrelationCholesky()&lt;/code&gt;. Note that we need to pass a list of bijectors to the &lt;code&gt;TransformedTransitionKernel&lt;/code&gt; constructor; in this case, we&amp;rsquo;re passing just a single bijector:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;bij_lkj_samps = sampleHMC(
    log_prob=lambda lkj: model.log_prob([lkj]),
    inits=model.sample(),
    bijectors_list=[tfb.CorrelationCholesky()]
)[0]
bij_lkj_samps[:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=9873388, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 1.        ,  0.        ],
        [-0.43139905,  0.90216124]],

       [[ 1.        ,  0.        ],
        [-0.43139905,  0.90216124]],

       [[ 1.        ,  0.        ],
        [-0.43139905,  0.90216124]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At first glance, these don&amp;rsquo;t look like correlation matrices either; that&amp;rsquo;s because they&amp;rsquo;re the &lt;em&gt;Cholesky factors&lt;/em&gt; of kosher correlation matrices.&lt;/p&gt;

&lt;h2 id=&#34;overthinking-box-cholesky-factors-3&#34;&gt;Overthinking box - Cholesky factors &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;

&lt;p&gt;Every correlation matrix $\Sigma$ can be decomposed as a product of a lower triangular matrix $L$ and its transpose $L^T$. More formally, a lower triangular matrix $L$ is the Cholesky factor of some correlation matrix $\Sigma$ if and only if its diagonal elements are strictly positive and each of its rows has unit norm.&lt;/p&gt;

&lt;p&gt;Cholesky factors come up in many different places in statistics, machine learning, metric learning, computational linear algebra, etc. In the context of Monte Carlo simulations, Cholesky factors are used to generate correlated quantities (which we often want) from uncorrelated samples (which are easy to generate in the computer): If $z$ is a matrix of uncorrelated normally distributed numbers, and $L$ is the Cholesky factor of some correlation matrix $\Sigma$, then $Lz$ would have the correlation structure described by $\Sigma$.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a simple demonstration. We generate 1000 samples from a bivariate guassian with zero mean, unit variance and no correlation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;z = tf.transpose(tfd.MultivariateNormalDiag(loc=[0,0], scale_diag=[1,1]).sample(1000))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now define a correlation matrix between two variables with correlation -0.85. We compute its Cholesky factor, multiply it with the original (uncorrelated) data, and voila:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;M = tf.constant([[1,-0.85],[-0.85,1]])
L = tf.cholesky(M)
Lz = L@z
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.scatter(z[0], z[1], label=&amp;quot;$z$&amp;quot;)
plt.scatter(Lz[0], Lz[1], label=&amp;quot;$Lz$&amp;quot;)
plt.legend(loc=&#39;upper right&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that the two components of $Lz$ are negatively correlated, as expected. More quantitatively, here&amp;rsquo;s the correlation matrix for the cholesky-tranformed data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tfp.stats.correlation(tf.transpose(Lz))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=9873636, shape=(2, 2), dtype=float32, numpy=
array([[ 0.9999995 , -0.8532509 ],
       [-0.8532509 ,  0.99999976]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;problem-2-the-wrong-log-prob&#34;&gt;Problem #2 - the wrong log_prob&lt;/h2&gt;

&lt;p&gt;So the bijector solves the constrained-unconstrained problem, and HMC can run smoothly. But things are trickier than that (and the sampler won&amp;rsquo;t tell you that). The HMC sampler works with the log probability function of the model. If we have an LKJ distribution somewhere in our model, than for every sample, HMC computes the &lt;code&gt;log_prob&lt;/code&gt; of the correlation matrix according to LKJ. But LKJ is a distribution over correlation matrices, not Cholesky factors of correlation matrices, which is the output of our bijector! So we end up computing the wrong &lt;code&gt;log_prob&lt;/code&gt;, which means we&amp;rsquo;re not sampling from the model we think we&amp;rsquo;re sampling. So what can we do?&lt;/p&gt;

&lt;p&gt;Solution number 1 is to make sure our cholesky-factors-of-correlation-matrices become correlation matrices before we compute their &lt;code&gt;log_prob&lt;/code&gt; according to LKJ. To do so, we need two more bijectors: &lt;code&gt;tfb.CholeskyOuterProduct&lt;/code&gt;, which maps $L$ to $LL^T$, and &lt;code&gt;tfb.Chain&lt;/code&gt; which, surprisingly, chains (composes) the two bijectors:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;chained_bij_samps = sampleHMC(
    lambda lkj: model.log_prob([lkj]), 
    model.sample(), 
    bijectors_list=[tfb.Chain([tfb.CholeskyOuterProduct(), tfb.CorrelationCholesky()])]
)[0]
chained_bij_samps[:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=12661134, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 1.        , -0.21354356],
        [-0.21354356,  1.        ]],

       [[ 1.        , -0.21354356],
        [-0.21354356,  1.        ]],

       [[ 1.        ,  0.01905983],
        [ 0.01905983,  1.0000001 ]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This looks good. And this time it actually is - this is doing what we think it&amp;rsquo;s doing. But this is cumbersome, and not very readable. Even worse, when we&amp;rsquo;ll pass these correlations matrices to a multivariate gaussian (the usual case), it&amp;rsquo;ll compute their cholesky factors anyway (check out the &lt;a href=&#34;https://github.com/tensorflow/probability/blob/4dd589ba945db902d28dbb75dc0a795706814d45/tensorflow_probability/python/distributions/mvn_full_covariance.py#L189&#34; target=&#34;_blank&#34;&gt;source code&lt;/a&gt;, as well as the depracation warning above it). So we end up sampling cholesky factors, tranforming them back to correlation matrices just to compute their cholesky factors again&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;enter-choleskylkj&#34;&gt;Enter CholeskyLKJ&lt;/h2&gt;

&lt;p&gt;Since &lt;code&gt;tfp-nightly-0.9.0.dev20190830&lt;/code&gt; (a daily-built version that contains the newest changes that have yet to made it into the latest stable release), we have a better option - the &lt;code&gt;CholeskyLKJ&lt;/code&gt; distribution. Unlike LKJ, this is a distribution over &lt;em&gt;cholesky factors&lt;/em&gt; of correlation matrices - so no need to go back and forth, or to chain bijectors&amp;hellip; It&amp;rsquo;s faster, numerically stabler, and it is by the &lt;a href=&#34;https://mc-stan.org/docs/2_19/functions-reference/cholesky-lkj-correlation-distribution.html&#34; target=&#34;_blank&#34;&gt;book&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To use it, we just need a single &lt;code&gt;tfb.CorrelationCholesky()&lt;/code&gt; bijector:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model =  tfd.JointDistributionSequential(
    [
        tfd.CholeskyLKJ(2,2),
    ]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cholesky_lkj_samps = sampleHMC(
    lambda lkj: model.log_prob([lkj]),
    model.sample(),
    bijectors_list=[tfb.CorrelationCholesky()]
)[0]
cholesky_lkj_samps[:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=14269238, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 1.        ,  0.        ],
        [ 0.20048861,  0.97969604]],

       [[ 1.        ,  0.        ],
        [-0.19122852,  0.9815455 ]],

       [[ 1.        ,  0.        ],
        [ 0.18798688,  0.9821716 ]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;a-simple-use-case&#34;&gt;A simple use case&lt;/h1&gt;

&lt;p&gt;We&amp;rsquo;ve covered the technicalities of sampling correlation matrices (and their Cholesky factors) with TFP. To get a more complete picture of how these are actually used, let&amp;rsquo;s see an example. We&amp;rsquo;re sticking with McElreath and Statistical Rethinking; this time we&amp;rsquo;re reproducing the café waiting times example.&lt;/p&gt;

&lt;h2 id=&#34;fake-data&#34;&gt;Fake data&lt;/h2&gt;

&lt;p&gt;Unlike the tadpoles example, this time we&amp;rsquo;re going to model fake data (aka synthetic data). This may sound strange, but it&amp;rsquo;s actually a &lt;em&gt;very&lt;/em&gt; useful skill, and it&amp;rsquo;s considered by many to be pretty much the first step in a Bayesian data analysis workflow (see &lt;a href=&#34;https://khakieconomics.github.io/2017/04/30/An-easy-way-to-simulate-fake-data-in-stan.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;). The reason is that unlike in a &amp;ldquo;real data analysis&amp;rdquo;, when you&amp;rsquo;re generating fake data, you &lt;em&gt;know&lt;/em&gt; the true underlying data generating process; making sure you can recover its parameters is a very important sanity check. It also helps in verifying the model is correctly specified and that the MCMC sampler does what you think it does, which is good.&lt;/p&gt;

&lt;p&gt;The data we&amp;rsquo;re generating describes the waiting times in 20 different cafés. Each café has a different average waiting times in the morning and in the afternoon. The average morning waiting time is the intercept, and the difference between afternoon and morning average waiting times is the slope. The intercepts and slopes for each of the 20 cafés are sampled from a (surprise surprise) correlated bivariate Gaussian distribution.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;##### Inputs needed to generate the covariance matrix between intercepts and slopes #####


a = 3.5  # average morning wait time
b = -1 # average difference afternoon wait time
sigma_a = 1 # standard deviation in the (café-specific) intercepts
sigma_b = 0.5 # standard deviation in the (café-specific) slopes
rho = -0.7 # correlation between intercepts and slopes

mu = [a,b] # the mean of our gaussian distribution
sigmas = [sigma_a,sigma_b] # vector of standard deviations
corr_matrix = np.array([[1,rho], [rho,1]]) # correlation matrix
cov_matrix = np.diag(sigmas)@corr_matrix@np.diag(sigmas)  # the covariance matrix of our gaussian distribution 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After setting the true parameters, we&amp;rsquo;re generating 20 samples of cafés:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n_cafés = 20 # 20 cafés overall

café_params = np.random.multivariate_normal(mu ,cov_matrix,size=n_cafés) 
café_intercept = café_params[:, 0] # intercepts are in the first column
café_slopes = café_params[:, 1] # slopes are in the second
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And compute the actual per-café morning and afternoon waiting times, in 10 different visits. Below is a sample of 10 rows from our dataframe (which has 200 data points overall - 10 visits in 20 cafés):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n_visits = 10 # 10 visits per café

afternoon = np.tile([0,1], n_visits * n_cafés//2) # alternate values for mornings and afternoons in the data frame
café_id = np.repeat(np.arange(n_cafés),n_visits) # data for each café are consecutive rows in the data frame

mu = café_intercept[café_id] + café_slopes[café_id] * afternoon # the regression equation for the mean waiting time
sigma = 0.5 # standard deviation of waiting time within cafés
wait = np.random.normal(mu, sigma, n_visits * n_cafés) # generate instances of waiting times
df = pd.DataFrame(dict(café = café_id, afternoon = afternoon, wait = wait))
print(df.sample(10).to_string(index=False))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; café  afternoon      wait
    8          1  2.175858
    9          0  2.364313
    9          1  1.744504
   14          0  3.716937
    3          1  1.419163
    0          1  1.959044
    5          0  1.045913
    4          0  1.083699
   17          1  2.796278
   15          1  3.430852
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;the-model&#34;&gt;The model&lt;/h2&gt;

&lt;p&gt;We specify in math (and latex) the model described above:&lt;/p&gt;

&lt;p&gt;$$\begin{align}
W_i &amp;amp; \sim \text{Normal}(\alpha_{café[i]}+\beta_{café[i]}\cdot \text{AFTERNOON}_i,\sigma) \\&lt;br /&gt;
\binom{\alpha_{café}}{\beta_{café}} &amp;amp; \sim \text{MVNormal}\left(\binom{\alpha}{\beta},\mathbb{S}\right) \\&lt;br /&gt;
\mathbb{S} &amp;amp; = \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right) \cdot LL^T \cdot \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right)  \\&lt;br /&gt;
\alpha &amp;amp; \sim \text{Normal}(5,2) \\&lt;br /&gt;
\beta &amp;amp; \sim \text{Normal}(-1,0.5) \\&lt;br /&gt;
\sigma_{\alpha},\sigma_{\beta} &amp;amp; \sim \text{Exp}(1) \\&lt;br /&gt;
\sigma &amp;amp; \sim \text{Exp}(1) \\&lt;br /&gt;
L &amp;amp; \sim \text{CholeskyLKJ}(2,2) \\&lt;br /&gt;
\end{align}$$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = tfd.JointDistributionSequential(
    [
        tfd.CholeskyLKJ(2,2),  # rho, the prior for the correlation matrix between intercepts and slopes
        tfd.Sample(tfd.Exponential(rate = 1),sample_shape = 1), # sigma, prior std for the waiting time
        tfd.Sample(tfd.Exponential(rate = 1),sample_shape = 2), # sigma_café, prior of stds for intercepts and slopes (vector of 2)
        tfd.Sample(tfd.Normal(loc = -1, scale = 0.5), sample_shape = 1),   # b, the prior mean for the slopes
        tfd.Sample(tfd.Normal(loc = 5, scale = 2), sample_shape = 1),   # a, the prior mean for the intercepts
        lambda a,b,sigma_café,sigma,chol_rho : tfd.Sample( # per-café intercepts and slopes
            tfd.MultivariateNormalTriL(
                loc = tf.concat([a,b],axis=-1),
                scale_tril = tf.linalg.LinearOperatorDiag(sigma_café).matmul(chol_rho)
            ),
            sample_shape=n_cafés
        ),
        lambda mvn, a, b, sigma_café, sigma : tfd.Independent(  #per-café waiting times
            tfd.Normal(
                loc = tf.gather(mvn[:,:,0],café_id,axis=-1) + tf.gather(mvn[:,:,1],café_id,axis=-1)*afternoon,
                scale = sigma
            ),
            reinterpreted_batch_ndims=1
        )
    ]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Couple of non-trivial things in the model above:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MultivariateNormalTriL&lt;/code&gt;: we&amp;rsquo;ve mentioned that a covariance matrix can be specified as $\Lambda L L^T\Lambda$ where $\Lambda$ is a diagonal matrix of standard deviations and $L$ is the cholesky factor of the correlation matrix. &lt;code&gt;MultivariateNormalTriL&lt;/code&gt; is a parametrization of a multivariate normal distribution whose covariance matrix is specificied using the lower triangular matrix $\Lambda L$.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LinearOperatorDiag&lt;/code&gt;: this turns a &lt;code&gt;sigma-café&lt;/code&gt; vector of length 2 to a 2x2 diagonal matrix; very similar to &lt;code&gt;tf.diag&lt;/code&gt;, but handles all the batching semantics for us.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tf.gather&lt;/code&gt;: this takes each intercept (in the case of &lt;code&gt;mvn[:,:,0]&lt;/code&gt;) and slope (in the case of &lt;code&gt;mvn[:,:,1]&lt;/code&gt; and tiles it 10 times, so overall we get a loc vector of size 200, with which we generate 200 different waiting times, 10 per café.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We now declare the &lt;code&gt;target_log_prob&lt;/code&gt; function for the HMC kernel, and initial values for 4 different chains. Like before, we throw away the last sample (predicted waiting times); we want to plug the waiting times from the data into the likelihood, instead.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n_chains = 4
log_prob_fn = lambda rho, sigma, sigma_café, b, a, mvn : model.log_prob([rho, sigma, sigma_café, b, a, mvn ,wait])
init_rho, init_sigma, init_sigma_café, init_b, init_a, init_mvn, _ = model.sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These initial values are used to specify the shape of the initial values we actually pass, specified below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;init_rho = tf.stack([tf.eye(2) for _ in range(n_chains)])
init_sigma = tf.ones_like(init_sigma)
init_sigma_café = tf.ones_like(init_sigma_café)
init_b = tf.zeros_like(init_b)
init_a = tf.zeros_like(init_a)
init_mvn = tf.zeros_like(init_mvn)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We define the list of bijectors. Note that since standard deviations are non-negative, their support is constrained, and we need a bijector here, as well. The appropriate bijector in this case is &lt;code&gt;tfb.Exp&lt;/code&gt;. Once we specificed a bijectors list, we need to match a bijector for any distribution in our &lt;code&gt;JointDistributionSequential&lt;/code&gt; object; since the support of &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; and &lt;code&gt;mvn&lt;/code&gt; is unconstrained, we simply use an identity transformation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;bijectors_list = [
    tfb.CorrelationCholesky(),
    tfb.Exp(),
    tfb.Exp(),
    tfb.Identity(),
    tfb.Identity(),
    tfb.Identity(),
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;states = sampleHMC(log_prob_fn,
                [init_rho, init_sigma, init_sigma_café, init_b, init_a, init_mvn],
                bijectors_list)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[s.shape for s in states]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[TensorShape([Dimension(500), Dimension(4), Dimension(2), Dimension(2)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(1)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(2)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(1)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(1)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(20), Dimension(2)])]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Shapes look alright. To see the posterior distribution of covariance values, we move back from Cholesky factors to correlation matrices, and multiply by the inferred sigmas (the zeroth axis is the number of samples, first is the number of the chain, so we transpose the second and third axes):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rhos = states[0]@tf.transpose(states[0],[0,1,3,2])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Same as above, we create diagonal matrices from our sampled &lt;code&gt;sigma_alpha&lt;/code&gt;, &lt;code&gt;sigma_beta&lt;/code&gt; values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sigmas = states[2]
diag_sigmas = tf.linalg.LinearOperatorDiag(sigmas)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inferred_covs = tf.matmul(diag_sigmas.matmul(rhos),diag_sigmas)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.figure(figsize=(9,4))
for (row_idx,col_idx), title in zip([(0,0),(0,1),(1,1)],[&amp;quot;$\sigma_{\\alpha}$&amp;quot;,&amp;quot;Covariance&amp;quot;,&amp;quot;$\sigma_{\\beta}$&amp;quot;]):
    plt.subplot(131+row_idx+col_idx)
    sns.distplot(inferred_covs[:,:,row_idx,col_idx].numpy().flatten(), label = &amp;quot;Posterior&amp;quot;)
    plt.axvline(cov_matrix[row_idx,col_idx],c=&#39;k&#39;,ls=&#39;--&#39;,label=&amp;quot;True value&amp;quot;)
    plt.legend()
    plt.title(title)
plt.tight_layout()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;3.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can also compare empirical waiting times with sampled waiting times:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;morning_wait_emp = df.query(&#39;afternoon == 0&#39;).groupby(&#39;café&#39;).wait.mean()
afternoon_wait_emp = df.query(&#39;afternoon == 1&#39;).groupby(&#39;café&#39;).wait.mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;morning_wait_pred = tf.reduce_mean(states[-1][:,:,:,0], axis=(0,1))
afternoon_wait_pred = tf.reduce_mean(states[-1][:,:,:,1], axis=(0,1)) + morning_wait_pred
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And we get the shrinkage that decorates Statistical Rethinking&amp;rsquo;s front cover:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.figure(figsize=(9,6))
ax = plt.subplot(111)
vals, vecs = np.linalg.eigh(np.cov(morning_wait_emp, afternoon_wait_emp))
theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))
w, h = 2 * np.sqrt(vals)
for contour_line in range(1,5):
    ell = Ellipse(xy=(np.mean(morning_wait_emp), np.mean(afternoon_wait_emp)),
                  width=w*contour_line, height=h*contour_line,
                  angle=theta, color=&#39;black&#39;)
    ell.set_facecolor(&#39;none&#39;)
    ax.add_artist(ell)
plt.scatter(morning_wait_emp,afternoon_wait_emp,label=&amp;quot;Empirical&amp;quot;)
plt.scatter(morning_wait_pred,afternoon_wait_pred, label=&amp;quot;MCMC&amp;quot;)
plt.scatter(morning_wait_emp.mean(),afternoon_wait_emp.mean(),marker=&#39;+&#39;,c=&#39;r&#39;,s=100, label=&amp;quot;Grand Mean&amp;quot;)
plt.legend()
for a,b,c,d in zip(morning_wait_emp, afternoon_wait_emp,  morning_wait_pred, afternoon_wait_pred):
    plt.arrow(a,b,0.7*(c.numpy()-a),0.7*(d.numpy()-b), head_width=0.05, alpha=0.3)
plt.xlabel(&amp;quot;Morning wait&amp;quot;)
plt.ylabel(&amp;quot;Afternoon wait&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;4.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Formally, the distribution is defined as: $\text{LKJ}\left(\Sigma\vert\eta\right)\propto\det\left(\Sigma\right)^{\left(\eta-1\right)}$. Intuitively, the correlation matrix defines an ellipsoid in $N$ dimensions, and its determinant is the volume of the ellipsoid. So, higher correlations -&amp;gt; tighter ellipsoid -&amp;gt; smaller volume -&amp;gt; smaller determinant -&amp;gt; more likely for small $\eta$ and less likely for large $\eta$.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Sigrid Keydana did an excellent job explaining TFP bijectors, and specifcally the intuition behind the jacobian correction, in &lt;a href=&#34;https://blogs.rstudio.com/tensorflow/posts/2019-04-05-bijectors-flows/&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; post.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Overthinking boxes are specific (usually mathematical) dive-ins in Statistical Rethinking.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Tutorial on Varying Intercepts Models with TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/varying-intercepts/</link>
      <pubDate>Mon, 08 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/varying-intercepts/</guid>
      <description>

&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;

&lt;p&gt;This post is about building varying intercepts models using TensorFlow Probability (&amp;ldquo;TFP&amp;rdquo;). It&amp;rsquo;s basically my attempt to translate Sigrid Keydana&amp;rsquo;s wonderful &lt;a href=&#34;https://blogs.rstudio.com/tensorflow/posts/2019-05-06-tadpoles-on-tensorflow/&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt; from R to Python. I&amp;rsquo;m doing this for a couple of reasons: First, I&amp;rsquo;ve played with TFP before, was quite impressed by its performance and flexibility, and wanted to learn more about it; Second, I wanted to start blogging, and this seemed like an easy start; Last, TFP is rather new, and there aren&amp;rsquo;t a whole lot of resources and tutorials about it - so this might even prove useful to someone, someday.&lt;/p&gt;

&lt;p&gt;Sigrid dedicated her post to &lt;a href=&#34;https://twitter.com/rlmcelreath&#34; target=&#34;_blank&#34;&gt;Richard McElreath&lt;/a&gt; and his book; I&amp;rsquo;d like to join her on that. I was looking for a good introduction to Bayesian stats for quite some time. BDA3 was too technical for me at that point, Kruschke&amp;rsquo;s was excellent but didn&amp;rsquo;t really dive into the more sophisticated topics I wanted to learn. Statistical Rethinking was spot on - interesting, fun to read, and super helpful. It&amp;rsquo;s very code-oriented, and has already been re-written in pure stan, brms, pymc3, julia and probably many others.&lt;/p&gt;

&lt;p&gt;Stats-wise, this post is going to be about varying intercepts models, which are perhaps the simplest kind of a multilevel model. The main idea behind them - called partial pooling - is simple and beautiful, but here I want to focus on the code, not the stats; for a nice introductory demo, check out &lt;a href=&#34;http://mfviz.com/hierarchical-models/&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; beautiful visualization, or &lt;a href=&#34;http://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; one. Better yet, get a copy of Statistical Rethinking and read the original. :-)&lt;/p&gt;

&lt;h1 id=&#34;the-data&#34;&gt;The data&lt;/h1&gt;

&lt;p&gt;We&amp;rsquo;re given data about 48 different tanks containing tadpoles (pre-frogs). Each tank has a &lt;code&gt;density&lt;/code&gt; (the initial number of tadpoles in it), a categorical feature &lt;code&gt;pred&lt;/code&gt; (whether the tank contained a predator or not), a categorical feature &lt;code&gt;size&lt;/code&gt; (big tank or small tank), the number of surviving tadpoles &lt;code&gt;surv&lt;/code&gt; and the proportion of surviving tadpoles &lt;code&gt;propsurv&lt;/code&gt; (which is simply &lt;code&gt;surv&lt;/code&gt;/&lt;code&gt;density&lt;/code&gt;). The original data came with the book&amp;rsquo;s R package; Luckily, it&amp;rsquo;s hosted in Osvaldo Martin&amp;rsquo;s &lt;a href=&#34;https://github.com/aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3&#34; target=&#34;_blank&#34;&gt;repo&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
df = pd.read_csv(&amp;quot;https://raw.githubusercontent.com/aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3/master/Data/reedfrogs.csv&amp;quot;)
df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;Tank&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;density&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;pred&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;surv&lt;/th&gt;
&lt;th&gt;propsurv&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td&gt;0.7&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Tank densities are either 10, 25 or 35.&lt;/p&gt;

&lt;h1 id=&#34;the-model&#34;&gt;The model&lt;/h1&gt;

&lt;p&gt;Our goal is to compute the probability of survival in each of the tanks. &lt;code&gt;propsurv&lt;/code&gt; is one way to do this, which is straightforward and intuitive - simply compute the per-tank ratio of surviving tadpoles. But this doesn&amp;rsquo;t make much sense, especially if you consider the small sample sizes - if I&amp;rsquo;d give you a tank with &lt;code&gt;density=1&lt;/code&gt;, would you feel comfortable with saying that the probability of survival is either 0% (&lt;code&gt;surv=0&lt;/code&gt;) or 100% (&lt;code&gt;surv=1&lt;/code&gt;)? Probably not.&lt;/p&gt;

&lt;p&gt;A different approach would be to ignore between-tanks variations, and assume all tanks have exactly the same probability of survival. Our best estimate is then the ratio of all the surviving tadpoles (in all tanks, combined) - or &lt;code&gt;sum(surv)/sum(density)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;A varying intercept model is somewhat in between - it assumes each tank has its own probability of survival, but that all these probabilities are coming from some distribution over &amp;ldquo;probabilities of survival&amp;rdquo;. This is how it looks like:&lt;/p&gt;

&lt;p&gt;$$
\begin{align}
\bar{\alpha} &amp;amp; \sim \text{Normal}(0,1.5) \\&lt;br /&gt;
\sigma &amp;amp; \sim \text{Exponential}(1) \\&lt;br /&gt;
\text{logit}\left(p_i\right) &amp;amp; \sim \text{Normal}\left(\bar{\alpha},\sigma\right) \\&lt;br /&gt;
s_i &amp;amp; \sim \text{Binomial}(n_i,p_i) \\&lt;br /&gt;
\end{align}
$$&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s all this? In short - we assume the logits of the survival probabilities are sampled from some normal distribution, whose parameters (often called &amp;ldquo;hyperparameters&amp;rdquo;) we&amp;rsquo;re trying to infer. &lt;code&gt;a_bar&lt;/code&gt; is the mean of this normal distribution, and we put a generic weakly informative prior on it - normal(0,1.5). &lt;code&gt;sigma&lt;/code&gt; is the standard deviation of this normal distribution, and we put an exponential prior on it. After sampling these two numbers, we plug them into the logits distribution, sample 48 different logit values, transform them to probabilities and sample 48 survival predictions from the binomial distributions (one per tank).  Now to the code itself. We begin with the necessary imports:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import tensorflow as tf
import tensorflow_probability as tfp
import seaborn as sns
import matplotlib.pyplot as plt 
import numpy as np
tfd = tfp.distributions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For ease-of-use, we&amp;rsquo;re using TensorFlow in Eager mode, which allows a more interactive and iterative workflow.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tf.compat.v1.enable_eager_execution()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;some-tfp-s-pre-requisites&#34;&gt;Some TFP&amp;rsquo;s pre-requisites&lt;/h2&gt;

&lt;p&gt;Before we start implementing the model itself, we need to cover some of the basic terminology around a &lt;code&gt;TensorFlow Distribution&lt;/code&gt;. For the purposes of this introductory post, you can think of a distribution as an object with the following two methods:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sample()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;log_prob()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both are pretty straightforward - &lt;code&gt;sample()&lt;/code&gt; allows you to generate samples from a given distribution; &lt;code&gt;log_prob()&lt;/code&gt; allows you to calculate the log-probability of a given value(s). There are other methods, of course, but these are the important ones for us.
There are two more attributes we need to mention:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;event_shape&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch_shape&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These were, at least for me, quite confusing (despite their pretty good &lt;a href=&#34;https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Distributions_Tutorial.ipynb&#34; target=&#34;_blank&#34;&gt;docs&lt;/a&gt;). &lt;code&gt;event_shape&lt;/code&gt; is the simpler of the two - if I have some joint probability distribution over N random variables, its &lt;code&gt;event_shape&lt;/code&gt; is N. For example, a bivariate gaussian would have an event shape of 2.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;batch_shape&lt;/code&gt; is trickier: TFP allows you to create a single Distribution object, which actually contains multiple, independent distributions. For example, &lt;code&gt;tfd.Bernoulli(probs=[.3, .5, .7])&lt;/code&gt; is a Distribution object composed of 3 different Bernoulli random variables (RVs) with probabilities of success .3, .5 and .7. The number of the independent distributions contained in this single object is its &lt;code&gt;batch_shape&lt;/code&gt;. Why do this? My best guess is that it gives TFP the ability to make use of the underlying TF infrastructure, in which batching (and broadcasting along a batch dimension) is a fundamental operation. We&amp;rsquo;ll get back to this in the code below.&lt;/p&gt;

&lt;p&gt;Now we&amp;rsquo;ll go ahead and define the model itself using TFP&amp;rsquo;s &lt;code&gt;JointDistributionSequential&lt;/code&gt; API:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;m = tfd.JointDistributionSequential(
    [
        tfd.Normal(loc=0, scale=1.5),
        tfd.Exponential(rate=1.),
        lambda sigma, a_bar: tfd.Sample(tfd.Normal(loc=a_bar, scale=sigma),sample_shape=[df.shape[0]]),
        lambda l: tfd.Independent(tfd.Binomial(total_count=df.density.astype(&#39;float32&#39;), logits=l),
                                  reinterpreted_batch_ndims=1)
    ]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main workhorse here is &lt;code&gt;tfd.JointDistributionSequential&lt;/code&gt;, which is very similar to &lt;code&gt;Sequential&lt;/code&gt; in Keras or PyTorch. It&amp;rsquo;s an object composed of list of Distribution-making functions (&lt;code&gt;tfd.Distribution&lt;/code&gt;s or Python callables that return a &lt;code&gt;tfd.Distribution&lt;/code&gt;). The idea of sequentially stacking distributions, and adding the dependencies between them (the fact that the values sampled from &lt;code&gt;tfd.Normal&lt;/code&gt; and &lt;code&gt;tfd.Exponential&lt;/code&gt; are &amp;lsquo;fed&amp;rsquo; into the 3rd distribution as its mean and standard deviation) is simple and intuitive, and fits nicely in the hierarchical modeling workflow; the code above is basically a 1-to-1 translation of the model specification.&lt;/p&gt;

&lt;p&gt;The tricky parts here are TFP&amp;rsquo;s &lt;code&gt;Sample&lt;/code&gt; and &lt;code&gt;Independent&lt;/code&gt;. What are these, then?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Sample&lt;/code&gt; - The third function receives the hyper-parameters &lt;code&gt;sigma&lt;/code&gt; and &lt;code&gt;a_bar&lt;/code&gt;, and should return one number per tank, drawn from a &lt;code&gt;normal(a_bar,sigma)&lt;/code&gt;. &lt;code&gt;tfd.Sample&lt;/code&gt; allows us to draw samples from the product distribution of all these 48 Gaussians; each sample from &lt;code&gt;Sample&lt;/code&gt; is a vector of 48 (uncorrelated) numbers, all with the same mean &lt;code&gt;a_bar&lt;/code&gt; and standard deviation &lt;code&gt;sigma&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Independent&lt;/code&gt; - the third distribution returns a vector of 48 numbers. If we simply write &lt;code&gt;tfd.Binomial(total_count=df.density.astype(&#39;float32&#39;), logits=l)&lt;/code&gt;, we&amp;rsquo;ll get a distribution with a &lt;code&gt;batch_shape&lt;/code&gt; of 48 and an &lt;code&gt;event_shape&lt;/code&gt; (), representing a scalar output. Wrapping this with &lt;code&gt;tfd.Independent&lt;/code&gt; transforms this output to be of &lt;code&gt;batch_shape&lt;/code&gt; () and &lt;code&gt;event_shape&lt;/code&gt; 48, representing a vector output, like we want it to be.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Another possibly-confusing issue here is the order of the parameters in the lambda expressions. The first parameter is the output of the previous distribution in the list, the second parameter is the output of the previous-previous distribution, etc&amp;hellip; This is why they third distribution gets &lt;code&gt;sigma&lt;/code&gt; before &lt;code&gt;a_bar&lt;/code&gt; despite the fact &lt;code&gt;sigma&lt;/code&gt; is defined &lt;em&gt;after&lt;/em&gt; &lt;code&gt;a_bar&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I found this API somewhat different than the &amp;ldquo;natural&amp;rdquo; way to think about the problem; however, if this ends up with  superior performance, it&amp;rsquo;s probably worth the learning curve for a wide enough range of problems.&lt;/p&gt;

&lt;h1 id=&#34;sampling-from-a-model&#34;&gt;Sampling from a model&lt;/h1&gt;

&lt;p&gt;The model&amp;rsquo;s &lt;code&gt;sample()&lt;/code&gt; method gets a &lt;code&gt;sample_shape&lt;/code&gt; argument which determines the shape of the generated sample. This, in turn, will be used to tell the MCMC sampler how many chains to run in parallel.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n_chains = 4

initial_a, initial_s, initial_logits, init_surv = m.sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since we&amp;rsquo;ve asked for 4 chains, &lt;code&gt;m.sample()&lt;/code&gt; returns 4 samples from the &lt;code&gt;a_bar&lt;/code&gt; hyperprior and 4 samples from the &lt;code&gt;sigma&lt;/code&gt; hyperprior; these, in turn, generate 4 new normal distributions, from which we sample 4x48 logit values. These values are then &amp;ldquo;pushed forward&amp;rdquo;, generating 4x48 samples from the binomial survival distributions. These survival predictions can (and probably should) be used to perform prior predictive checks, but we don&amp;rsquo;t need them to define the sampler, itself.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;initial_a.shape, initial_s.shape, initial_logits.shape, init_surv.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(TensorShape([Dimension(4)]),
 TensorShape([Dimension(4)]),
 TensorShape([Dimension(4), Dimension(48)]),
 TensorShape([Dimension(4), Dimension(48)]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we create the sampler object. This step is composed of 3 different TFP objects. The first is the Hamiltonian Monte Carlo transition kernel, which uses the model&amp;rsquo;s &lt;code&gt;.log_prob()&lt;/code&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(
    target_log_prob_fn = lambda x,y,z : m.log_prob([x,y,z,df.surv.astype(&#39;float32&#39;)]),
    step_size=0.1,
    num_leapfrog_steps=3
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that we&amp;rsquo;re not using the model&amp;rsquo;s &lt;code&gt;.log_prob()&lt;/code&gt; &lt;em&gt;as is&lt;/em&gt;; instead, we make sure that the log-probability is always computed with respect to the actual, observed survival data. This is the purpose of the &lt;code&gt;lambda&lt;/code&gt; function above. For the other two required parameters, I&amp;rsquo;m using the ones from Sigrid&amp;rsquo;s post.&lt;/p&gt;

&lt;p&gt;The second part is the &lt;code&gt;SimpleStepSizeAdaptation&lt;/code&gt; object, which takes the kernel defined above and returns a new kernel with dynamic step size adaptation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;kernel = tfp.mcmc.SimpleStepSizeAdaptation(
    inner_kernel=inner_kernel,
    target_accept_prob = 0.8,
    num_adaptation_steps = 500
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lastly, the sampling function. This object takes as input the initial states (and through them, number of chains to run), number of burnin steps, number of steps to run after burnin, a kernel (our augmented HMC kernel), and a trace function, which determines what kind of intermediate results we want to save. After sampling ends (this can take a while, depending on the complexity of your model), the function returns the samples (and traced results). Here I&amp;rsquo;ve decided not to save intermediate results, at all; the simple diagnostics I&amp;rsquo;m interested in can be computed from the samples themselves.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a_bars, sigmas, logits = tfp.mcmc.sample_chain(
    current_state=[
        tf.zeros_like(initial_a), 
        tf.ones_like(initial_s),
        initial_logits
    ],
    num_results=500,
    num_burnin_steps=500,
    kernel=kernel,
    trace_fn=None
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s have a look at the output shapes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a_bars.shape, sigmas.shape, logits.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(TensorShape([Dimension(500), Dimension(4)]),
 TensorShape([Dimension(500), Dimension(4)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(48)]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The sampler returned 500 samples per chain per parameter - exactly what we want.&lt;/p&gt;

&lt;p&gt;TFP provides standard MCMC diagnostics, such as effective sample size per logit parameter (we average over chains):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tf.reduce_mean(tfp.mcmc.effective_sample_size(logits),axis=0)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=1643926, shape=(48,), dtype=float32, numpy=
array([ 39.01448 ,  27.656044,  64.033554,  23.641933,  38.67304 ,
        43.81818 ,  27.42485 ,  56.60047 ,  86.46597 ,  53.400955,
        62.463234,  68.98154 ,  71.84833 ,  85.98772 ,  53.90014 ,
        45.368874,  57.142807,  64.70456 ,  80.501144,  30.96955 ,
        51.123882,  90.971016,  83.67827 , 133.95776 , 147.53087 ,
       237.56706 , 124.73306 , 213.96054 , 255.63586 , 127.86496 ,
       169.16728 , 222.58665 ,  57.26799 ,  62.313004,  59.934887,
       140.44281 , 126.62906 ,  44.229973,  80.57881 , 100.344055,
       102.71631 , 307.0775  , 298.0421  , 298.77765 , 275.2672  ,
       241.8357  , 134.39154 , 334.7177  ], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And R-hat values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tfp.mcmc.potential_scale_reduction(logits)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=1643986, shape=(48,), dtype=float32, numpy=
array([1.0393666, 1.0419586, 1.014595 , 1.0326122, 1.0066991, 1.0365033,
       1.1032237, 1.0193528, 1.0026469, 1.03286  , 1.0212902, 1.0046616,
       1.0046593, 1.0190336, 1.0491707, 1.0185002, 1.0236404, 1.0240865,
       1.0135043, 1.0091226, 1.0240618, 1.0212263, 1.0040884, 1.0057993,
       1.0115193, 1.0074626, 1.0053723, 1.0013644, 1.0038955, 1.0128344,
       1.0199273, 1.0040274, 1.1276014, 1.0033313, 1.0127679, 1.0017091,
       1.0118763, 1.0570774, 1.04308  , 1.0189458, 1.0144566, 1.0009695,
       1.0063009, 1.0008804, 1.0011569, 1.0057343, 1.0079254, 1.0071955],
      dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can easily inspect the traceplots of the hyperparameters (each color stands for a different chain):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.subplot(121)
plt.plot(a_bars.numpy(),alpha=0.3)
plt.subplot(122)
plt.plot(sigmas.numpy(),alpha=0.3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_34_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We get nicely mixed chains, which is good. We can also plot the posterior distributions of the logits for the different tanks:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.figure(figsize=(12,9))
for i in range(df.shape[0]):
    plt.subplot(7,7,i+1)
    for j in range(n_chains):
        sns.kdeplot(np.array(logits[:,j,i]))
plt.tight_layout()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_36_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here, each subplot corresponds to one tank, and different colors represent different chains. Just by eye-balling the posteriors, we can see a lot of variability between tanks; this is obvious when we compute posterior survival probabilities themselves:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ps = tf.sigmoid(logits).numpy()

plt.figure(figsize=(12,9))
for i in range(df.shape[0]):
    current_ps = ps[:,:,i]
    pred = plt.errorbar(x=[i],y=[current_ps.mean()],
                     yerr=np.array([current_ps.mean()-np.quantile(current_ps,0.25),
                                    np.quantile(current_ps,0.75)-current_ps.mean()]).reshape(2,-1),
                     fmt=&#39;o&#39;,c=&#39;k&#39;)
    act = plt.scatter(i,df.loc[i,&#39;propsurv&#39;],c=&#39;r&#39;)
plt.grid()
plt.xlabel(&amp;quot;Tank number&amp;quot;,fontsize=20)
plt.ylabel(&amp;quot;Survival probability&amp;quot;,fontsize=20)
plt.axhline(df.surv.sum()/df.density.sum(),lw=1)
for density_change in np.where(df.density.diff())[0][1:]:
    plt.axvline(density_change,ls=&#39;--&#39;,c=&#39;k&#39;,lw=1)
plt.legend([pred,act],[&#39;50% Prediction Interval&#39;,&#39;propsurv&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_38_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The black dots are the posterior mean probabilities, the errorbars represent the interquartile range, the red dots are &lt;code&gt;propsurv&lt;/code&gt; (the no-pooling estimate), and the blue horizontal line is the grand mean (the complete-pooling estimate). Vertical lines split the tanks to densities 10, 25 and 35. We can see that, as expected, posterior probabilities are shrunk towards the grand mean. We can also plot the difference between the posterior means and &lt;code&gt;propsurv&lt;/code&gt;, to observe that shrinkage is indeed larger when the sample size is smaller:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i in range(df.shape[0]):
    current_ps = ps[:,:,i]
    plt.scatter(i,(df.loc[i,&#39;propsurv&#39;]-current_ps.mean()),c=&#39;k&#39;)
plt.axhline(0,lw=1)
for density_change in np.where(df.density.diff())[0][1:]:
    plt.axvline(density_change,ls=&#39;--&#39;,c=&#39;k&#39;,lw=1)
plt.xlabel(&amp;quot;Tank number&amp;quot;,fontsize=20)
plt.ylabel(&amp;quot;Shrinkage&amp;quot;,fontsize=20)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_40_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h1&gt;

&lt;p&gt;TFP certainly has a different feel to it compared to other probabilistic programming frameworks like PyMC3 or Stan; specifically, the introduction of batching semantics, and the complexity of the API that is exposed, are very different and pose a real learning curve. The slope, I guess, depends on one&amp;rsquo;s background.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
