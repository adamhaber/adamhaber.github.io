<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bayesian Models | Adam Haber</title>
    <link>https://adamhaber.github.io/tags/bayesian-models/</link>
      <atom:link href="https://adamhaber.github.io/tags/bayesian-models/index.xml" rel="self" type="application/rss+xml" />
    <description>Bayesian Models</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 18 Nov 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://adamhaber.github.io/img/icon-192.png</url>
      <title>Bayesian Models</title>
      <link>https://adamhaber.github.io/tags/bayesian-models/</link>
    </image>
    
    <item>
      <title>Mr. P meets TFP - mixed effects model with post-stratification in TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/mrp/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/mrp/</guid>
      <description>

&lt;h2 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learn an interesting method for generalizing inferences from a biased sample to a population of interest&lt;/li&gt;
&lt;li&gt;See why prior predictive checks are great&lt;/li&gt;
&lt;li&gt;Implement a simple mixed-effects model in TFP&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;

&lt;p&gt;This post is a TFP port of Lauren Kennedy and Jonah Gabry&amp;rsquo;s excellent &lt;a href=&#34;http://mc-stan.org/rstanarm/articles/mrp.html&#34; target=&#34;_blank&#34;&gt;MRP with rstanarm&lt;/a&gt; vignette. It describes a very interesting statistical method for generalizing inferences from a biased sample to a population of interest. The method is called multilevel regression with poststratification, or MRP if you prefer acronyms, or Mister P if you prefer statisticians jokes. Along the way, we&amp;rsquo;ll see why prior predictive checks are so nice and important, how to implement a mixed-effect model in TFP, and how to make predictions for smaller sub-populations.&lt;/p&gt;

&lt;p&gt;I chose to port the vignette because the problem MRP address - generalizing from a biased sample to a population - is so prevalent and important, that knowing what are the possible tools to handle it seemed valuable. I found that porting models from one language to another is an excellent way to learn the model, the problem, and the languages themselves, so it&amp;rsquo;s kind of a win-win-win and publishing it might also help others so why not.&lt;/p&gt;

&lt;p&gt;I strongly recommend reading the original vignette; the people who wrote it are much more knowledgeable than I am about this subject, and I also chose to focus on slightly different things so they&amp;rsquo;re not 100% overlapping. At the end of this post you can find links for further reading.&lt;/p&gt;

&lt;h3 id=&#34;imports-and-helper-functions-data-generation&#34;&gt;Imports and helper functions - data generation&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from collections import namedtuple
import numpy as np
import itertools as it
import pandas as pd
from scipy.special import expit as inv_logit
from scipy.stats import sem
import seaborn as sns
import matplotlib.pyplot as plt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.random.seed(98)

sns.set_palette(&amp;quot;muted&amp;quot;)
params = {
    &#39;legend.fontsize&#39;: &#39;x-large&#39;,
    &#39;figure.figsize&#39;: (9, 6),
    &#39;axes.labelsize&#39;: &#39;x-large&#39;,
    &#39;axes.titlesize&#39;:&#39;x-large&#39;,
    &#39;xtick.labelsize&#39;:&#39;x-large&#39;,
    &#39;ytick.labelsize&#39;:&#39;x-large&#39;
}
plt.rcParams.update(params)
%config InlineBackend.figure_format = &#39;retina&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;the-data&#34;&gt;The data&lt;/h1&gt;

&lt;p&gt;The data we&amp;rsquo;ll work with is simulated data; this has the obvious advantage that we know the ground truth so we&amp;rsquo;ll be able to assess just how well our method generalizes to the population. The data describes the proportion of the population who would choose to adopt a cat over a dog, given the opportunity. Our outcome variable in this example is binary (cat/dog), but MRP is not restricted to such outcomes and can be used for discrete outcomes with more than two values, as well as continuous outcomes.&lt;/p&gt;

&lt;p&gt;These are the variables we&amp;rsquo;ll be working with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sex = range(2)
eth = range(3)
age = range(7)
income = range(3)
state = range(50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;They&amp;rsquo;re all categorical; we use zero-based indexing to enumerate them (instead of calling them &amp;lsquo;Male&amp;rsquo;, &amp;lsquo;Female&amp;rsquo; etc) because it&amp;rsquo;ll make all the indexing gymnastics in the actual implementation somewhat simpler.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;poststrat&lt;/code&gt; is a dataframe containing all $2\times3\times7\times3\times50=6300$ possible combinations of these variables:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;poststrat = pd.DataFrame(
    list(it.product(sex, eth, age, income, state)),
    columns=[&amp;quot;sex&amp;quot;, &amp;quot;eth&amp;quot;, &amp;quot;age&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;state&amp;quot;],
)
poststrat.sample(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4675&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1749&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;49&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2460&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;poststrat.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(6300, 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below are the different proportions of the different variables &lt;em&gt;in the population&lt;/em&gt;. For example, 20% of the population are in the first age group, 10% are in the second, etc. For each combination of variables we&amp;rsquo;ll compute the number of people that share this specific combination by multiplying the total number of people in the population (assumed to be 250 million) with the different probabilities (this means we&amp;rsquo;re assuming the joint probability distribution factorizes, that is - that the different variables are independent).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p_age = np.array([0.2, 0.1, 0.2, 0.2, 0.10, 0.1, 0.1])
p_sex = np.array([0.52, 0.48])
p_eth = np.array([0.5, 0.2, 0.3])
p_income = np.array([0.50, 0.35, 0.15])
p_state_tmp = np.random.uniform(low=10, high=20, size=50)
p_state = np.array(p_state_tmp / p_state_tmp.sum())

poststrat[&amp;quot;N&amp;quot;] = (
    250e6
    * p_sex[poststrat[&amp;quot;sex&amp;quot;]]
    * p_eth[poststrat[&amp;quot;eth&amp;quot;]]
    * p_age[poststrat[&amp;quot;age&amp;quot;]]
    * p_income[poststrat[&amp;quot;income&amp;quot;]]
    * p_state[poststrat[&amp;quot;state&amp;quot;]]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We also assume that different groups have different probabilities of being included in the sample; in a way, that&amp;rsquo;s the entire point (if all groups had the same probability of being included in the sample then the sample was representative of the population). There&amp;rsquo;s a baseline probability of being in the sample, but it cancels out in the weighted average; what determines who is in our sample is &lt;code&gt;p_response_weighted&lt;/code&gt;, which is &lt;code&gt;p_response&lt;/code&gt; weighted by the number of people in each group:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;p_response_baseline = 0.01
p_response_sex = np.array([2, 0.8]) / 2.8
p_response_eth = np.array([1, 1.2, 2.5]) / 4.7 
p_response_age = np.array([1, 0.4, 1, 1.5, 3, 5, 7]) / 18.9
p_response_inc = np.array([1, 0.9, 0.8]) / 2.7
p_response_state = np.random.beta(a=1, b=1, size=50)
p_response_state = p_response_state / p_response_state.sum()

p_response = (
    p_response_baseline
    * p_response_sex[poststrat[&amp;quot;sex&amp;quot;]]
    * p_response_eth[poststrat[&amp;quot;eth&amp;quot;]]
    * p_response_age[poststrat[&amp;quot;age&amp;quot;]]
    * p_response_inc[poststrat[&amp;quot;income&amp;quot;]]
    * p_response_state[poststrat[&amp;quot;state&amp;quot;]]
)

p_response_weighted = poststrat[&amp;quot;N&amp;quot;] * p_response / (poststrat[&amp;quot;N&amp;quot;] * p_response).sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now sample 1200 individuals from the entire population. This means we&amp;rsquo;re actually sampling rows from our &lt;code&gt;poststrat&lt;/code&gt; dataframe with different probabilities given by &lt;code&gt;p_response_weighted&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n = 1200
people = np.random.choice(
    np.arange(poststrat.shape[0]), size=n, replace=True, p=p_response_weighted
)
sample = poststrat.drop(&amp;quot;N&amp;quot;, axis=1).iloc[people].reset_index()
sample.sample(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;index&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;520&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;287&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2626&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;870&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;69&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1517&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;169&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4104&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now we&amp;rsquo;re getting to the thing we&amp;rsquo;ll actually measure in the sample (and then try to generalize to the population) - cat preference. Below are the coefficients of a regression model that determines the log-odds of cat preference, $\log\frac{P(\text{prefers cats})}{P(\text{prefers dogs})}$ for each group in the population. We&amp;rsquo;ll use these coefficients to compute the actual probability of cats preference for each group:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;coef_sex = np.array([0, -0.3])
coef_eth = np.array([0, 0.6, 0.9])
coef_age = np.array([0, -0.2, -0.3, 0.4, 0.5, 0.7, 0.8, 0.9])
coef_income = np.array([0, -0.2, 0.6])
coef_state = np.insert(np.random.normal(0, 1, 49).round(1), 0, 0)
coef_age_sex = np.vstack(
    [
        np.array([0, 0.1, 0.23, 0.3, 0.43, 0.5, 0.6]),
        np.array([0, -0.1, -0.23, -0.5, -0.43, -0.5, -0.6]),
    ]
).T
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;true_pop = poststrat.drop(&amp;quot;N&amp;quot;, axis=1)
true_pop[&amp;quot;cat_pref&amp;quot;] = inv_logit(
    coef_sex[true_pop[&amp;quot;sex&amp;quot;]]
    + coef_eth[true_pop[&amp;quot;eth&amp;quot;]]
    + coef_age[true_pop[&amp;quot;age&amp;quot;]]
    + coef_income[true_pop[&amp;quot;income&amp;quot;]]
    + coef_state[true_pop[&amp;quot;state&amp;quot;]]
    + coef_age_sex[true_pop[&amp;quot;age&amp;quot;], true_pop[&amp;quot;sex&amp;quot;]]
)
true_pop.sample(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cat_pref&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;6124&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.71095&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;177&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.549834&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;5755&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.331812&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2102&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.802184&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3931&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.524979&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We now use the computed probabilities to determine, for each individual in our sample, whether she&amp;rsquo;s a cats person or a dogs person. Note that this is still the fake data generation part; we&amp;rsquo;re not modelling anything yet.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sample[&amp;quot;cat_pref&amp;quot;] = np.random.binomial(n=1, p=true_pop[&amp;quot;cat_pref&amp;quot;][people], size=n)
sample.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;index&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cat_pref&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;671&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;906&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3062&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Just to get a glimpse of the problem Mr. P is trying to solve, the sample mean is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sample[&amp;quot;cat_pref&amp;quot;].mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.7083333333333334
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While the true mean in the population (which is a weighted sum of the per-group probabilities and the group sizes) is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;true_pop_pref = sum(true_pop[&amp;quot;cat_pref&amp;quot;] * poststrat[&amp;quot;N&amp;quot;]) / sum(poststrat[&amp;quot;N&amp;quot;])
true_pop_pref
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.5941253009200917
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So our sample overestimates cats-lovin&amp;rsquo; in the population by 18% - people who like cats also like taking surveys.&lt;/p&gt;

&lt;h2 id=&#34;visualizations&#34;&gt;Visualizations&lt;/h2&gt;

&lt;p&gt;To get a better understanding of the problem (unrepresentativeness of the sample), we&amp;rsquo;ll plot some summary statistics and see how they differ:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f, ax = plt.subplots(1, 4, figsize=(12, 3))

pd.DataFrame(
    dict(pop=pd.Series(p_age), sample=(sample.age.value_counts().sort_index() / n))
).plot(kind=&amp;quot;bar&amp;quot;, ax=ax[0], title=&amp;quot;age&amp;quot;)
pd.DataFrame(
    dict(pop=pd.Series(p_eth), sample=(sample.eth.value_counts().sort_index() / n))
).plot(kind=&amp;quot;bar&amp;quot;, ax=ax[1], legend=False, title=&amp;quot;ethnicity&amp;quot;)
pd.DataFrame(
    dict(
        pop=pd.Series(p_income), sample=(sample.income.value_counts().sort_index() / n)
    )
).plot(kind=&amp;quot;bar&amp;quot;, ax=ax[2], legend=False, title=&amp;quot;income&amp;quot;)
pd.DataFrame(
    dict(pop=pd.Series(p_sex), sample=(sample.sex.value_counts().sort_index() / n))
).plot(kind=&amp;quot;bar&amp;quot;, ax=ax[3], legend=False, title=&amp;quot;sex&amp;quot;)
plt.tight_layout()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_33_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At least by eyeballing the charts, the differences seem substantial; for example, if there&amp;rsquo;s a big difference in cats preference between males and females, we expect to see a substantial difference between the cats preference in the sample and in the population.&lt;/p&gt;

&lt;p&gt;We can also plot how cats preference changes between different groups &lt;em&gt;within&lt;/em&gt; our sample - for example, is there a difference in cats preference between different age groups? (yes there is)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f, axes = plt.subplots(1, 4, figsize=(12, 3), sharey=True)
for key, ax in zip([&amp;quot;age&amp;quot;, &amp;quot;eth&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;sex&amp;quot;], axes):
    sample.groupby(key)[&amp;quot;cat_pref&amp;quot;].agg(dict(mean=np.mean, std=sem)).reset_index().plot(
        kind=&amp;quot;bar&amp;quot;, x=key, y=&amp;quot;mean&amp;quot;, yerr=&amp;quot;std&amp;quot;, ax=ax, legend=False
    )
    plt.ylim(0, 1)
plt.tight_layout()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_36_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;the-model&#34;&gt;The model&lt;/h1&gt;

&lt;p&gt;We now turn to the MR part of MRP - the multilevel regression part. More specifically, we&amp;rsquo;ll build a Bayesian multilevel logistic regression model of cats preference. Even more specifically, we&amp;rsquo;ll build what&amp;rsquo;s called a &amp;ldquo;mixed
effects&amp;rdquo; model. Mixed effects models are one of those places that, at least for me, the statisticians terminology is &lt;em&gt;extremely&lt;/em&gt; confusing; it also seems to be inconsistent between different academic fields.  I usually find it easier to look at the actual model specification to understand what&amp;rsquo;s going on:&lt;/p&gt;

&lt;p&gt;For each group $j\in\left[1,&amp;hellip;,6300\right]$ we model the probability of cats preference as&lt;/p&gt;

&lt;p&gt;$$
\begin{align}
\theta_j &amp;amp; = logit^{-1}(
\alpha +
X_{j}\beta
+ \alpha_{\rm state[j]}^{\rm state}
+ \alpha_{\rm age[j]}^{\rm age}
+ \alpha_{\rm eth[j]}^{\rm eth}
+ \alpha_{\rm inc[j]}^{\rm inc}
) \\&lt;br /&gt;
\alpha_{\rm state[j]}^{\rm state} &amp;amp; \sim N(0,\sigma^{\rm state}) \\&lt;br /&gt;
\alpha_{\rm age[j]}^{\rm age} &amp;amp; \sim N(0,\sigma^{\rm age})\\&lt;br /&gt;
\alpha_{\rm eth[j]}^{\rm eth} &amp;amp; \sim N(0,\sigma^{\rm eth})\\&lt;br /&gt;
\alpha_{\rm inc[j]}^{\rm inc} &amp;amp;\sim N(0,\sigma^{\rm inc}) \\&lt;br /&gt;
\sigma^{\rm state} &amp;amp; \sim {\rm HalfNormal}(1) \\&lt;br /&gt;
\sigma^{\rm age} &amp;amp; \sim {\rm HalfNormal}(1) \\&lt;br /&gt;
\sigma^{\rm eth} &amp;amp; \sim {\rm HalfNormal}(1) \\&lt;br /&gt;
\sigma^{\rm income} &amp;amp; \sim {\rm HalfNormal}(1) \\&lt;br /&gt;
\beta &amp;amp; \sim N(0,2.5) \\&lt;br /&gt;
\alpha &amp;amp; \sim N(0,10) \\&lt;br /&gt;
\end{align}
$$&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve seen expressions like $\alpha_{\rm state[j]}^{\rm state}$ when we&amp;rsquo;ve implemented &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34; target=&#34;_blank&#34;&gt;varying intercepts models&lt;/a&gt;. What makes this a &amp;ldquo;mixed effects&amp;rdquo; models is that $\beta$ is the same $\beta$ for all groups, while the different $\alpha^*$-s vary between groups. I&amp;rsquo;m sure there are subtleties and nuances that this doesn&amp;rsquo;t capture, but for me this is a simple-to-read, simple-to-implement explanation of mixed effects models.&lt;/p&gt;

&lt;p&gt;As for the model itself:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$X$ is a (binary) design matrix that holds indicators for sex, age and sex-age interactions - we&amp;rsquo;ll construct it in a second.&lt;/li&gt;
&lt;li&gt;$\alpha$ is an intercept term.&lt;/li&gt;
&lt;li&gt;$\beta$ is a coefficient vector.&lt;/li&gt;
&lt;li&gt;The different $\alpha^*$-s are per-group varying intercepts.&lt;/li&gt;
&lt;li&gt;The different $\sigma^*$-s are hyperpriors for variation between groups.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The priors on $\alpha,\beta$ are rstanarm&amp;rsquo;s default priors; I couldn&amp;rsquo;t find rstanarm&amp;rsquo;s default prior on the $\sigma^*$ so I chose to use a halfnormal(1) prior.&lt;/p&gt;

&lt;p&gt;Our design matrix $X$ will represent a one-hot-encoded representation of the sampled individuals sex, age, and sex-age interaction term. Here&amp;rsquo;s how it looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;factors = pd.get_dummies(sample[[&amp;quot;sex&amp;quot;, &amp;quot;age&amp;quot;]].astype(&amp;quot;category&amp;quot;)).drop(
    [&amp;quot;sex_0&amp;quot;, &amp;quot;age_0&amp;quot;], axis=1
)
interactions = pd.DataFrame(
    factors.drop(&amp;quot;sex_1&amp;quot;, axis=1).values * factors[&amp;quot;sex_1&amp;quot;].values[:, None],
    columns=[f&amp;quot;sex_1*age_{i+1}&amp;quot; for i in range(6)],
)
features = pd.concat([factors, interactions], axis=1)
features.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_6&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_6&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;features.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(1200, 13)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make TF shape issues simpler, we convert it to a numpy array and transpose it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;features = features.values.T
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;imports-and-helper-functions-inference&#34;&gt;Imports and helper functions - inference&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow_probability import distributions as tfd
from tensorflow_probability import bijectors as tfb
import arviz as az
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n_chains = 4
dtype = tf.float32
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def step_size_setter_fn(pkr, new_step_size):
    return pkr._replace(
        inner_results=pkr.inner_results._replace(step_size=new_step_size)
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;factors = pd.get_dummies(sample[[&amp;quot;sex&amp;quot;, &amp;quot;age&amp;quot;]].astype(&amp;quot;category&amp;quot;)).drop(
    [&amp;quot;sex_0&amp;quot;, &amp;quot;age_0&amp;quot;], axis=1
)
interactions = pd.DataFrame(
    factors.drop(&amp;quot;sex_1&amp;quot;, axis=1).values * factors[&amp;quot;sex_1&amp;quot;].values[:, None],
    columns=[f&amp;quot;sex_1*age_{i}&amp;quot; for i in range(6)],
)
features = pd.concat([factors, interactions], axis=1).values.T
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def trace_fn(current_samp, pkr):

    return (
        pkr.inner_results.inner_results.target_log_prob,
        pkr.inner_results.inner_results.leapfrogs_taken,
        pkr.inner_results.inner_results.has_divergence,
        pkr.inner_results.inner_results.energy,
        pkr.inner_results.inner_results.log_accept_ratio,
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@tf.function(experimental_compile=True)
def run_nuts(target_log_prob_fn, initial_states, bijectors_list):
    step_sizes = [1e-2 * tf.ones_like(i) for i in initial_states]
    kernel = tfp.mcmc.TransformedTransitionKernel(
        tfp.mcmc.nuts.NoUTurnSampler(target_log_prob_fn, step_size=step_sizes),
        bijector=bijectors_list,
    )

    kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(
        kernel,
        target_accept_prob=tf.cast(0.8, dtype=dtype),
        num_adaptation_steps=800,
        step_size_setter_fn=step_size_setter_fn,
        step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,
        log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio,
    )

    # Sampling from the chain.
    mcmc_trace, pkr = tfp.mcmc.sample_chain(
        num_results=1000,
        num_burnin_steps=1000,
        current_state=[
            bijector.forward(state)
            for bijector, state in zip(bijectors_list, initial_states)
        ],
        kernel=kernel,
        trace_fn=trace_fn,
    )

    return mcmc_trace, pkr
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# using pymc3 naming conventions, with log_likelihood instead of lp so that ArviZ can compute loo and waic
sample_stats_name = [
    &amp;quot;log_likelihood&amp;quot;,
    &amp;quot;tree_size&amp;quot;,
    &amp;quot;diverging&amp;quot;,
    &amp;quot;energy&amp;quot;,
    &amp;quot;mean_tree_accept&amp;quot;,
]


def tfp_trace_to_arviz(tfp_trace, var_names=None, sample_stats_name=sample_stats_name):

    samps, trace = tfp_trace
    if var_names is None:
        var_names = [&amp;quot;var &amp;quot; + str(x) for x in range(len(samps))]

    sample_stats = {k: v.numpy().T for k, v in zip(sample_stats_name, trace)}
    posterior = {
        name: tf.transpose(samp, [1, 0, 2]).numpy()
        for name, samp in zip(var_names, samps)
    }
    return az.from_dict(posterior=posterior, sample_stats=sample_stats)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For more details about calling TFP&amp;rsquo;s NUTS sampler, and the helper functions defined above, see &lt;a href=&#34;https://adamhaber.github.io/2019/10/21/Bayesian-golf-puttings,-NUTS,-and-optimizing-your-sampling-function-with-TensorFlow-Probability.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;first-implemetation&#34;&gt;First implemetation&lt;/h2&gt;

&lt;p&gt;We now turn to implement the whole model in TFP. Since there aren&amp;rsquo;t many complicated intermediate calculations, a &lt;code&gt;JointDistributionSequential&lt;/code&gt; is a reasonable choice for implementing the model. For a more detailed explanation on the different &lt;code&gt;JointDistribution&lt;/code&gt; alternatives, see &lt;a href=&#34;https://adamhaber.github.io/2019/10/21/Bayesian-golf-puttings,-NUTS,-and-optimizing-your-sampling-function-with-TensorFlow-Probability.html#model-1&#34; target=&#34;_blank&#34;&gt;this post&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = tfd.JointDistributionSequential(
    [
        tfd.HalfNormal(1),  # sigma_state
        lambda sigma_state: tfd.Sample(tfd.Normal(0, sigma_state), sample_shape=50),
        tfd.HalfNormal(1),  # sigma_eth
        lambda sigma_eth: tfd.Sample(tfd.Normal(0, sigma_eth), sample_shape=3),
        tfd.HalfNormal(1),  # sigma_income
        lambda sigma_income: tfd.Sample(tfd.Normal(0, sigma_income), sample_shape=3),
        tfd.HalfNormal(1),  # sigma_age
        lambda sigma_age: tfd.Sample(tfd.Normal(0, sigma_age), sample_shape=7),
        tfd.Normal(0, 10),  # intercept
        tfd.Sample(tfd.Normal(0, 2.5), sample_shape=13),  # coeffs
        lambda coeffs, intercept, coef_age, sigma_age, coef_income, sigma_income, coef_eth, sigma_eth, coef_state: tfd.Independent(
            tfd.Binomial(
                total_count=1,
                logits=intercept[:, tf.newaxis]
                + coeffs @ tf.cast(features, tf.float32)
                + tf.squeeze(
                    tf.gather(coef_age, tf.cast(sample[&amp;quot;age&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_income, tf.cast(sample[&amp;quot;income&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_eth, tf.cast(sample[&amp;quot;eth&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_state, tf.cast(sample[&amp;quot;state&amp;quot;], tf.int32), axis=-1)
                ),
            ),
            reinterpreted_batch_ndims=1,
        ),
    ]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The model description isn&amp;rsquo;t short, but it doesn&amp;rsquo;t contain anything we haven&amp;rsquo;t covered in previous posts. Let&amp;rsquo;s call &lt;code&gt;.sample&lt;/code&gt; and &lt;code&gt;.log_prob&lt;/code&gt; just to make sure everything works:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[s.shape for s in model.sample(n_chains)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[TensorShape([4]),
 TensorShape([4, 50]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 7]),
 TensorShape([4]),
 TensorShape([4, 13]),
 TensorShape([4, 1200])]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.log_prob(model.sample(n_chains))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-121.06135 ,   21.950146,  -69.38415 , -224.08742 ], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So our model technically works&amp;hellip; but does it makes sense?&lt;/p&gt;

&lt;h2 id=&#34;prior-predictive-checks&#34;&gt;Prior predictive checks&lt;/h2&gt;

&lt;p&gt;Prior predictive checks are an extremely valuable technique to assess your model and your priors, before seeing any data. To learn more about PPCs (horrible acronym as the first P can also stand for &lt;em&gt;posterior&lt;/em&gt;), I highly recommend Michael Betancourt&amp;rsquo;s &lt;a href=&#34;https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html&#34; target=&#34;_blank&#34;&gt;principled bayesian workflow&lt;/a&gt; case study.&lt;/p&gt;

&lt;p&gt;Anyway, let&amp;rsquo;s generate samples from our model, and use the samples to compute the logits (the linear expression within the &lt;code&gt;inv_logit&lt;/code&gt; function):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inits = model.sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state = inits[1:10][
    ::-1
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;logits = (
    intercept[:, tf.newaxis]
    + coeffs @ tf.cast(features, tf.float32)
    + tf.squeeze(tf.gather(coef_age, tf.cast(sample[&amp;quot;age&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_income, tf.cast(sample[&amp;quot;income&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_eth, tf.cast(sample[&amp;quot;eth&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_state, tf.cast(sample[&amp;quot;state&amp;quot;], tf.int32), axis=-1))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each chain gives us 1200 different numbers - the log-odds for cat preference for our 1200 sampled individuals. Let&amp;rsquo;s plot these four histograms:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i, l in enumerate(logits):
    sns.distplot(l, bins=30, label=f&amp;quot;from chain {i}&amp;quot;)
plt.legend()
plt.xlabel(&amp;quot;${\\rm logit}\\left(\\theta_j\\right)$&amp;quot;)
lim = plt.xlim();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_67_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that it&amp;rsquo;s OK that each color (each chain) is multimodal - this just means that we&amp;rsquo;re inferring different &amp;ldquo;types&amp;rdquo; of cats preference across groups.&lt;/p&gt;

&lt;p&gt;The problem with what we got is the &lt;em&gt;scale&lt;/em&gt; - having ${\rm logit}\left(\theta_j\right)=-15$ means $\theta_j=0.000000003&amp;hellip;$ which doesn&amp;rsquo;t really makes sense, even for a group that &lt;em&gt;really&lt;/em&gt; likes dogs. This implies that our priors are way too diffuse, the normal(0,10) being the primary suspect. So let&amp;rsquo;s make everything normal(0,1) and do this again:&lt;/p&gt;

&lt;h1 id=&#34;same-likelihood-better-priors&#34;&gt;Same likelihood, better priors&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = tfd.JointDistributionSequential(
    [
        tfd.HalfNormal(1),  # sigma_state
        lambda sigma_state: tfd.Sample(tfd.Normal(0, sigma_state), sample_shape=50),
        tfd.HalfNormal(1),  # sigma_eth
        lambda sigma_eth: tfd.Sample(tfd.Normal(0, sigma_eth), sample_shape=3),
        tfd.HalfNormal(1),  # sigma_income
        lambda sigma_income: tfd.Sample(tfd.Normal(0, sigma_income), sample_shape=3),
        tfd.HalfNormal(1),  # sigma_age
        lambda sigma_age: tfd.Sample(tfd.Normal(0, sigma_age), sample_shape=7),
        tfd.Normal(0, 1),  # intercept
        tfd.Sample(tfd.Normal(0, 1), sample_shape=13),  # coeffs
        lambda coeffs, intercept, coef_age, a, coef_income, b, coef_eth, c, coef_state: tfd.Independent(
            tfd.Binomial(
                total_count=1,
                logits=intercept[:, tf.newaxis]
                + coeffs @ tf.cast(features, tf.float32)
                + tf.squeeze(
                    tf.gather(coef_age, tf.cast(sample[&amp;quot;age&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_income, tf.cast(sample[&amp;quot;income&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_eth, tf.cast(sample[&amp;quot;eth&amp;quot;], tf.int32), axis=-1)
                )
                + tf.squeeze(
                    tf.gather(coef_state, tf.cast(sample[&amp;quot;state&amp;quot;], tf.int32), axis=-1)
                ),
            ),
            reinterpreted_batch_ndims=1,
        ),
    ]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inits = model.sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state = inits[1:10][
    ::-1
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;logits = (
    intercept[:, tf.newaxis]
    + coeffs @ tf.cast(features, tf.float32)
    + tf.squeeze(tf.gather(coef_age, tf.cast(sample[&amp;quot;age&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_income, tf.cast(sample[&amp;quot;income&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_eth, tf.cast(sample[&amp;quot;eth&amp;quot;], tf.int32), axis=-1))
    + tf.squeeze(tf.gather(coef_state, tf.cast(sample[&amp;quot;state&amp;quot;], tf.int32), axis=-1))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i, l in enumerate(logits):
    sns.distplot(l, bins=30, label=f&amp;quot;from chain {i}&amp;quot;)
plt.legend()
plt.xlabel(&amp;quot;${\\rm logit}\\left(\\theta_j\\right)$&amp;quot;)
plt.xlim(*lim);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_74_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This makes much more sense. The variance between groups is still there but it doesn&amp;rsquo;t spread across several order of magnitude (that is, with this prior it&amp;rsquo;s no longer plausible that some groups love cats 10 million times more than other groups). This seems like a good starting point.&lt;/p&gt;

&lt;p&gt;Note that the overly wide priors are also very problematic, inference wise - running the same notebook with the first model returns all sorts of sampling problems (divergent transitions, bad mixing, random seed dependence etc) while the 2nd, more informed version does not.&lt;/p&gt;

&lt;h2 id=&#34;getting-the-shapes-right&#34;&gt;Getting the shapes right&lt;/h2&gt;

&lt;p&gt;This is, by far, the hardest thing for me when building a probablistic model with TFP. Knowing where to put &lt;code&gt;[...,],  tf.newaxis&lt;/code&gt; or &lt;code&gt;[None,]&lt;/code&gt; requires some trial and error - here are some checks to verify we got this right (after &lt;em&gt;a lot&lt;/em&gt; of failed attempts and some help from Junpeng Lao):&lt;/p&gt;

&lt;p&gt;First, we want to make sure the model can evaluate the log probability of its own samples, and that we get &lt;code&gt;n_chains&lt;/code&gt; different numbers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.log_prob(inits)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-619.5229 , -520.8101 , -460.97076, -609.21765], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Second, we want to make sure that all shapes of the different parameters in our samples are as we expect, which basically should be the number of chains in the first axis and the shape of whatever it is we&amp;rsquo;re sampling in the rest - or nothing, if it&amp;rsquo;s just a scalar:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[s.shape for s in inits]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[TensorShape([4]),
 TensorShape([4, 50]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 7]),
 TensorShape([4]),
 TensorShape([4, 13]),
 TensorShape([4, 1200])]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main thing to look out for here are redundant extra dimensions (for example, &lt;code&gt;TensorShape([4, 1])&lt;/code&gt; instead of &lt;code&gt;TensorShape([4])&lt;/code&gt; - these will almost always cause broadcasting issues.&lt;/p&gt;

&lt;p&gt;Next, we want to add an extra axis for the data we condition on. Again, this is for broadcasting purposes - we want to make sure &lt;code&gt;tf&lt;/code&gt; &amp;ldquo;replicates&amp;rdquo; the data across different chains.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tf.cast(sample[&amp;quot;cat_pref&amp;quot;], tf.float32)[tf.newaxis, ...].shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;TensorShape([1, 1200])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, the &lt;code&gt;log_prob&lt;/code&gt; function closure - we want to make sure our &lt;code&gt;log_prob&lt;/code&gt; function gets as inputs all the different parameters, concatenates them with the data we&amp;rsquo;re conditioning on, and then uses the original model &lt;code&gt;log_prob&lt;/code&gt; function to evaluate; practically, we want to verify that if we pass all the parameters (&lt;em&gt;without&lt;/em&gt; the conditioning data), we get &lt;code&gt;n_chains&lt;/code&gt; different numbers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;lp = lambda *x: model.log_prob(
    list(x) + [tf.cast(sample[&amp;quot;cat_pref&amp;quot;], tf.float32)[tf.newaxis, ...]]
)
lp(*inits[:-1])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1315.5156, -1436.2715, -1799.2578, -1901.1874], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;inference&#34;&gt;Inference&lt;/h2&gt;

&lt;p&gt;With sensible priors and TFP shape issues dealt with, we can proceed with actually runnning the sampler.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inits = [
    tf.random.uniform(s.shape, -2, 2, tf.float32, name=&amp;quot;initializer&amp;quot;) for s in inits
]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace, kr = run_nuts(
    lp,
    inits[:-1],
    bijectors_list=[
        tfb.Exp(),
        tfb.Identity(),
        tfb.Exp(),
        tfb.Identity(),
        tfb.Exp(),
        tfb.Identity(),
        tfb.Exp(),
        tfb.Identity(),
        tfb.Identity(),
        tfb.Identity(),
    ],
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Always&lt;/em&gt; check your TF shapes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[s.shape for s in trace]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[TensorShape([1000, 4]),
 TensorShape([1000, 4, 50]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 3]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 3]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 7]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 13])]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This looks good; for arviz intergration purposes, we&amp;rsquo;ll add an extra axis for the parameters whose tensor shape is &lt;code&gt;TensorShape([1000, 4])&lt;/code&gt;, and then call our &lt;code&gt;tfp_trace_to_arviz&lt;/code&gt; helper function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace_ex = [s[..., tf.newaxis] if len(s.shape) == 2 else s for s in trace]
az_trace = tfp_trace_to_arviz((trace_ex, kr))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;az.summary(az_trace).head(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hpd_3%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hpd_97%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mcse_mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mcse_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_bulk&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_tail&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r_hat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 0[0]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.056&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.153&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.779&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.338&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1771&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1806&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2668&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[0]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.016&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.607&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.173&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.155&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.011&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.009&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2822&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2235&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2843&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2538&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[1]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.025&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.505&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.997&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.927&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3978&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4013&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2918&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[2]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.477&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.463&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.362&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.38&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.007&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4207&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2794&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4232&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2521&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[3]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.764&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.896&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.017&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.013&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2102&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1745&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2132&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1908&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Sampling diagnostics look good; we have no divergent transitions, and $\hat{R}$ values are all close to 1:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;az.summary(az_trace)[&amp;quot;r_hat&amp;quot;].describe()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;count    81.0
mean      1.0
std       0.0
min       1.0
25%       1.0
50%       1.0
75%       1.0
max       1.0
Name: r_hat, dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We won&amp;rsquo;t go down the model-diagnostics-rabbit-hole now; we&amp;rsquo;re here to learn about Mister P.&lt;/p&gt;

&lt;h2 id=&#34;p-part&#34;&gt;P part&lt;/h2&gt;

&lt;p&gt;So far we&amp;rsquo;ve defined, critisized and fitted a multilevel logisitic regression model. Now comes the poststratification part. Poststratification is a technical and intimidating word; it basically means &amp;ldquo;adjusting the inferences from my sample to the population by using additional knowledge about proportions in the population&amp;rdquo;. To do so, we&amp;rsquo;ll:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Compute a design matrix $X$ for the population.&lt;/li&gt;
&lt;li&gt;Use our 4000 sampled parameters to compute 4000 different logits for each group in the population. This will yield a 4000x6300 matrix.&lt;/li&gt;
&lt;li&gt;For each row (representing a single draw from our posterior), we&amp;rsquo;ll compute the population mean as a weighted sum of per-group cat preference and group&amp;rsquo;s size. This will give us a vector of 4000 numbers.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The mean of these 4000 numbers will be our estimate for the population mean.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;post_factors = pd.get_dummies(poststrat[[&amp;quot;sex&amp;quot;, &amp;quot;age&amp;quot;]].astype(&amp;quot;category&amp;quot;)).drop(
[&amp;quot;sex_0&amp;quot;, &amp;quot;age_0&amp;quot;], axis=1
)
post_interactions = pd.DataFrame(
post_factors.drop(&amp;quot;sex_1&amp;quot;, axis=1).values * post_factors[&amp;quot;sex_1&amp;quot;].values[:, None],
columns=[f&amp;quot;sex_1*age_{i}&amp;quot; for i in range(6)],
)
post_features = pd.concat([post_factors, post_interactions], axis=1).values.T
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;intercept = trace[8]
coeffs = trace[9]
coef_age = trace[7]
coef_income = trace[5]
coef_eth = trace[3]
coef_state = trace[1]

logits = (
intercept[..., tf.newaxis]
+ coeffs @ tf.cast(post_features, tf.float32)
+ tf.gather(trace[7], tf.cast(poststrat[&amp;quot;age&amp;quot;], tf.int32), axis=-1)
+ tf.gather(coef_income, tf.cast(poststrat[&amp;quot;income&amp;quot;], tf.int32), axis=-1)
+ tf.gather(coef_eth, tf.cast(poststrat[&amp;quot;eth&amp;quot;], tf.int32), axis=-1)
+ tf.gather(coef_state, tf.cast(poststrat[&amp;quot;state&amp;quot;], tf.int32), axis=-1)
)
posterior_prob = inv_logit(logits)
posterior_prob = posterior_prob.reshape(-1, 6300)
posterior_prob.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(4000, 6300)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;poststrat_prob = posterior_prob @ poststrat[&amp;quot;N&amp;quot;][:, None] / poststrat[&amp;quot;N&amp;quot;].sum()
poststrat_prob.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(4000, 1)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So how good is MRP? We plot the histogram of our 4000 different estimates of the population mean, together with the estimate from the sample (dashed line) and the true mean:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sns.distplot(poststrat_prob, bins=100)
plt.axvline(true_pop_pref, label=&amp;quot;population mean&amp;quot;, lw=3, c=&amp;quot;k&amp;quot;)
plt.axvline(sample[&amp;quot;cat_pref&amp;quot;].mean(), label=&amp;quot;sample mean&amp;quot;, lw=3, ls=&amp;quot;--&amp;quot;, c=&amp;quot;k&amp;quot;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_106_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can see that the posterior mean is much closer to the true mean - so MRP definitely helps!&lt;/p&gt;

&lt;h1 id=&#34;estimates-for-states&#34;&gt;Estimates for states&lt;/h1&gt;

&lt;p&gt;The nice thing about having a model is that we can use it to answer all sorts of different questions. For example, we can repeat the analysis we just did and estimate per-state means. We&amp;rsquo;re still computing the design matrix, logits etc as before but we&amp;rsquo;re constraining ourselves to one state at a time. For each state, we&amp;rsquo;ll compute the model&amp;rsquo;s mean and standard deviations, together with the true mean and the sample mean:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;state_data = namedtuple(
    &amp;quot;state_data&amp;quot;,
    [
        &amp;quot;state&amp;quot;,
        &amp;quot;model_state_sd&amp;quot;,
        &amp;quot;model_state_pref&amp;quot;,
        &amp;quot;sample_state_pref&amp;quot;,
        &amp;quot;true_state_pref&amp;quot;,
        &amp;quot;N&amp;quot;,
    ],
)
states_data = []

for i in range(50):
    state_features = np.squeeze(post_features[:, np.where(poststrat.state == i)])
    state_poststrat = poststrat.query(f&amp;quot;state=={i}&amp;quot;)
    logits = (
        intercept[..., tf.newaxis]
        + coeffs @ tf.cast(state_features, tf.float32)
        + tf.gather(
            trace[7],
            tf.cast(state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;age&amp;quot;], tf.int32),
            axis=-1,
        )
        + tf.gather(
            coef_income,
            tf.cast(state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;income&amp;quot;], tf.int32),
            axis=-1,
        )
        + tf.gather(
            coef_eth,
            tf.cast(state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;eth&amp;quot;], tf.int32),
            axis=-1,
        )
        + tf.gather(
            coef_state,
            tf.cast(state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;state&amp;quot;], tf.int32),
            axis=-1,
        )
    )
    posterior_prob = inv_logit(logits)
    posterior_prob = posterior_prob.reshape(-1, state_features.shape[1])
    state_poststrat_prob = (
        posterior_prob
        @ state_poststrat.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;N&amp;quot;][:, None]
        / state_poststrat[&amp;quot;N&amp;quot;].sum()
    )
    states_data.append(
        state_data(
            i,
            state_poststrat_prob.std(),
            state_poststrat_prob.mean(),
            sample.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;cat_pref&amp;quot;].mean(),
            np.sum(true_pop.query(f&amp;quot;state=={i}&amp;quot;)[&amp;quot;cat_pref&amp;quot;] * state_poststrat[&amp;quot;N&amp;quot;])
            / np.sum(state_poststrat[&amp;quot;N&amp;quot;]),
            sample.query(f&amp;quot;state=={i}&amp;quot;).shape[0],
        )
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;state_df = pd.DataFrame(states_data)
state_df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;model_state_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;model_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sample_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;true_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;N&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.116844&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.580393&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.596565&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0956771&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.583293&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.658961&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0817888&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.669766&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.823529&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.69817&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.145332&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.505946&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.553341&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0768275&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.493726&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.611111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.443913&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Graphically, this is how this looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f, ax = plt.subplots(figsize=(6, 6))
state_df.plot(
    x=&amp;quot;true_state_pref&amp;quot;,
    y=&amp;quot;model_state_pref&amp;quot;,
    yerr=&amp;quot;model_state_sd&amp;quot;,
    ax=ax,
    kind=&amp;quot;scatter&amp;quot;,
    label=&amp;quot;Model&amp;quot;,
)
state_df.plot(
    x=&amp;quot;true_state_pref&amp;quot;,
    y=&amp;quot;sample_state_pref&amp;quot;,
    ax=ax,
    kind=&amp;quot;scatter&amp;quot;,
    c=&amp;quot;C1&amp;quot;,
    label=&amp;quot;Sample&amp;quot;,
)
ax.plot([0, 1], [0, 1], c=&amp;quot;k&amp;quot;)
f.tight_layout()
plt.ylabel(&amp;quot;Cat preference&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_113_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that the model predictions of state-wise preferences (blue dots) are closer to the identity line compared to the orange dots (sample per-state mean preferences).&lt;/p&gt;

&lt;p&gt;Another interesting thing to see is how the model uncertainty (quantified by the standard deviation of the model predictions, per state) is related to sample size; we can see that the model is more confident (lower std) for states with higher N, which is what we would expect:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.scatter(state_df[&amp;quot;N&amp;quot;], state_df[&amp;quot;model_state_sd&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_116_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;summary-and-further-reading&#34;&gt;Summary and further reading&lt;/h1&gt;

&lt;p&gt;This post was a code-oriented introduction to MRP, which is a very interesting technique that nicely leverages the built in advantages of multilevel models. We&amp;rsquo;ve also seen how taking a package&amp;rsquo;s priors for granted is not always a good idea, and how prior predictive checks can help us calibrate our priors and our beliefs.&lt;/p&gt;

&lt;p&gt;In case you want to learn more, other than Lauren and Jonah&amp;rsquo;s vignette, these are all excellent reads:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Austin Rochford&amp;rsquo;s &lt;a href=&#34;https://austinrochford.com/posts/2017-07-09-mrpymc3.html&#34; target=&#34;_blank&#34;&gt;MRPyMC3&lt;/a&gt; tutorial&lt;/li&gt;
&lt;li&gt;Andrew Gelman&amp;rsquo;s post about Mister P&amp;rsquo;s &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2013/10/09/mister-p-whats-its-secret-sauce/&#34; target=&#34;_blank&#34;&gt;secret sauce&lt;/a&gt;. Somewhat more technical and perhaps more political-science specific, but still interesting and relevant.&lt;/li&gt;
&lt;li&gt;Dan Simpson&amp;rsquo;s post on &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2019/08/22/multilevel-structured-regression-and-post-stratification/&#34; target=&#34;_blank&#34;&gt;structured priors&lt;/a&gt; for MRP; this is somewhat more advanced, but Dan&amp;rsquo;s posts are always fun to read.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian golf puttings, NUTS, and optimizing your sampling function with TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/nuts/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/nuts/</guid>
      <description>

&lt;h2 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Port a great Bayesian modelling tutorial from Stan to TFP&lt;/li&gt;
&lt;li&gt;Discuss how to speed up our sampling function&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;trace_fn&lt;/code&gt; to produce Stan-like &lt;code&gt;generated quantities&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Explore the results using the ArviZ library.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;

&lt;p&gt;This is a TFP-port one of of the best Bayesian modelling tutorials I&amp;rsquo;ve seen online - the &lt;a href=&#34;https://mc-stan.org/users/documentation/case-studies/golf.html&#34; target=&#34;_blank&#34;&gt;Model building and expansion for golf putting&lt;/a&gt; Stan tutorial. It&amp;rsquo;s a beautiful example of modeling from first principles, and why the incorporation of domain knowledge into a statistical model - in this case, knowing a little bit about golf and some high-school physics - is so important. Since there&amp;rsquo;s no chance I&amp;rsquo;ll explain the subject nearly as well as Gelman, go read his tutorial and come back if you want to learn how to do this with TFP. :-)&lt;/p&gt;

&lt;p&gt;Other than the actual TFP code for the different models, this post will also shortly discuss the new NUTS kernel, various optimizations techniques to make sampling (much) faster, how to use &lt;code&gt;trace_fn&lt;/code&gt; to produce Stan-style generated quantities, and the ArviZ plotting library for inspecting sampler traces and statistics. I&amp;rsquo;m not an expert on any of these topics - I&amp;rsquo;ll share what I&amp;rsquo;ve learned while trying to implement these models, and provide links for further reading.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re more into basketball than golf, you might be interested in &lt;a href=&#34;https://jamesblandecon.github.io/NBAJumpShotsIndividual.html&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; case-study; it&amp;rsquo;s based on the golf tutorial, but analyzes NBA jump shots instead.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# the necessary imports
import tensorflow.compat.v2 as tf

import tensorflow_probability as tfp

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt 
import numpy as np
from time import time
from tensorflow_probability import distributions as tfd
from tensorflow_probability import bijectors as tfb
from functools import partial

import arviz as az  #we&#39;ll get to that
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sns.set_palette(&amp;quot;muted&amp;quot;)
np.random.seed(1324)
dtype=tf.float32
params = {
    &#39;legend.fontsize&#39;: &#39;x-large&#39;,
    &#39;figure.figsize&#39;: (9, 6),
    &#39;axes.labelsize&#39;: &#39;x-large&#39;,
    &#39;axes.titlesize&#39;:&#39;x-large&#39;,
    &#39;xtick.labelsize&#39;:&#39;x-large&#39;,
    &#39;ytick.labelsize&#39;:&#39;x-large&#39;
}
plt.rcParams.update(params)
%config InlineBackend.figure_format = &#39;retina&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;arviz&#34;&gt;ArviZ&lt;/h1&gt;

&lt;p&gt;In the previous posts we&amp;rsquo;ve been using &lt;a href=&#34;https://seaborn.pydata.org&#34; target=&#34;_blank&#34;&gt;seaborn&lt;/a&gt; for plotting. Seaborn is an amazing plotting library with good defaults and well-designed API, but it was not built with MCMC simulations in mind. &lt;a href=&#34;https://arviz-devs.github.io/arviz/&#34; target=&#34;_blank&#34;&gt;ArviZ&lt;/a&gt; was. ArviZ allows for &amp;ldquo;Exploratory analysis of Bayesian models&amp;rdquo;, and interfaces with many bayesian modeling libraries such as PyStan, PyMC3, Pyro, emcee and TFP. ArviZ prints nice dataframes with summary statistics, supports model comparison using LOO and WAIC (similar to the &lt;a href=&#34;https://cran.r-project.org/web/packages/loo/loo.pdf&#34; target=&#34;_blank&#34;&gt;loo&lt;/a&gt; package in R), and a wide variety of diagnosis tools; it&amp;rsquo;s the most comprehensive Python package for this sort of analysis I&amp;rsquo;ve seen, and it&amp;rsquo;s maintained by top PyMC3 contributors.&lt;/p&gt;

&lt;p&gt;The only drawback for using ArviZ with TFP at the moment is that the &lt;code&gt;from_tfp&lt;/code&gt; function has troubles with multi-chain traces (which are pretty much the norm); I adjusted a code snippet from &lt;a href=&#34;https://colab.research.google.com/gist/junpenglao/51cd25c6372f8d2ab3490d4af8f97401/tfp_nuts_demo.ipynb&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; notebook and wrote a small helper function to handle this. The &lt;code&gt;tfp_trace_to_arviz&lt;/code&gt; function gets a &lt;code&gt;StatesAndTrace&lt;/code&gt; object, which is a container with two elements:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a list of samples tensors (the actual output of the sampler).&lt;/li&gt;
&lt;li&gt;a list of trace statistics.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;hellip; and returns an ArviZ &lt;code&gt;InferenceData&lt;/code&gt; object. There is a wide range of statistics we can extract from our sampler, which are important for sampling diagnosis. This is the actual function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# using pymc3 naming conventions, with log_likelihood instead of lp so that ArviZ can compute loo and waic
sample_stats_name = [&#39;log_likelihood&#39;,&#39;tree_size&#39;,&#39;diverging&#39;,&#39;energy&#39;,&#39;mean_tree_accept&#39;]

def tfp_trace_to_arviz(
    tfp_trace,
    var_names=None, 
    sample_stats_name=sample_stats_name):
    
    samps, trace = tfp_trace
    if var_names is None:
        var_names = [&amp;quot;var &amp;quot; + str(x) for x in range(len(samps))]
        
    sample_stats = {k:v.numpy().T for k, v in zip(sample_stats_name, trace)}
    posterior = {name : tf.transpose(samp, [1, 0, 2]).numpy() for name, samp in zip(var_names, samps)}
    return az.from_dict(posterior=posterior, sample_stats=sample_stats)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only tricky thing here is the &lt;code&gt;tf.transpose&lt;/code&gt; operation - we&amp;rsquo;re making sure the chain dimension is the first axis, to be consistent with ArviZ conventions (see &lt;a href=&#34;https://github.com/arviz-devs/arviz/blob/24f8268844cf3cc5cf10d152e955c3122ec477c0/arviz/data/base.py#L103&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;az.data.numpy_to_data_array&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;h1 id=&#34;nuts&#34;&gt;NUTS&lt;/h1&gt;

&lt;p&gt;Previous posts have used the Hamiltonian Monte Carlo sampler to sample from our posterior distributions. When I tried to use HMC to sample from the models described below (specifically, from the 3rd and 4th models) I&amp;rsquo;ve had troubles reproducing the results from the Stan tutorial. I&amp;rsquo;ve posted a question on the TFP google group (super responsive and helpful), and Junpeng Lao (PyMC3 core developer, now working on TFP) recommended I&amp;rsquo;ll try the new NUTS kernel, instead. He said NUTS requires significantly less hand-tuning for complex models, compared to HMC; he was right.&lt;/p&gt;

&lt;p&gt;Since the posts so far were mostly code-oriented, we haven&amp;rsquo;t really gotten into the HMC algorithm, so we&amp;rsquo;re not going to get into why NUTS is an improvement; suffice to say it traverses the posterior distribution in a more efficient way, which is good for us (the simple people who don&amp;rsquo;t know how to hand-tune the number of leapfrog steps). We&amp;rsquo;ll see below another new addition to TFP that helps with another fine-tuning problem.&lt;/p&gt;

&lt;p&gt;For further reading, these are all excellent:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The original &lt;a href=&#34;http://jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf&#34; target=&#34;_blank&#34;&gt;NUTS&lt;/a&gt; paper.&lt;/li&gt;
&lt;li&gt;Michael Betancourt&amp;rsquo;s &lt;a href=&#34;https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=2&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=2ahUKEwisvufdvJflAhWl5OAKHctkBaYQFjABegQIAhAB&amp;amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1701.02434&amp;amp;usg=AOvVaw0KCc_YNSmoxjpHQOaZP2IN&#34; target=&#34;_blank&#34;&gt;A Conceptual Introduction to Hamiltonian Monte Carlo&lt;/a&gt; paper.&lt;/li&gt;
&lt;li&gt;For the more code-oriented reader - Colin Carroll&amp;rsquo;s excellent &lt;a href=&#34;https://colindcarroll.com/2019/04/11/hamiltonian-monte-carlo-from-scratch/&#34; target=&#34;_blank&#34;&gt;series&lt;/a&gt; of posts on HMC, tuning, etc. Colin is one of the maintainers of both ArviZ and PyMC3.&lt;/li&gt;
&lt;li&gt;Sigrid Keydana&amp;rsquo;s &lt;a href=&#34;https://blogs.rstudio.com/tensorflow/posts/2019-10-03-intro-to-hmc/&#34; target=&#34;_blank&#34;&gt;explanation&lt;/a&gt; is also excellent and less intimidating than the original articles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;rsquo;ll now go over the code we&amp;rsquo;ll use to run the NUTS sampler. We&amp;rsquo;ll start with explaining &lt;code&gt;trace_fn&lt;/code&gt;, which is not NUTS specific but we&amp;rsquo;ll use it in our &lt;code&gt;run_nuts&lt;/code&gt; function; then we&amp;rsquo;ll cover the &lt;code&gt;run_nuts&lt;/code&gt; function itself.&lt;/p&gt;

&lt;h2 id=&#34;tracing-sampler-statistics&#34;&gt;Tracing sampler statistics&lt;/h2&gt;

&lt;p&gt;TFP allows us to collect various statistics of the sampling procedure, which can be important for diagnosing different kinds of problems with our model. To tell TFP which sampler statistics we actually care about, we need to pass &lt;code&gt;sample_chain&lt;/code&gt; a mysterious looking function called &lt;code&gt;trace_fn&lt;/code&gt;, which takes two arguments: &lt;code&gt;states&lt;/code&gt;, and &lt;code&gt;previous_kernel_results&lt;/code&gt; (or &lt;code&gt;pkr&lt;/code&gt;; took me a while understand what this stands for). In most examples (e.g., in &lt;code&gt;sample_chain&lt;/code&gt;&amp;rsquo;s docs), the &lt;code&gt;states&lt;/code&gt; argument is discarded and some field(s) of the &lt;code&gt;pkr&lt;/code&gt; (which is a &lt;code&gt;collections.namedtuple&lt;/code&gt; object) are returned. To see what are the different kinds of statistics you can extract from &lt;code&gt;previous_kernel_results&lt;/code&gt; for the NUTS sampler, see &lt;a href=&#34;https://github.com/tensorflow/probability/blob/b959b26b7b3eee31711096d140b01cf58768e5e1/tensorflow_probability/python/mcmc/nuts.py#L73&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Following the same notebook linked above, we&amp;rsquo;re extracting the following statistics (most of this came from this PyMC3 &lt;a href=&#34;https://docs.pymc.io/notebooks/sampler-stats.html&#34; target=&#34;_blank&#34;&gt;Sampler Statistics&lt;/a&gt; notebook):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;target_log_prob&lt;/code&gt; - log likelihood of the current state. If you&amp;rsquo;re interested in using ArviZ for model comparison, you need to extract this.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;leapfrogs_taken&lt;/code&gt; - NUTS generates a binary tree during sampling; this is the number of leafs in the tree per iteration. If the tree size is large, this can imply there are strong correlations in the posterior, high curvature &amp;ldquo;funnels&amp;rdquo;, and that &lt;a href=&#34;https://mc-stan.org/docs/2_18/stan-users-guide/reparameterization-section.html&#34; target=&#34;_blank&#34;&gt;reparameterization&lt;/a&gt; of the model (for example, moving from a centered to non-centered representation) might be helpful.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;has_divergence&lt;/code&gt; - Whether the trajectory for this sample diverged. See Michael Betancourt&amp;rsquo;s excellent &lt;a href=&#34;https://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html&#34; target=&#34;_blank&#34;&gt;post&lt;/a&gt; for what are divergences and how you can use them to detect problems with your model.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;energy&lt;/code&gt; - The energy at the point in phase-space where the sample was accepted. Can be used to identify posteriors with problematically long tails. See &lt;a href=&#34;https://discourse.pymc.io/t/about-nuts-sampling-and-energy-plot/831&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;log_accept_ratio&lt;/code&gt; - The mean acceptance probability for the tree that generated this sample. This can be compared to the desired target acceptance ratio for diagnosis.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def trace_fn(_, pkr):  
return (
    pkr.inner_results.inner_results.target_log_prob,
    pkr.inner_results.inner_results.leapfrogs_taken,
    pkr.inner_results.inner_results.has_divergence,
    pkr.inner_results.inner_results.energy,
    pkr.inner_results.inner_results.log_accept_ratio
)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;code&gt;pkr.inner_results.inner_results&lt;/code&gt; part is due to the fact that we&amp;rsquo;re using a kernel-within-a-kernel-within-a-kernel - see below.&lt;/p&gt;

&lt;h2 id=&#34;calling-nuts&#34;&gt;Calling NUTS&lt;/h2&gt;

&lt;p&gt;The code for running the NUTS sampler is somewhat different than the &lt;code&gt;sampleHMC&lt;/code&gt; function we&amp;rsquo;ve used in the previous posts. Here&amp;rsquo;s a helper function for running NUTS that takes a tracing function, a log probability function, a list of initial values and an (optional) list of bijectors, and returns samples and sampler statistics.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n_chains = 10

def run_nuts_template(
    trace_fn,
    target_log_prob_fn,
    inits,
    bijectors_list=None, 
    num_steps=500,
    num_burnin=500,
    n_chains=n_chains):
    
    step_size = np.random.rand(n_chains, 1)*.5 + 1.
    
    if not isinstance(inits, list):
        inits = [inits]
        
    if bijectors_list is None:
        bijectors_list = [tfb.Identity()]*len(inits)

    kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(
        tfp.mcmc.TransformedTransitionKernel(
            inner_kernel=tfp.mcmc.NoUTurnSampler(
                target_log_prob_fn,
                step_size=[step_size]*len(inits)
            ),
            bijector=bijectors_list
        ),
        target_accept_prob=.8,
        num_adaptation_steps=int(0.8*num_burnin),
        step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(
              inner_results=pkr.inner_results._replace(step_size=new_step_size)
          ),
        step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,
        log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio,
    )
    
    res = tfp.mcmc.sample_chain(
        num_results=num_steps,
        num_burnin_steps=num_burnin,
        current_state=inits,
        kernel=kernel,
        trace_fn=trace_fn
    )
    return res
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What have we got here?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;NUTS&lt;/code&gt; kernel is hidden within the &lt;code&gt;TransformedTransitionKernel&lt;/code&gt;, and gets as inputs the &lt;code&gt;target_log_prob_fn&lt;/code&gt; function representing the model we want to sample from, and a list of per-variable &lt;code&gt;step_size&lt;/code&gt; for the NUTS algorithm. TFP&amp;rsquo;s docs recommend these should be of the same order-of-magnitude as the standard deviations of the target distribution; here they&amp;rsquo;re taken to be of order 1, and jittered (this can apparently help with areas of high-curvature of the posterior - see the Stan manual on &lt;a href=&#34;https://mc-stan.org/docs/2_18/reference-manual/hmc-algorithm-parameters.html&#34; target=&#34;_blank&#34;&gt;HMC parameters&lt;/a&gt; for more details).&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;TransformedTransitionKernel&lt;/code&gt; wraps &lt;code&gt;NUTS&lt;/code&gt; in case we&amp;rsquo;re using unconstraining bijectors. For a more in-depth explanation on bijectors, see my previous &lt;a href=&#34;https://adamhaber.github.io/2019/09/02/Varying-Slopes-Models-and-the-CholeskyLKJ-Distribution-in-TensorFlow-Probability.html&#34; target=&#34;_blank&#34;&gt;post&lt;/a&gt;. If no bijectors are passed, we&amp;rsquo;re using Identity bijectors.&lt;/li&gt;
&lt;li&gt;This is wrapped by &lt;code&gt;tfp.mcmc.DualAveragingStepSizeAdaptation&lt;/code&gt;, which, as the name suggests, adapts the sampler step size in order to make sampling more efficient. This is the 2nd addition that saves hand-tuning I&amp;rsquo;ve mentioned above. We&amp;rsquo;re setting the number of adaptation steps to be 80% of the number of burnin step, following TFP&amp;rsquo;s &lt;a href=&#34;https://github.com/tensorflow/probability/blob/b959b26b7b3eee31711096d140b01cf58768e5e1/tensorflow_probability/python/mcmc/dual_averaging_step_size_adaptation.py#L113&#34; target=&#34;_blank&#34;&gt;recommendation&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The whole kernel-within-kernel-within-kernel is passed to &lt;code&gt;sample_chain&lt;/code&gt;, along with initial values, the trace function from above, number of burnin steps and number of results.&lt;/p&gt;

&lt;h2 id=&#34;speeding-up-your-sampler-with-xla-compilation&#34;&gt;Speeding up your sampler with XLA compilation&lt;/h2&gt;

&lt;p&gt;We can call &lt;code&gt;run_nuts&lt;/code&gt; as it is and everything will work fine. However, we can use some TFP optimisation tricks to make sampling &lt;em&gt;significantly&lt;/em&gt; faster. Optimizing the sampling function is a one liner:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;run_nuts = partial(run_nuts_template, trace_fn)

run_nuts_opt = tf.function(run_nuts)
run_nuts_defun = tf.function(run_nuts, autograph=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What&amp;rsquo;s this?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We&amp;rsquo;re using &lt;code&gt;functools.partial&lt;/code&gt; to &amp;ldquo;plug in&amp;rdquo; the tracing function. This simply saves writing &lt;code&gt;run_nuts&lt;/code&gt; several times for several tracing functions.&lt;/li&gt;
&lt;li&gt;Decorating the &lt;code&gt;run_nuts&lt;/code&gt; function with &lt;code&gt;tf.function&lt;/code&gt; compiles it into a &lt;code&gt;tf.Graph&lt;/code&gt;, which means faster execution and easy integration with the GPU or TPU. This is done by tracing the TensorFlow operations in &lt;code&gt;run_nuts&lt;/code&gt; and constructing the corresponding &lt;code&gt;tf.Graph&lt;/code&gt;, allowing TensorFlow to optimize and exploit parallelism in the computation defined by &lt;code&gt;run_nuts&lt;/code&gt;. See &lt;a href=&#34;https://www.tensorflow.org/guide/function&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/function&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; if you&amp;rsquo;re interested in learning more.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;autograph=False&lt;/code&gt; is related to how control-flow statements are handled; setting it to &lt;code&gt;False&lt;/code&gt; is the recommendation of the TFP team (we&amp;rsquo;ll benchmark all these below).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can even have a faster version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;run_nuts_defun_xla = tf.function(run_nuts, autograph=False, experimental_compile=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;experimental_compile=True&lt;/code&gt; compiles the whole graph into XLA, which is even faster, as we&amp;rsquo;ll see below. XLA is a domain-specific compiler used by TensorFlow (and jax) to produce highly optimized code and CPU/GPU/TPU compatibility. For learning more about XLA compilation, read &lt;a href=&#34;https://www.tensorflow.org/xla&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; and watch the talk at the bottom of the page.&lt;/p&gt;

&lt;h1 id=&#34;data&#34;&gt;Data&lt;/h1&gt;

&lt;p&gt;There are two datasets in the original Stan tutorial - we call them &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;new_data&lt;/code&gt;. The first column is the distance (&lt;code&gt;x&lt;/code&gt;) from the hole, the second column is the number of attempts, and the last column is the number of successful putts:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = np.array([[2,1443,1346],
[3,694,577],
[4,455,337],
[5,353,208],
[6,272,149],
[7,256,136],
[8,240,111],
[9,217,69],
[10,200,67],
[11,237,75],
[12,202,52],
[13,192,46],
[14,174,54],
[15,167,28],
[16,201,27],
[17,195,31],
[18,191,33],
[19,147,20],
[20,152,24]])

new_data = np.array([[0.28, 45198, 45183],
[0.97, 183020, 182899],
[1.93, 169503, 168594],
[2.92, 113094, 108953],
[3.93, 73855, 64740],
[4.94, 53659, 41106],
[5.94, 42991, 28205],
[6.95, 37050, 21334],
[7.95, 33275, 16615],
[8.95, 30836, 13503],
[9.95, 28637, 11060],
[10.95, 26239, 9032],
[11.95, 24636, 7687],
[12.95, 22876, 6432],
[14.43, 41267, 9813],
[16.43, 35712, 7196],
[18.44, 31573, 5290],
[20.44, 28280, 4086],
[21.95, 13238, 1642],
[24.39, 46570, 4767],
[28.40, 38422, 2980],
[32.39, 31641, 1996],
[36.39, 25604, 1327],
[40.37, 20366, 834],
[44.38, 15977, 559],
[48.37, 11770, 311],
[52.36, 8708, 231],
[57.25, 8878, 204],
[63.23, 5492, 103],
[69.18, 3087, 35],
[75.19, 1742, 24]])

df = pd.DataFrame(data, columns = [&#39;x&#39;,&#39;n&#39;,&#39;y&#39;])
new_df = pd.DataFrame(new_data, columns = [&#39;x&#39;,&#39;n&#39;,&#39;y&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is how the data looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.scatter(df[&#39;x&#39;],df[&#39;y&#39;]/df[&#39;n&#39;],c=&#39;b&#39;,label=&#39;data&#39;)
plt.scatter(new_df[&#39;x&#39;],new_df[&#39;y&#39;]/new_df[&#39;n&#39;],c=&#39;r&#39;,label=&#39;new_data&#39;)
plt.legend()
plt.xlabel(&amp;quot;Distance&amp;quot;)
plt.ylabel(&amp;quot;% of success&amp;quot;)
plt.title(&amp;quot;Original data&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_28_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;model-1&#34;&gt;Model 1&lt;/h1&gt;

&lt;p&gt;The first model is a simple logistic regression. Since the graph above is somewhat skewed and not symmetric around its midpoint (like a sigmoid), you can already guess logistic regression won&amp;rsquo;t be very accurate but why not:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;root = tfd.JointDistributionCoroutine.Root

def golf_logistic():
    a = yield root(tfd.Sample(tfd.Normal(0,1e6),1))
    b = yield root(tfd.Sample(tfd.Normal(0,1e6),1))
    y = yield tfd.Independent(
        tfd.Binomial(
            total_count = tf.cast(df[&#39;n&#39;],dtype),
            logits = a+tf.cast(df[&#39;x&#39;],dtype)*b
        )
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;golf_logistic_jd = tfd.JointDistributionCoroutine(golf_logistic)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that unlike the Stan tutorial, we&amp;rsquo;re using a super-vague but proper prior $\mathcal{N}\left(0,10^6\right)$.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll use &lt;code&gt;tfd.JointDistributionCoroutine&lt;/code&gt; to build all 4 models in this post. &lt;code&gt;JointDistributionCoroutine&lt;/code&gt; is a cousin of the more-intuitive &lt;code&gt;JointDistributionSequential&lt;/code&gt; we&amp;rsquo;ve used in previous posts. Instead of a list of &lt;code&gt;tfd.Distribution&lt;/code&gt;-like instances, we&amp;rsquo;re passing a generator that yields a sequence of &lt;code&gt;tfd.Distribution&lt;/code&gt;-like instances. The main advantage is that with &lt;code&gt;Coroutine&lt;/code&gt;&amp;rsquo;s function syntax its easier to express intermediate calculations, compared to &lt;code&gt;Sequential&lt;/code&gt;&amp;rsquo;s list syntax. This will come in handy already in the 2nd model.&lt;/p&gt;

&lt;p&gt;The main differences are that we need to use &lt;code&gt;yield&lt;/code&gt; everytime we&amp;rsquo;re sampling from a distribution, and wrap priors (random variables in the model that don&amp;rsquo;t depend on other random variables) with &lt;code&gt;root&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Once we have our model, we feed its &lt;code&gt;log_prob&lt;/code&gt; method together with the observed data into &lt;code&gt;run_nuts&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;golf_logistic_log_prob = lambda *args: golf_logistic_jd.log_prob(args + (tf.cast(df[&#39;y&#39;],dtype),))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see how each of the &lt;code&gt;run_nuts&lt;/code&gt; version is doing:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts(golf_logistic_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 13min 5s, sys: 4.28 s, total: 13min 10s
Wall time: 13min 13s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_opt(golf_logistic_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 29.7 s, sys: 4.13 s, total: 33.8 s
Wall time: 18.7 s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_defun(golf_logistic_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 29 s, sys: 4.04 s, total: 33 s
Wall time: 17.9 s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_defun_xla(golf_logistic_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 6.29 s, sys: 77.9 ms, total: 6.37 s
Wall time: 6.39 s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So &lt;code&gt;tf.function&lt;/code&gt; makes a &lt;em&gt;huge&lt;/em&gt; difference, &lt;code&gt;autograph&lt;/code&gt; True/False doesn&amp;rsquo;t really matter here, and XLA definitely helps.&lt;/p&gt;

&lt;p&gt;Visualizing the results with ArviZ is now straightforward:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace1 = tfp_trace_to_arviz(res,[&#39;a&#39;,&#39;b&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;az.plot_trace(trace1);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_42_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And so is displaying summary statistics:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;az.summary(trace1)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;th&gt;sd&lt;/th&gt;
      &lt;th&gt;hpd_3%&lt;/th&gt;
      &lt;th&gt;hpd_97%&lt;/th&gt;
      &lt;th&gt;mcse_mean&lt;/th&gt;
      &lt;th&gt;mcse_sd&lt;/th&gt;
      &lt;th&gt;ess_mean&lt;/th&gt;
      &lt;th&gt;ess_sd&lt;/th&gt;
      &lt;th&gt;ess_bulk&lt;/th&gt;
      &lt;th&gt;ess_tail&lt;/th&gt;
      &lt;th&gt;r_hat&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;a[0]&lt;/th&gt;
      &lt;td&gt;2.231&lt;/td&gt;
      &lt;td&gt;0.061&lt;/td&gt;
      &lt;td&gt;2.115&lt;/td&gt;
      &lt;td&gt;2.346&lt;/td&gt;
      &lt;td&gt;0.002&lt;/td&gt;
      &lt;td&gt;0.001&lt;/td&gt;
      &lt;td&gt;1017.0&lt;/td&gt;
      &lt;td&gt;1016.0&lt;/td&gt;
      &lt;td&gt;1030.0&lt;/td&gt;
      &lt;td&gt;833.0&lt;/td&gt;
      &lt;td&gt;1.01&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;b[0]&lt;/th&gt;
      &lt;td&gt;-0.256&lt;/td&gt;
      &lt;td&gt;0.007&lt;/td&gt;
      &lt;td&gt;-0.269&lt;/td&gt;
      &lt;td&gt;-0.243&lt;/td&gt;
      &lt;td&gt;0.000&lt;/td&gt;
      &lt;td&gt;0.000&lt;/td&gt;
      &lt;td&gt;1294.0&lt;/td&gt;
      &lt;td&gt;1293.0&lt;/td&gt;
      &lt;td&gt;1297.0&lt;/td&gt;
      &lt;td&gt;1320.0&lt;/td&gt;
      &lt;td&gt;1.01&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Let&amp;rsquo;s see how this logistic regression looks like when we use the mean parameters:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a,b = az.summary(trace1)[&#39;mean&#39;]
plt.plot(df[&#39;x&#39;], [np.exp(x)/(1+np.exp(x)) for x in a+df[&#39;x&#39;]*b],c=&#39;r&#39;,label=&#39;model 1&#39;) 
plt.scatter(df[&#39;x&#39;], df[&#39;y&#39;]/df[&#39;n&#39;],label=&#39;data&#39;) 
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_46_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;model-2&#34;&gt;Model 2&lt;/h1&gt;

&lt;p&gt;Logistic regression is a good start, but we can see it&amp;rsquo;s not doing a very good job at fitting our data. The second model is a major improvement, incorporating the knowledge that this data is describing attempts to insert a small ball into a larger hole; therefore their sizes, the distance between them and the corresponding angles probably matter.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;r = (1.68/2)/12 #ball size
R = (4.25/2)/12 #hole size

#threshold angles
df[&#39;th_angle&#39;] = np.arcsin((R-r)/df[&#39;x&#39;])          
new_df[&#39;th_angle&#39;] = np.arcsin((R-r)/new_df[&#39;x&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;normal_cdf = tfb.NormalCDF()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def golf_angle_distance():
    # priors
    sigma = yield root(tfd.Sample(tfd.HalfNormal(1e6),1))
    
    # transformations
    phi = 2*normal_cdf.forward(
        tf.cast(df[&#39;th_angle&#39;],dtype)/sigma
    )-1
    
    # likelihood
    y = yield tfd.Independent(
        tfd.Binomial(
            tf.cast(df[&#39;n&#39;],dtype),
            probs=phi
        )
    )

golf_angle_distance_jd = tfd.JointDistributionCoroutine(golf_angle_distance)
golf_angle_distance_jd_log_prob = lambda *args: golf_angle_distance_jd.log_prob(
    args + (tf.cast(df[&#39;y&#39;], dtype),)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that something like &lt;code&gt;phi&lt;/code&gt; would be difficult to express with &lt;code&gt;Sequential&lt;/code&gt;, but straightforward with &lt;code&gt;Coroutine&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll use this model as an opportunity to do something different with our &lt;code&gt;trace_fn&lt;/code&gt;. Stan has this super useful &lt;code&gt;generated quantities&lt;/code&gt; block, in which we can use the sampled parameters to generated various kinds of quantities of interest. We&amp;rsquo;ve mentioned above that &lt;code&gt;trace_fn&lt;/code&gt; takes a &lt;code&gt;state&lt;/code&gt; and a &lt;code&gt;pkr&lt;/code&gt;, and usually discards the first. We&amp;rsquo;ll now modify our &lt;code&gt;trace_fn&lt;/code&gt; so that in each step it takes the current angle (in radians) and converts it to degrees:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def trace_fn_angles(current_state, pkr):  
    return (
        tf.squeeze(current_state[0]*180/np.pi),
        pkr.inner_results.inner_results.target_log_prob,
        pkr.inner_results.inner_results.leapfrogs_taken,
        pkr.inner_results.inner_results.has_divergence,
        pkr.inner_results.inner_results.energy,
        pkr.inner_results.inner_results.log_accept_ratio
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;re taking the current state, representing the angle in radians, and convert it to degrees. The &lt;code&gt;tf.squeeze&lt;/code&gt; is here to get rid of a redundant dimension that can cause broadcasting issues later.&lt;/p&gt;

&lt;p&gt;As for timing - the non &lt;code&gt;tf.function&lt;/code&gt;-ed version is so slow that we won&amp;rsquo;t even try. Let&amp;rsquo;s compare the other alternatives:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;run_nuts_angle = partial(run_nuts_template, trace_fn_angles)

run_nuts_opt_angle = tf.function(run_nuts_angle)
run_nuts_defun_angle = tf.function(run_nuts_angle, autograph=False)
run_nuts_defun_xla_angle = tf.function(run_nuts_angle, autograph=False, experimental_compile=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_opt_angle(golf_angle_distance_jd_log_prob, [tf.ones((n_chains,1))], [tfb.Exp()])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 6.18 s, sys: 808 ms, total: 6.99 s
Wall time: 3.96 s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_defun_angle(golf_angle_distance_jd_log_prob, [tf.ones((n_chains,1))], [tfb.Exp()])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 6.06 s, sys: 755 ms, total: 6.82 s
Wall time: 3.93 s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_defun_xla_angle(golf_angle_distance_jd_log_prob, [tf.ones((n_chains,1))], [tfb.Exp()])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 5.29 s, sys: 59.1 ms, total: 5.35 s
Wall time: 5.38 s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;No clear winner this time. Let&amp;rsquo;s inspect the trace:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace2 = tfp_trace_to_arviz(res,[&#39;sigma&#39;],
                            sample_stats_name=[&#39;angle&#39;]+sample_stats_name)
az.plot_trace(trace2);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_60_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Since we traced the angles using &lt;code&gt;trace_fn_angles&lt;/code&gt;, ArviZ treats it as another sample statistics - it&amp;rsquo;s saved as an &lt;code&gt;xarray.DataArray&lt;/code&gt; and even has its own plotting method:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace2.sample_stats.angle.plot.hist(bins=30);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_62_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I found this nice and cleaner than &lt;code&gt;sns.distplot(res[0][0].numpy().flatten()*180/np.pi)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We print the summary statistics and make sure we&amp;rsquo;re reproducing the Stan tutorial results:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;az.summary(trace2)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;th&gt;sd&lt;/th&gt;
      &lt;th&gt;hpd_3%&lt;/th&gt;
      &lt;th&gt;hpd_97%&lt;/th&gt;
      &lt;th&gt;mcse_mean&lt;/th&gt;
      &lt;th&gt;mcse_sd&lt;/th&gt;
      &lt;th&gt;ess_mean&lt;/th&gt;
      &lt;th&gt;ess_sd&lt;/th&gt;
      &lt;th&gt;ess_bulk&lt;/th&gt;
      &lt;th&gt;ess_tail&lt;/th&gt;
      &lt;th&gt;r_hat&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;sigma[0]&lt;/th&gt;
      &lt;td&gt;0.027&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.026&lt;/td&gt;
      &lt;td&gt;0.027&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;2074.0&lt;/td&gt;
      &lt;td&gt;2073.0&lt;/td&gt;
      &lt;td&gt;2077.0&lt;/td&gt;
      &lt;td&gt;3648.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h2 id=&#34;comparing-models-1-2-with-arviz&#34;&gt;Comparing models 1 &amp;amp; 2 with ArviZ&lt;/h2&gt;

&lt;p&gt;ArviZ allows us to conduct model comparison using approximate Leave-One-Out cross validation and WAIC information criteria (read more &lt;a href=&#34;https://mc-stan.org/loo/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; if you&amp;rsquo;re interested). To do so, our ArviZ objects must have a &lt;code&gt;log_likelihood&lt;/code&gt; sampler stats field (this is why we&amp;rsquo;ve included &lt;code&gt;target_log_prob&lt;/code&gt; in our tracing function):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace1.sample_stats.log_likelihood.shape, trace2.sample_stats.log_likelihood.shape 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;((10, 500), (10, 500))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Model comparison is now as easy as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;az.compare({&#39;Model 1&#39;:trace1, &#39;Model 2&#39;:trace2})
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;rank&lt;/th&gt;
      &lt;th&gt;waic&lt;/th&gt;
      &lt;th&gt;p_waic&lt;/th&gt;
      &lt;th&gt;d_waic&lt;/th&gt;
      &lt;th&gt;weight&lt;/th&gt;
      &lt;th&gt;se&lt;/th&gt;
      &lt;th&gt;dse&lt;/th&gt;
      &lt;th&gt;warning&lt;/th&gt;
      &lt;th&gt;waic_scale&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Model 2&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;203.973&lt;/td&gt;
      &lt;td&gt;0.521524&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2.20886e-14&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;deviance&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Model 1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;424.486&lt;/td&gt;
      &lt;td&gt;1.12655&lt;/td&gt;
      &lt;td&gt;220.513&lt;/td&gt;
      &lt;td&gt;1.30697e-48&lt;/td&gt;
      &lt;td&gt;1.10443e-14&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;deviance&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The models are ranked from best to worst, so Model 2 (not surprisingly) outperforms Model 1. For more info about model comparison, how to read this table and its visualization using &lt;code&gt;az.plot_compare&lt;/code&gt;, see &lt;a href=&#34;https://docs.pymc.io/notebooks/model_comparison.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;model-3&#34;&gt;Model 3&lt;/h1&gt;

&lt;p&gt;The authors aren&amp;rsquo;t satisfied with the fit of Model 2 and incorporate yet another piece of golf knowledge - other than shooting the ball at the right angle, you need to shoot it to the right distance, as well. They describe how this can be modelled, and proceed to fit the model:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;distance_tol = 3.
overshot = 1.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def golf_angle_distance_2():
    # priors
    sigma_angle = yield root(tfd.Sample(tfd.HalfNormal(1),1))
    sigma_distance = yield root(tfd.Sample(tfd.HalfNormal(1),1))

    # transformations
    p_angle = 2 * normal_cdf.forward(
        tf.cast(new_df[&#39;th_angle&#39;],dtype)/sigma_angle
    )-1
    
    p_dist = normal_cdf.forward(
        (distance_tol-overshot)/(tf.cast(new_df[&#39;x&#39;]+overshot,dtype)*sigma_distance)
    ) - \
    normal_cdf.forward(
        (-overshot)/(tf.cast(new_df[&#39;x&#39;]+overshot,dtype)*sigma_distance)
    )
    
    # likelihood
    y = yield tfd.Independent(
        tfd.Binomial(
            tf.cast(new_df[&#39;n&#39;],dtype),
            probs=p_angle*p_dist
        )
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;golf_angle_distance_2_jd = tfd.JointDistributionCoroutine(golf_angle_distance_2)
golf_angle_distance_2_jd_log_prob = lambda *args: golf_angle_distance_2_jd.log_prob(
    args + (tf.cast(new_df[&#39;y&#39;], dtype),)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_opt(golf_angle_distance_2_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))],
                              bijectors_list=[tfb.Exp(), tfb.Exp()])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 23min 51s, sys: 4min 30s, total: 28min 21s
Wall time: 10min 13s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_defun(golf_angle_distance_2_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))],
                              bijectors_list=[tfb.Exp(), tfb.Exp()])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 18min 56s, sys: 3min 51s, total: 22min 48s
Wall time: 8min 11s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_defun_xla(golf_angle_distance_2_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))],
                              bijectors_list=[tfb.Exp(), tfb.Exp()])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 1min 57s, sys: 38.1 s, total: 2min 35s
Wall time: 1min 6s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, XLA makes ~8x difference in speed, which is incredible for an inherently iterative process!&lt;/p&gt;

&lt;p&gt;As for the trace:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace3 = tfp_trace_to_arviz(res,[&#39;sigma_angle&#39;,&#39;sigma_distance&#39;])
az.plot_trace(trace3);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_80_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This isn&amp;rsquo;t what you want to see when inspecting a trace&amp;hellip; The chains haven&amp;rsquo;t mixed at all. Surprisingly, the Stan version had divergent transitions here, while we did not:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace3.sample_stats.diverging.sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;xarray.DataArray &#39;diverging&#39; ()&amp;gt;
array(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;model-4&#34;&gt;Model 4&lt;/h1&gt;

&lt;p&gt;In the 4th model, instead of using a binomial likelihood, we&amp;rsquo;re using a normal approximation of the binomial distribution and adding an additional noise term (read the original for a more in-depth explanation):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def golf_angle_distance_3(): 
    # priors
    sigma_angle = yield root(tfd.Sample(tfd.HalfNormal(1), 1))
    sigma_distance = yield root(tfd.Sample(tfd.HalfNormal(1), 1))
    sigma_y = yield root(tfd.Sample(tfd.HalfNormal(1), 1))
    
    # transformations
    p_angle = 2 * normal_cdf.forward(
      tf.cast(new_df[&#39;th_angle&#39;],dtype)/sigma_angle
    ) - 1
    p_dist = normal_cdf.forward(
      (distance_tol-overshot)/(tf.cast(new_df[&#39;x&#39;]+overshot,dtype)*sigma_distance)
    ) - \
    normal_cdf.forward(
      (-overshot)/(tf.cast(new_df[&#39;x&#39;]+overshot,dtype)*sigma_distance)
    )
    p = p_dist*p_angle
    
    # likelihood
    probs = yield tfd.Independent(
        tfd.Normal(p, tf.sqrt(p*(1-p)/(tf.cast(new_df[&#39;n&#39;],dtype))+sigma_y**2))
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;golf_angle_distance_3_jd = tfd.JointDistributionCoroutine(golf_angle_distance_3)

golf_angle_distance_3_jd_log_prob = lambda *args: golf_angle_distance_3_jd.log_prob(
    args + (tf.cast(new_df[&#39;y&#39;]/new_df[&#39;n&#39;], dtype),)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_opt(golf_angle_distance_3_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1)),tf.ones((n_chains,1))],
                 bijectors_list=[tfb.Exp()]*3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 3min 45s, sys: 45.6 s, total: 4min 30s
Wall time: 1min 39s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_defun(golf_angle_distance_3_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1)),tf.ones((n_chains,1))],
                 bijectors_list=[tfb.Exp()]*3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 4min 2s, sys: 48.4 s, total: 4min 50s
Wall time: 1min 46s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
res = run_nuts_defun_xla(golf_angle_distance_3_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1)),tf.ones((n_chains,1))],
                 bijectors_list=[tfb.Exp()]*3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 15.8 s, sys: 177 ms, total: 16 s
Wall time: 16.1 s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Again, XLA is simply an incredible speed up of the sampling function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trace4 = tfp_trace_to_arviz(res,[&#39;sigma_angle&#39;,&#39;sigma_distance&#39;,&#39;sigma_y&#39;])
az.plot_trace(trace4);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_91_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This looks much better:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;az.summary(trace4)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;th&gt;sd&lt;/th&gt;
      &lt;th&gt;hpd_3%&lt;/th&gt;
      &lt;th&gt;hpd_97%&lt;/th&gt;
      &lt;th&gt;mcse_mean&lt;/th&gt;
      &lt;th&gt;mcse_sd&lt;/th&gt;
      &lt;th&gt;ess_mean&lt;/th&gt;
      &lt;th&gt;ess_sd&lt;/th&gt;
      &lt;th&gt;ess_bulk&lt;/th&gt;
      &lt;th&gt;ess_tail&lt;/th&gt;
      &lt;th&gt;r_hat&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;sigma_angle[0]&lt;/th&gt;
      &lt;td&gt;0.018&lt;/td&gt;
      &lt;td&gt;0.000&lt;/td&gt;
      &lt;td&gt;0.018&lt;/td&gt;
      &lt;td&gt;0.018&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;3349.0&lt;/td&gt;
      &lt;td&gt;3348.0&lt;/td&gt;
      &lt;td&gt;3330.0&lt;/td&gt;
      &lt;td&gt;3283.0&lt;/td&gt;
      &lt;td&gt;1.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;sigma_distance[0]&lt;/th&gt;
      &lt;td&gt;0.080&lt;/td&gt;
      &lt;td&gt;0.001&lt;/td&gt;
      &lt;td&gt;0.078&lt;/td&gt;
      &lt;td&gt;0.083&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;3178.0&lt;/td&gt;
      &lt;td&gt;3169.0&lt;/td&gt;
      &lt;td&gt;3169.0&lt;/td&gt;
      &lt;td&gt;2313.0&lt;/td&gt;
      &lt;td&gt;1.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;sigma_y[0]&lt;/th&gt;
      &lt;td&gt;0.003&lt;/td&gt;
      &lt;td&gt;0.001&lt;/td&gt;
      &lt;td&gt;0.002&lt;/td&gt;
      &lt;td&gt;0.004&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;662.0&lt;/td&gt;
      &lt;td&gt;662.0&lt;/td&gt;
      &lt;td&gt;656.0&lt;/td&gt;
      &lt;td&gt;675.0&lt;/td&gt;
      &lt;td&gt;1.01&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We&amp;rsquo;ll extract the mean parameters from the summary, and plot the resulting function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mean_sigma_angle, mean_sigma_dist, mean_sigma_y = az.summary(trace4)[&#39;mean&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;normal_cdf = tfb.NormalCDF()

p_angle = 2 * normal_cdf.forward(
    tf.cast(new_df[&#39;th_angle&#39;],dtype)/mean_sigma_angle
)-1

p_dist = normal_cdf.forward(
    (distance_tol-overshot)/(tf.cast(new_df[&#39;x&#39;]+overshot,dtype)*mean_sigma_dist)
) - \
normal_cdf.forward(
    (-overshot)/(tf.cast(new_df[&#39;x&#39;]+overshot,dtype)*mean_sigma_dist)
)
mean_p = (p_dist*p_angle).numpy()
std_p = (tf.sqrt(mean_p*(1-mean_p)/(tf.cast(new_df[&#39;n&#39;],dtype))+mean_sigma_y**2)).numpy()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.scatter(new_df[&#39;x&#39;],new_df[&#39;y&#39;]/new_df[&#39;n&#39;],label=&#39;data&#39;)
plt.errorbar(new_df[&#39;x&#39;],mean_p,yerr=std_p,c=&#39;k&#39;,label=&#39;model 4&#39;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_97_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is, by all means, a very impressive fit. And the errorbars are there, they&amp;rsquo;re just too small we can&amp;rsquo;t actually see them. Definitely not bad for a 3 parameters model.&lt;/p&gt;

&lt;h1 id=&#34;comparison-summary&#34;&gt;Comparison summary&lt;/h1&gt;

&lt;p&gt;This is a summary of the different timings:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Model 1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Model 2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Model 3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Model 4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;without tf.function&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;793&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;tf.function, autograph=True&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18.7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.96&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;613&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;99&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;tf.function, autograph=False&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17.9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;strong&gt;3.93&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;491&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;106&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;tf.function + XLA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;strong&gt;6.39&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.38&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;strong&gt;66&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;strong&gt;16&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;So XLA compilation is a clear winner. Running the same models with 256 chains instead of 10 (very easy to do with TFP) gives qualitatively similar results.&lt;/p&gt;

&lt;h1 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h1&gt;

&lt;p&gt;In this post we&amp;rsquo;ve tried to replicate Stan&amp;rsquo;s awesome golf tutorial. Along the way, we saw how to work with the new NUTS kernel, how to speed it up using &lt;code&gt;tf.function&lt;/code&gt; and XLA compilation, how to use the &lt;code&gt;trace_fn&lt;/code&gt; to generated quantities of interest, and how to use ArviZ to handle all the plotting for us.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
