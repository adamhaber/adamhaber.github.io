[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a PhD student at Weizmann Institute of Science, under the supervision of Prof. Elad Schneidman. I have a BA in Physics and Mathematics from the Hebrew University. My work focuses on finding principles underlying structure-to-function relations in small neuronal networks. To address such questions, I combine simulation-based approaches with more information-theoretical tools and maximum entropy modelling.\nI also work as a data scientist at Atidot, mostly working on machine-learning approaches to actuarial challenges such as mortality risk assessment and churn prediction.\nBesides my own research topics, I\u0026rsquo;m very interested in scientific computing in general, and probabilistic programming in particular. I constantly try to expand my knowledge in statistics and probability theory, mostly by following interesting people on Twitter (and refs within). I especially enjoy (but rarely truly understand) topics that lie at the intersection of statistics and geometry, such as information geometry and computational optimal transport.\nI\u0026rsquo;m married to Inbar, and together we\u0026rsquo;re running a life-long longitudinal study on a pair of twins. I love hiking, rock climbing, eating, and dogs.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://adamhaber.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m a PhD student at Weizmann Institute of Science, under the supervision of Prof. Elad Schneidman. I have a BA in Physics and Mathematics from the Hebrew University. My work focuses on finding principles underlying structure-to-function relations in small neuronal networks. To address such questions, I combine simulation-based approaches with more information-theoretical tools and maximum entropy modelling.\nI also work as a data scientist at Atidot, mostly working on machine-learning approaches to actuarial challenges such as mortality risk assessment and churn prediction.","tags":null,"title":"Adam Haber","type":"authors"},{"authors":null,"categories":null,"content":"TL;DR The new Stan compiler has an alternative backend that allows you to do this:\nstan2tfp is a lightwight interface for this compiler, that allows you to do this with one line of code, and fit the model to data with another.\nWhy stan2tfp In short - to get the convenience of Stan programs and the scalability of TensorFlow. The model is written in Stan, which means you get a lot of the benefits of having the Stan compiler behind your shoulder (types, bounds, etc). This comes practically for free, since there\u0026rsquo;s no C++ compilation. After the model is converted to TensorFlow Probability code, you sit on top of the entire TF infrastructure, which has many advantages. For example, moving from 4 chains to more than a thousand is practically free.\nNote that the TFP backend of the Stan compiler is still in its infancy. It only supports a subset of the distributions covered by Stan, and only minimal parts of the language. Expect bugs and sharp edges. Please help by trying it out, reporting bugs, and letting me know what you think!\nHow stan2tfp works stan2tfp is just a wrapper, it doesn\u0026rsquo;t do anything smart by itself; all the actual work is done by the compiler, which was written the Stan Development Team. The core functionality can be summarized as follows:\nCode generation We first create a Stan2tfp Python object. It \u0026ldquo;eats\u0026rdquo; a Stan program (string/file), calls the compiler, \u0026ldquo;catches\u0026rdquo; the emitted TFP code (from stdout) and saves it as a Python string. In the process, it checks for the compiler - if it\u0026rsquo;s not found, stan2tfp will download it for you. This only needs to happen once.\nEvaluation by the interpreter The string that represents the model is then evaled by the Python interpreter. This creates a Python object in the current namespace. Note that the model is still not instantiated - we haven\u0026rsquo;t passed any data, so we can\u0026rsquo;t sample from the model. The eval is packed within the constructor, and the compiler doesn\u0026rsquo;t emit any \u0026ldquo;hazardous code\u0026rdquo;, so using it is safe.\nInstantiating and fitting the model To fit the model, we need to pass a data dictionary either to the Stan2tfp constructor, or to the init_model function. After the data is passed, we can call sample, which wraps TFP\u0026rsquo;s MCMC machinery, aiming for sensible defaults and ease-of-use. At this point, we left Stan-world completely, and everything is TFP-ed - the model, the inference algorithm, etc.\nBasic example To illustrate the basic functionallity, we\u0026rsquo;ll fit the eight schools model (the \u0026ldquo;hello world\u0026rdquo; of bayesian models) using stan2tfp.\nWe begin by importing stan2tfp, and some plotting functionality:\nfrom stan2tfp import Stan2tfp import seaborn as sns import matplotlib.pyplot as plt import arviz as az Here\u0026rsquo;s the original Stan model:\ndata { int\u0026lt;lower=0\u0026gt; J; real y[J]; real\u0026lt;lower=0\u0026gt; sigma[J]; } parameters { real mu; real\u0026lt;lower=0\u0026gt; tau; vector[J] theta_tilde; } transformed parameters { vector[J] theta = mu + tau * theta_tilde; } model { mu ~ normal(0, 5); tau ~ normal(0, 5); theta_tilde ~ normal(0, 1); y ~ normal(theta, sigma); } The data is specified using a Python dictionary:\neight_schools_data_dict = dict( J=8, y=[28, 8, -3, 7, -1, 1, 18, 12], sigma=[15, 10, 16, 11, 9, 11, 10, 18] ) Finally, the model object itself is created:\nmodel = Stan2tfp( stan_file_path=\u0026#34;eight_schools.stan\u0026#34;, data_dict=eight_schools_data_dict ) Downloading the latest stan2tfp compiler... Download complete, saved to: /Users/adamhaber/projects/stan2tfp/stan2tfp/stan2tfp_compiler.exe Compiling stan file to tfp file... The emitted TFP code is accessible via get_tfp_code() (see the picture at the top of the post). This code is then evaled by the interpreter and creates the necessary Python objects in the current namespace. We can now call sample to fit the model:\nmcmc_trace, kernel_results = model.sample() model.sample returns the actual samples (mcmc_trace) and TFP\u0026rsquo;s kernel_results (holding important sampler diagnostics). Since we\u0026rsquo;re in TFP-world now, we can use any tool from the TFP ecosystem we like; specifically, we can use the excellent Arviz library for plotting the results:\ndata_for_az = az.from_tfp(posterior=mcmc_trace, var_names=[\u0026#39;mu\u0026#39;,\u0026#39;trace\u0026#39;,\u0026#39;theta_tilde\u0026#39;]) az.plot_forest(data_for_az) That\u0026rsquo;s it. I\u0026rsquo;ll probably post some benchmarks and comparisons in the near future.\n","date":1590019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590019200,"objectID":"49ebe4cfbd0c9a51a05a8c2ae4f6bfa1","permalink":"https://adamhaber.github.io/post/stan2tfp-post1/","publishdate":"2020-05-21T00:00:00Z","relpermalink":"/post/stan2tfp-post1/","section":"post","summary":"TL;DR The new Stan compiler has an alternative backend that allows you to do this:\nstan2tfp is a lightwight interface for this compiler, that allows you to do this with one line of code, and fit the model to data with another.\nWhy stan2tfp In short - to get the convenience of Stan programs and the scalability of TensorFlow. The model is written in Stan, which means you get a lot of the benefits of having the Stan compiler behind your shoulder (types, bounds, etc).","tags":["TFP","Stan","Bayesian Models"],"title":"Introducing Stan2tfp - a lightweight interface for the Stan-to-TensorFlow Probability compiler","type":"post"},{"authors":null,"categories":null,"content":"TL;DR We\u0026rsquo;ll:\n Learn an interesting method for generalizing inferences from a biased sample to a population of interest See why prior predictive checks are great Implement a simple mixed-effects model in TFP  Intro This post is a TFP port of Lauren Kennedy and Jonah Gabry\u0026rsquo;s excellent MRP with rstanarm vignette. It describes a very interesting statistical method for generalizing inferences from a biased sample to a population of interest. The method is called multilevel regression with poststratification, or MRP if you prefer acronyms, or Mister P if you prefer statisticians jokes. Along the way, we\u0026rsquo;ll see why prior predictive checks are so nice and important, how to implement a mixed-effect model in TFP, and how to make predictions for smaller sub-populations.\nI chose to port the vignette because the problem MRP address - generalizing from a biased sample to a population - is so prevalent and important, that knowing what are the possible tools to handle it seemed valuable. I found that porting models from one language to another is an excellent way to learn the model, the problem, and the languages themselves, so it\u0026rsquo;s kind of a win-win-win and publishing it might also help others so why not.\nI strongly recommend reading the original vignette; the people who wrote it are much more knowledgeable than I am about this subject, and I also chose to focus on slightly different things so they\u0026rsquo;re not 100% overlapping. At the end of this post you can find links for further reading.\nImports and helper functions - data generation from collections import namedtuple import numpy as np import itertools as it import pandas as pd from scipy.special import expit as inv_logit from scipy.stats import sem import seaborn as sns import matplotlib.pyplot as plt np.random.seed(98) sns.set_palette(\u0026#34;muted\u0026#34;) params = { \u0026#39;legend.fontsize\u0026#39;: \u0026#39;x-large\u0026#39;, \u0026#39;figure.figsize\u0026#39;: (9, 6), \u0026#39;axes.labelsize\u0026#39;: \u0026#39;x-large\u0026#39;, \u0026#39;axes.titlesize\u0026#39;:\u0026#39;x-large\u0026#39;, \u0026#39;xtick.labelsize\u0026#39;:\u0026#39;x-large\u0026#39;, \u0026#39;ytick.labelsize\u0026#39;:\u0026#39;x-large\u0026#39; } plt.rcParams.update(params) %config InlineBackend.figure_format = \u0026#39;retina\u0026#39; The data The data we\u0026rsquo;ll work with is simulated data; this has the obvious advantage that we know the ground truth so we\u0026rsquo;ll be able to assess just how well our method generalizes to the population. The data describes the proportion of the population who would choose to adopt a cat over a dog, given the opportunity. Our outcome variable in this example is binary (cat/dog), but MRP is not restricted to such outcomes and can be used for discrete outcomes with more than two values, as well as continuous outcomes.\nThese are the variables we\u0026rsquo;ll be working with:\nsex = range(2) eth = range(3) age = range(7) income = range(3) state = range(50) They\u0026rsquo;re all categorical; we use zero-based indexing to enumerate them (instead of calling them \u0026lsquo;Male\u0026rsquo;, \u0026lsquo;Female\u0026rsquo; etc) because it\u0026rsquo;ll make all the indexing gymnastics in the actual implementation somewhat simpler.\npoststrat is a dataframe containing all $2\\times3\\times7\\times3\\times50=6300$ possible combinations of these variables:\npoststrat = pd.DataFrame( list(it.product(sex, eth, age, income, state)), columns=[\u0026#34;sex\u0026#34;, \u0026#34;eth\u0026#34;, \u0026#34;age\u0026#34;, \u0026#34;income\u0026#34;, \u0026#34;state\u0026#34;], ) poststrat.sample(5)     sex eth age income state     4675 1 1 3 0 25   1620 0 1 3 2 20   1749 0 1 4 1 49   1141 0 1 0 1 41   2460 0 2 2 1 10    poststrat.shape (6300, 5)  Below are the different proportions of the different variables in the population. For example, 20% of the population are in the first age group, 10% are in the second, etc. For each combination of variables we\u0026rsquo;ll compute the number of people that share this specific combination by multiplying the total number of people in the population (assumed to be 250 million) with the different probabilities (this means we\u0026rsquo;re assuming the joint probability distribution factorizes, that is - that the different variables are independent).\np_age = np.array([0.2, 0.1, 0.2, 0.2, 0.10, 0.1, 0.1]) p_sex = np.array([0.52, 0.48]) p_eth = np.array([0.5, 0.2, 0.3]) p_income = np.array([0.50, 0.35, 0.15]) p_state_tmp = np.random.uniform(low=10, high=20, size=50) p_state = np.array(p_state_tmp / p_state_tmp.sum()) poststrat[\u0026#34;N\u0026#34;] = ( 250e6 * p_sex[poststrat[\u0026#34;sex\u0026#34;]] * p_eth[poststrat[\u0026#34;eth\u0026#34;]] * p_age[poststrat[\u0026#34;age\u0026#34;]] * p_income[poststrat[\u0026#34;income\u0026#34;]] * p_state[poststrat[\u0026#34;state\u0026#34;]] ) We also assume that different groups have different probabilities of being included in the sample; in a way, that\u0026rsquo;s the entire point (if all groups had the same probability of being included in the sample then the sample was representative of the population). There\u0026rsquo;s a baseline probability of being in the sample, but it cancels out in the weighted average; what determines who is in our sample is p_response_weighted, which is p_response weighted by the number of people in each group:\np_response_baseline = 0.01 p_response_sex = np.array([2, 0.8]) / 2.8 p_response_eth = np.array([1, 1.2, 2.5]) / 4.7 p_response_age = np.array([1, 0.4, 1, 1.5, 3, 5, 7]) / 18.9 p_response_inc = np.array([1, 0.9, 0.8]) / 2.7 p_response_state = np.random.beta(a=1, b=1, size=50) p_response_state = p_response_state / p_response_state.sum() p_response = ( p_response_baseline * p_response_sex[poststrat[\u0026#34;sex\u0026#34;]] * p_response_eth[poststrat[\u0026#34;eth\u0026#34;]] * p_response_age[poststrat[\u0026#34;age\u0026#34;]] * p_response_inc[poststrat[\u0026#34;income\u0026#34;]] * p_response_state[poststrat[\u0026#34;state\u0026#34;]] ) p_response_weighted = poststrat[\u0026#34;N\u0026#34;] * p_response / (poststrat[\u0026#34;N\u0026#34;] * p_response).sum() We now sample 1200 individuals from the entire population. This means we\u0026rsquo;re actually sampling rows from our poststrat dataframe with different probabilities given by p_response_weighted:\nn = 1200 people = np.random.choice( np.arange(poststrat.shape[0]), size=n, replace=True, p=p_response_weighted ) sample = poststrat.drop(\u0026#34;N\u0026#34;, axis=1).iloc[people].reset_index() sample.sample(5)     index sex eth age income state     520 2141 0 2 0 0 41   287 2626 0 2 3 1 26   870 2591 0 2 3 0 41   69 1517 0 1 3 0 17   169 4104 1 0 6 1 4    Now we\u0026rsquo;re getting to the thing we\u0026rsquo;ll actually measure in the sample (and then try to generalize to the population) - cat preference. Below are the coefficients of a regression model that determines the log-odds of cat preference, $\\log\\frac{P(\\text{prefers cats})}{P(\\text{prefers dogs})}$ for each group in the population. We\u0026rsquo;ll use these coefficients to compute the actual probability of cats preference for each group:\ncoef_sex = np.array([0, -0.3]) coef_eth = np.array([0, 0.6, 0.9]) coef_age = np.array([0, -0.2, -0.3, 0.4, 0.5, 0.7, 0.8, 0.9]) coef_income = np.array([0, -0.2, 0.6]) coef_state = np.insert(np.random.normal(0, 1, 49).round(1), 0, 0) coef_age_sex = np.vstack( [ np.array([0, 0.1, 0.23, 0.3, 0.43, 0.5, 0.6]), np.array([0, -0.1, -0.23, -0.5, -0.43, -0.5, -0.6]), ] ).T true_pop = poststrat.drop(\u0026#34;N\u0026#34;, axis=1) true_pop[\u0026#34;cat_pref\u0026#34;] = inv_logit( coef_sex[true_pop[\u0026#34;sex\u0026#34;]] + coef_eth[true_pop[\u0026#34;eth\u0026#34;]] + coef_age[true_pop[\u0026#34;age\u0026#34;]] + coef_income[true_pop[\u0026#34;income\u0026#34;]] + coef_state[true_pop[\u0026#34;state\u0026#34;]] + coef_age_sex[true_pop[\u0026#34;age\u0026#34;], true_pop[\u0026#34;sex\u0026#34;]] ) true_pop.sample(5)     sex eth age income state cat_pref     6124 1 2 5 2 24 0.71095   177 0 0 1 0 27 0.549834   5755 1 2 3 1 5 0.331812   2102 0 2 0 0 2 0.802184   3931 1 0 5 0 31 0.524979    We now use the computed probabilities to determine, for each individual in our sample, whether she\u0026rsquo;s a cats person or a dogs person. Note that this is still the fake data generation part; we\u0026rsquo;re not modelling anything yet.\nsample[\u0026#34;cat_pref\u0026#34;] = np.random.binomial(n=1, p=true_pop[\u0026#34;cat_pref\u0026#34;][people], size=n) sample.head()     index sex eth age income state cat_pref     0 671 0 0 4 1 21 1   1 2141 0 2 0 0 41 1   2 906 0 0 6 0 6 1   3 3062 0 2 6 1 12 1   4 6043 1 2 5 0 43 1    Just to get a glimpse of the problem Mr. P is trying to solve, the sample mean is:\nsample[\u0026#34;cat_pref\u0026#34;].mean() 0.7083333333333334  While the true mean in the population (which is a weighted sum of the per-group probabilities and the group sizes) is:\ntrue_pop_pref = sum(true_pop[\u0026#34;cat_pref\u0026#34;] * poststrat[\u0026#34;N\u0026#34;]) / sum(poststrat[\u0026#34;N\u0026#34;]) true_pop_pref 0.5941253009200917  So our sample overestimates cats-lovin\u0026rsquo; in the population by 18% - people who like cats also like taking surveys.\nVisualizations To get a better understanding of the problem (unrepresentativeness of the sample), we\u0026rsquo;ll plot some summary statistics and see how they differ:\nf, ax = plt.subplots(1, 4, figsize=(12, 3)) pd.DataFrame( dict(pop=pd.Series(p_age), sample=(sample.age.value_counts().sort_index() / n)) ).plot(kind=\u0026#34;bar\u0026#34;, ax=ax[0], title=\u0026#34;age\u0026#34;) pd.DataFrame( dict(pop=pd.Series(p_eth), sample=(sample.eth.value_counts().sort_index() / n)) ).plot(kind=\u0026#34;bar\u0026#34;, ax=ax[1], legend=False, title=\u0026#34;ethnicity\u0026#34;) pd.DataFrame( dict( pop=pd.Series(p_income), sample=(sample.income.value_counts().sort_index() / n) ) ).plot(kind=\u0026#34;bar\u0026#34;, ax=ax[2], legend=False, title=\u0026#34;income\u0026#34;) pd.DataFrame( dict(pop=pd.Series(p_sex), sample=(sample.sex.value_counts().sort_index() / n)) ).plot(kind=\u0026#34;bar\u0026#34;, ax=ax[3], legend=False, title=\u0026#34;sex\u0026#34;) plt.tight_layout() At least by eyeballing the charts, the differences seem substantial; for example, if there\u0026rsquo;s a big difference in cats preference between males and females, we expect to see a substantial difference between the cats preference in the sample and in the population.\nWe can also plot how cats preference changes between different groups within our sample - for example, is there a difference in cats preference between different age groups? (yes there is)\nf, axes = plt.subplots(1, 4, figsize=(12, 3), sharey=True) for key, ax in zip([\u0026#34;age\u0026#34;, \u0026#34;eth\u0026#34;, \u0026#34;income\u0026#34;, \u0026#34;sex\u0026#34;], axes): sample.groupby(key)[\u0026#34;cat_pref\u0026#34;].agg(dict(mean=np.mean, std=sem)).reset_index().plot( kind=\u0026#34;bar\u0026#34;, x=key, y=\u0026#34;mean\u0026#34;, yerr=\u0026#34;std\u0026#34;, ax=ax, legend=False ) plt.ylim(0, 1) plt.tight_layout() The model We now turn to the MR part of MRP - the multilevel regression part. More specifically, we\u0026rsquo;ll build a Bayesian multilevel logistic regression model of cats preference. Even more specifically, we\u0026rsquo;ll build what\u0026rsquo;s called a \u0026ldquo;mixed effects\u0026rdquo; model. Mixed effects models are one of those places that, at least for me, the statisticians terminology is extremely confusing; it also seems to be inconsistent between different academic fields. I usually find it easier to look at the actual model specification to understand what\u0026rsquo;s going on:\nFor each group $j\\in\\left[1,\u0026hellip;,6300\\right]$ we model the probability of cats preference as\n$$ \\begin{align} \\theta_j \u0026amp; = logit^{-1}( \\alpha + X_{j}\\beta\n \\alpha_{\\rm state[j]}^{\\rm state} \\alpha_{\\rm age[j]}^{\\rm age} \\alpha_{\\rm eth[j]}^{\\rm eth} \\alpha_{\\rm inc[j]}^{\\rm inc} ) \\\\\\\n\\alpha_{\\rm state[j]}^{\\rm state} \u0026amp; \\sim N(0,\\sigma^{\\rm state}) \\\\\\\n\\alpha_{\\rm age[j]}^{\\rm age} \u0026amp; \\sim N(0,\\sigma^{\\rm age})\\\\\\\n\\alpha_{\\rm eth[j]}^{\\rm eth} \u0026amp; \\sim N(0,\\sigma^{\\rm eth})\\\\\\\n\\alpha_{\\rm inc[j]}^{\\rm inc} \u0026amp;\\sim N(0,\\sigma^{\\rm inc}) \\\\\\\n\\sigma^{\\rm state} \u0026amp; \\sim {\\rm HalfNormal}(1) \\\\\\\n\\sigma^{\\rm age} \u0026amp; \\sim {\\rm HalfNormal}(1) \\\\\\\n\\sigma^{\\rm eth} \u0026amp; \\sim {\\rm HalfNormal}(1) \\\\\\\n\\sigma^{\\rm income} \u0026amp; \\sim {\\rm HalfNormal}(1) \\\\\\\n\\beta \u0026amp; \\sim N(0,2.5) \\\\\\\n\\alpha \u0026amp; \\sim N(0,10) \\\\\\\n\\end{align} $$  We\u0026rsquo;ve seen expressions like $\\alpha_{\\rm state[j]}^{\\rm state}$ when we\u0026rsquo;ve implemented varying intercepts models. What makes this a \u0026ldquo;mixed effects\u0026rdquo; models is that $\\beta$ is the same $\\beta$ for all groups, while the different $\\alpha^*$-s vary between groups. I\u0026rsquo;m sure there are subtleties and nuances that this doesn\u0026rsquo;t capture, but for me this is a simple-to-read, simple-to-implement explanation of mixed effects models.\nAs for the model itself:\n $X$ is a (binary) design matrix that holds indicators for sex, age and sex-age interactions - we\u0026rsquo;ll construct it in a second. $\\alpha$ is an intercept term. $\\beta$ is a coefficient vector. The different $\\alpha^*$-s are per-group varying intercepts. The different $\\sigma^*$-s are hyperpriors for variation between groups.  The priors on $\\alpha,\\beta$ are rstanarm\u0026rsquo;s default priors; I couldn\u0026rsquo;t find rstanarm\u0026rsquo;s default prior on the $\\sigma^*$ so I chose to use a halfnormal(1) prior.\nOur design matrix $X$ will represent a one-hot-encoded representation of the sampled individuals sex, age, and sex-age interaction term. Here\u0026rsquo;s how it looks like:\nfactors = pd.get_dummies(sample[[\u0026#34;sex\u0026#34;, \u0026#34;age\u0026#34;]].astype(\u0026#34;category\u0026#34;)).drop( [\u0026#34;sex_0\u0026#34;, \u0026#34;age_0\u0026#34;], axis=1 ) interactions = pd.DataFrame( factors.drop(\u0026#34;sex_1\u0026#34;, axis=1).values * factors[\u0026#34;sex_1\u0026#34;].values[:, None], columns=[f\u0026#34;sex_1*age_{i+1}\u0026#34; for i in range(6)], ) features = pd.concat([factors, interactions], axis=1) features.head()     sex_1 age_1 age_2 age_3 age_4 age_5 age_6 sex_1*age_1 sex_1*age_2 sex_1*age_3 sex_1*age_4 sex_1*age_5 sex_1*age_6     0 0 0 0 0 1 0 0 0 0 0 0 0 0   1 0 0 0 0 0 0 0 0 0 0 0 0 0   2 0 0 0 0 0 0 1 0 0 0 0 0 0   3 0 0 0 0 0 0 1 0 0 0 0 0 0   4 1 0 0 0 0 1 0 0 0 0 0 1 0    features.shape (1200, 13)  To make TF shape issues simpler, we convert it to a numpy array and transpose it:\nfeatures = features.values.T Imports and helper functions - inference import tensorflow as tf import tensorflow_probability as tfp from tensorflow_probability import distributions as tfd from tensorflow_probability import bijectors as tfb import arviz as az n_chains = 4 dtype = tf.float32 def step_size_setter_fn(pkr, new_step_size): return pkr._replace( inner_results=pkr.inner_results._replace(step_size=new_step_size) ) factors = pd.get_dummies(sample[[\u0026#34;sex\u0026#34;, \u0026#34;age\u0026#34;]].astype(\u0026#34;category\u0026#34;)).drop( [\u0026#34;sex_0\u0026#34;, \u0026#34;age_0\u0026#34;], axis=1 ) interactions = pd.DataFrame( factors.drop(\u0026#34;sex_1\u0026#34;, axis=1).values * factors[\u0026#34;sex_1\u0026#34;].values[:, None], columns=[f\u0026#34;sex_1*age_{i}\u0026#34; for i in range(6)], ) features = pd.concat([factors, interactions], axis=1).values.T def trace_fn(current_samp, pkr): return ( pkr.inner_results.inner_results.target_log_prob, pkr.inner_results.inner_results.leapfrogs_taken, pkr.inner_results.inner_results.has_divergence, pkr.inner_results.inner_results.energy, pkr.inner_results.inner_results.log_accept_ratio, ) @tf.function(experimental_compile=True) def run_nuts(target_log_prob_fn, initial_states, bijectors_list): step_sizes = [1e-2 * tf.ones_like(i) for i in initial_states] kernel = tfp.mcmc.TransformedTransitionKernel( tfp.mcmc.nuts.NoUTurnSampler(target_log_prob_fn, step_size=step_sizes), bijector=bijectors_list, ) kernel = tfp.mcmc.DualAveragingStepSizeAdaptation( kernel, target_accept_prob=tf.cast(0.8, dtype=dtype), num_adaptation_steps=800, step_size_setter_fn=step_size_setter_fn, step_size_getter_fn=lambda pkr: pkr.inner_results.step_size, log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio, ) # Sampling from the chain. mcmc_trace, pkr = tfp.mcmc.sample_chain( num_results=1000, num_burnin_steps=1000, current_state=[ bijector.forward(state) for bijector, state in zip(bijectors_list, initial_states) ], kernel=kernel, trace_fn=trace_fn, ) return mcmc_trace, pkr # using pymc3 naming conventions, with log_likelihood instead of lp so that ArviZ can compute loo and waic sample_stats_name = [ \u0026#34;log_likelihood\u0026#34;, \u0026#34;tree_size\u0026#34;, \u0026#34;diverging\u0026#34;, \u0026#34;energy\u0026#34;, \u0026#34;mean_tree_accept\u0026#34;, ] def tfp_trace_to_arviz(tfp_trace, var_names=None, sample_stats_name=sample_stats_name): samps, trace = tfp_trace if var_names is None: var_names = [\u0026#34;var \u0026#34; + str(x) for x in range(len(samps))] sample_stats = {k: v.numpy().T for k, v in zip(sample_stats_name, trace)} posterior = { name: tf.transpose(samp, [1, 0, 2]).numpy() for name, samp in zip(var_names, samps) } return az.from_dict(posterior=posterior, sample_stats=sample_stats) For more details about calling TFP\u0026rsquo;s NUTS sampler, and the helper functions defined above, see here.\nFirst implemetation We now turn to implement the whole model in TFP. Since there aren\u0026rsquo;t many complicated intermediate calculations, a JointDistributionSequential is a reasonable choice for implementing the model. For a more detailed explanation on the different JointDistribution alternatives, see this post.\nmodel = tfd.JointDistributionSequential( [ tfd.HalfNormal(1), # sigma_state lambda sigma_state: tfd.Sample(tfd.Normal(0, sigma_state), sample_shape=50), tfd.HalfNormal(1), # sigma_eth lambda sigma_eth: tfd.Sample(tfd.Normal(0, sigma_eth), sample_shape=3), tfd.HalfNormal(1), # sigma_income lambda sigma_income: tfd.Sample(tfd.Normal(0, sigma_income), sample_shape=3), tfd.HalfNormal(1), # sigma_age lambda sigma_age: tfd.Sample(tfd.Normal(0, sigma_age), sample_shape=7), tfd.Normal(0, 10), # intercept tfd.Sample(tfd.Normal(0, 2.5), sample_shape=13), # coeffs lambda coeffs, intercept, coef_age, sigma_age, coef_income, sigma_income, coef_eth, sigma_eth, coef_state: tfd.Independent( tfd.Binomial( total_count=1, logits=intercept[:, tf.newaxis] + coeffs @ tf.cast(features, tf.float32) + tf.squeeze( tf.gather(coef_age, tf.cast(sample[\u0026#34;age\u0026#34;], tf.int32), axis=-1) ) + tf.squeeze( tf.gather(coef_income, tf.cast(sample[\u0026#34;income\u0026#34;], tf.int32), axis=-1) ) + tf.squeeze( tf.gather(coef_eth, tf.cast(sample[\u0026#34;eth\u0026#34;], tf.int32), axis=-1) ) + tf.squeeze( tf.gather(coef_state, tf.cast(sample[\u0026#34;state\u0026#34;], tf.int32), axis=-1) ), ), reinterpreted_batch_ndims=1, ), ] ) The model description isn\u0026rsquo;t short, but it doesn\u0026rsquo;t contain anything we haven\u0026rsquo;t covered in previous posts. Let\u0026rsquo;s call .sample and .log_prob just to make sure everything works:\n[s.shape for s in model.sample(n_chains)] [TensorShape([4]), TensorShape([4, 50]), TensorShape([4]), TensorShape([4, 3]), TensorShape([4]), TensorShape([4, 3]), TensorShape([4]), TensorShape([4, 7]), TensorShape([4]), TensorShape([4, 13]), TensorShape([4, 1200])]  model.log_prob(model.sample(n_chains)) \u0026lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-121.06135 , 21.950146, -69.38415 , -224.08742 ], dtype=float32)\u0026gt;  So our model technically works\u0026hellip; but does it makes sense?\nPrior predictive checks Prior predictive checks are an extremely valuable technique to assess your model and your priors, before seeing any data. To learn more about PPCs (horrible acronym as the first P can also stand for posterior), I highly recommend Michael Betancourt\u0026rsquo;s principled bayesian workflow case study.\nAnyway, let\u0026rsquo;s generate samples from our model, and use the samples to compute the logits (the linear expression within the inv_logit function):\ninits = model.sample(n_chains) coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state = inits[1:10][ ::-1 ] logits = ( intercept[:, tf.newaxis] + coeffs @ tf.cast(features, tf.float32) + tf.squeeze(tf.gather(coef_age, tf.cast(sample[\u0026#34;age\u0026#34;], tf.int32), axis=-1)) + tf.squeeze(tf.gather(coef_income, tf.cast(sample[\u0026#34;income\u0026#34;], tf.int32), axis=-1)) + tf.squeeze(tf.gather(coef_eth, tf.cast(sample[\u0026#34;eth\u0026#34;], tf.int32), axis=-1)) + tf.squeeze(tf.gather(coef_state, tf.cast(sample[\u0026#34;state\u0026#34;], tf.int32), axis=-1)) ) Each chain gives us 1200 different numbers - the log-odds for cat preference for our 1200 sampled individuals. Let\u0026rsquo;s plot these four histograms:\nfor i, l in enumerate(logits): sns.distplot(l, bins=30, label=f\u0026#34;from chain {i}\u0026#34;) plt.legend() plt.xlabel(\u0026#34;${\\\\rm logit}\\\\left(\\\\theta_j\\\\right)$\u0026#34;) lim = plt.xlim(); Note that it\u0026rsquo;s OK that each color (each chain) is multimodal - this just means that we\u0026rsquo;re inferring different \u0026ldquo;types\u0026rdquo; of cats preference across groups.\nThe problem with what we got is the scale - having ${\\rm logit}\\left(\\theta_j\\right)=-15$ means $\\theta_j=0.000000003\u0026hellip;$ which doesn\u0026rsquo;t really makes sense, even for a group that really likes dogs. This implies that our priors are way too diffuse, the normal(0,10) being the primary suspect. So let\u0026rsquo;s make everything normal(0,1) and do this again:\nSame likelihood, better priors model = tfd.JointDistributionSequential( [ tfd.HalfNormal(1), # sigma_state lambda sigma_state: tfd.Sample(tfd.Normal(0, sigma_state), sample_shape=50), tfd.HalfNormal(1), # sigma_eth lambda sigma_eth: tfd.Sample(tfd.Normal(0, sigma_eth), sample_shape=3), tfd.HalfNormal(1), # sigma_income lambda sigma_income: tfd.Sample(tfd.Normal(0, sigma_income), sample_shape=3), tfd.HalfNormal(1), # sigma_age lambda sigma_age: tfd.Sample(tfd.Normal(0, sigma_age), sample_shape=7), tfd.Normal(0, 1), # intercept tfd.Sample(tfd.Normal(0, 1), sample_shape=13), # coeffs lambda coeffs, intercept, coef_age, a, coef_income, b, coef_eth, c, coef_state: tfd.Independent( tfd.Binomial( total_count=1, logits=intercept[:, tf.newaxis] + coeffs @ tf.cast(features, tf.float32) + tf.squeeze( tf.gather(coef_age, tf.cast(sample[\u0026#34;age\u0026#34;], tf.int32), axis=-1) ) + tf.squeeze( tf.gather(coef_income, tf.cast(sample[\u0026#34;income\u0026#34;], tf.int32), axis=-1) ) + tf.squeeze( tf.gather(coef_eth, tf.cast(sample[\u0026#34;eth\u0026#34;], tf.int32), axis=-1) ) + tf.squeeze( tf.gather(coef_state, tf.cast(sample[\u0026#34;state\u0026#34;], tf.int32), axis=-1) ), ), reinterpreted_batch_ndims=1, ), ] ) inits = model.sample(n_chains) coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state = inits[1:10][ ::-1 ] logits = ( intercept[:, tf.newaxis] + coeffs @ tf.cast(features, tf.float32) + tf.squeeze(tf.gather(coef_age, tf.cast(sample[\u0026#34;age\u0026#34;], tf.int32), axis=-1)) + tf.squeeze(tf.gather(coef_income, tf.cast(sample[\u0026#34;income\u0026#34;], tf.int32), axis=-1)) + tf.squeeze(tf.gather(coef_eth, tf.cast(sample[\u0026#34;eth\u0026#34;], tf.int32), axis=-1)) + tf.squeeze(tf.gather(coef_state, tf.cast(sample[\u0026#34;state\u0026#34;], tf.int32), axis=-1)) ) for i, l in enumerate(logits): sns.distplot(l, bins=30, label=f\u0026#34;from chain {i}\u0026#34;) plt.legend() plt.xlabel(\u0026#34;${\\\\rm logit}\\\\left(\\\\theta_j\\\\right)$\u0026#34;) plt.xlim(*lim); This makes much more sense. The variance between groups is still there but it doesn\u0026rsquo;t spread across several order of magnitude (that is, with this prior it\u0026rsquo;s no longer plausible that some groups love cats 10 million times more than other groups). This seems like a good starting point.\nNote that the overly wide priors are also very problematic, inference wise - running the same notebook with the first model returns all sorts of sampling problems (divergent transitions, bad mixing, random seed dependence etc) while the 2nd, more informed version does not.\nGetting the shapes right This is, by far, the hardest thing for me when building a probablistic model with TFP. Knowing where to put [...,], tf.newaxis or [None,] requires some trial and error - here are some checks to verify we got this right (after a lot of failed attempts and some help from Junpeng Lao):\nFirst, we want to make sure the model can evaluate the log probability of its own samples, and that we get n_chains different numbers:\nmodel.log_prob(inits) \u0026lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-619.5229 , -520.8101 , -460.97076, -609.21765], dtype=float32)\u0026gt;  Second, we want to make sure that all shapes of the different parameters in our samples are as we expect, which basically should be the number of chains in the first axis and the shape of whatever it is we\u0026rsquo;re sampling in the rest - or nothing, if it\u0026rsquo;s just a scalar:\n[s.shape for s in inits] [TensorShape([4]), TensorShape([4, 50]), TensorShape([4]), TensorShape([4, 3]), TensorShape([4]), TensorShape([4, 3]), TensorShape([4]), TensorShape([4, 7]), TensorShape([4]), TensorShape([4, 13]), TensorShape([4, 1200])]  The main thing to look out for here are redundant extra dimensions (for example, TensorShape([4, 1]) instead of TensorShape([4]) - these will almost always cause broadcasting issues.\nNext, we want to add an extra axis for the data we condition on. Again, this is for broadcasting purposes - we want to make sure tf \u0026ldquo;replicates\u0026rdquo; the data across different chains.\ntf.cast(sample[\u0026#34;cat_pref\u0026#34;], tf.float32)[tf.newaxis, ...].shape TensorShape([1, 1200])  Finally, the log_prob function closure - we want to make sure our log_prob function gets as inputs all the different parameters, concatenates them with the data we\u0026rsquo;re conditioning on, and then uses the original model log_prob function to evaluate; practically, we want to verify that if we pass all the parameters (without the conditioning data), we get n_chains different numbers:\nlp = lambda *x: model.log_prob( list(x) + [tf.cast(sample[\u0026#34;cat_pref\u0026#34;], tf.float32)[tf.newaxis, ...]] ) lp(*inits[:-1]) \u0026lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1315.5156, -1436.2715, -1799.2578, -1901.1874], dtype=float32)\u0026gt;  Inference With sensible priors and TFP shape issues dealt with, we can proceed with actually runnning the sampler.\ninits = [ tf.random.uniform(s.shape, -2, 2, tf.float32, name=\u0026#34;initializer\u0026#34;) for s in inits ] trace, kr = run_nuts( lp, inits[:-1], bijectors_list=[ tfb.Exp(), tfb.Identity(), tfb.Exp(), tfb.Identity(), tfb.Exp(), tfb.Identity(), tfb.Exp(), tfb.Identity(), tfb.Identity(), tfb.Identity(), ], ) Always check your TF shapes:\n[s.shape for s in trace] [TensorShape([1000, 4]), TensorShape([1000, 4, 50]), TensorShape([1000, 4]), TensorShape([1000, 4, 3]), TensorShape([1000, 4]), TensorShape([1000, 4, 3]), TensorShape([1000, 4]), TensorShape([1000, 4, 7]), TensorShape([1000, 4]), TensorShape([1000, 4, 13])]  This looks good; for arviz intergration purposes, we\u0026rsquo;ll add an extra axis for the parameters whose tensor shape is TensorShape([1000, 4]), and then call our tfp_trace_to_arviz helper function:\ntrace_ex = [s[..., tf.newaxis] if len(s.shape) == 2 else s for s in trace] az_trace = tfp_trace_to_arviz((trace_ex, kr)) az.summary(az_trace).head(5)     mean sd hpd_3% hpd_97% mcse_mean mcse_sd ess_mean ess_sd ess_bulk ess_tail r_hat     var 0[0] 1.056 0.153 0.779 1.338 0.004 0.003 1785 1771 1806 2668 1   var 1[0] 0.016 0.607 -1.173 1.155 0.011 0.009 2822 2235 2843 2538 1   var 1[1] 0.025 0.505 -0.997 0.927 0.008 0.008 3978 1785 4013 2918 1   var 1[2] 0.477 0.463 -0.362 1.38 0.007 0.006 4207 2794 4232 2521 1   var 1[3] -0.36 0.764 -1.896 1.008 0.017 0.013 2102 1745 2132 1908 1    Sampling diagnostics look good; we have no divergent transitions, and $\\hat{R}$ values are all close to 1:\naz.summary(az_trace)[\u0026#34;r_hat\u0026#34;].describe() count 81.0 mean 1.0 std 0.0 min 1.0 25% 1.0 50% 1.0 75% 1.0 max 1.0 Name: r_hat, dtype: float64  We won\u0026rsquo;t go down the model-diagnostics-rabbit-hole now; we\u0026rsquo;re here to learn about Mister P.\nP part So far we\u0026rsquo;ve defined, critisized and fitted a multilevel logisitic regression model. Now comes the poststratification part. Poststratification is a technical and intimidating word; it basically means \u0026ldquo;adjusting the inferences from my sample to the population by using additional knowledge about proportions in the population\u0026rdquo;. To do so, we\u0026rsquo;ll:\n Compute a design matrix $X$ for the population. Use our 4000 sampled parameters to compute 4000 different logits for each group in the population. This will yield a 4000x6300 matrix. For each row (representing a single draw from our posterior), we\u0026rsquo;ll compute the population mean as a weighted sum of per-group cat preference and group\u0026rsquo;s size. This will give us a vector of 4000 numbers. The mean of these 4000 numbers will be our estimate for the population mean.  post_factors = pd.get_dummies(poststrat[[\u0026#34;sex\u0026#34;, \u0026#34;age\u0026#34;]].astype(\u0026#34;category\u0026#34;)).drop( [\u0026#34;sex_0\u0026#34;, \u0026#34;age_0\u0026#34;], axis=1 ) post_interactions = pd.DataFrame( post_factors.drop(\u0026#34;sex_1\u0026#34;, axis=1).values * post_factors[\u0026#34;sex_1\u0026#34;].values[:, None], columns=[f\u0026#34;sex_1*age_{i}\u0026#34; for i in range(6)], ) post_features = pd.concat([post_factors, post_interactions], axis=1).values.T intercept = trace[8] coeffs = trace[9] coef_age = trace[7] coef_income = trace[5] coef_eth = trace[3] coef_state = trace[1] logits = ( intercept[..., tf.newaxis] + coeffs @ tf.cast(post_features, tf.float32) + tf.gather(trace[7], tf.cast(poststrat[\u0026#34;age\u0026#34;], tf.int32), axis=-1) + tf.gather(coef_income, tf.cast(poststrat[\u0026#34;income\u0026#34;], tf.int32), axis=-1) + tf.gather(coef_eth, tf.cast(poststrat[\u0026#34;eth\u0026#34;], tf.int32), axis=-1) + tf.gather(coef_state, tf.cast(poststrat[\u0026#34;state\u0026#34;], tf.int32), axis=-1) ) posterior_prob = inv_logit(logits) posterior_prob = posterior_prob.reshape(-1, 6300) posterior_prob.shape (4000, 6300)  poststrat_prob = posterior_prob @ poststrat[\u0026#34;N\u0026#34;][:, None] / poststrat[\u0026#34;N\u0026#34;].sum() poststrat_prob.shape (4000, 1)  So how good is MRP? We plot the histogram of our 4000 different estimates of the population mean, together with the estimate from the sample (dashed line) and the true mean:\nsns.distplot(poststrat_prob, bins=100) plt.axvline(true_pop_pref, label=\u0026#34;population mean\u0026#34;, lw=3, c=\u0026#34;k\u0026#34;) plt.axvline(sample[\u0026#34;cat_pref\u0026#34;].mean(), label=\u0026#34;sample mean\u0026#34;, lw=3, ls=\u0026#34;--\u0026#34;, c=\u0026#34;k\u0026#34;) plt.legend(); You can see that the posterior mean is much closer to the true mean - so MRP definitely helps!\nEstimates for states The nice thing about having a model is that we can use it to answer all sorts of different questions. For example, we can repeat the analysis we just did and estimate per-state means. We\u0026rsquo;re still computing the design matrix, logits etc as before but we\u0026rsquo;re constraining ourselves to one state at a time. For each state, we\u0026rsquo;ll compute the model\u0026rsquo;s mean and standard deviations, together with the true mean and the sample mean:\nstate_data = namedtuple( \u0026#34;state_data\u0026#34;, [ \u0026#34;state\u0026#34;, \u0026#34;model_state_sd\u0026#34;, \u0026#34;model_state_pref\u0026#34;, \u0026#34;sample_state_pref\u0026#34;, \u0026#34;true_state_pref\u0026#34;, \u0026#34;N\u0026#34;, ], ) states_data = [] for i in range(50): state_features = np.squeeze(post_features[:, np.where(poststrat.state == i)]) state_poststrat = poststrat.query(f\u0026#34;state=={i}\u0026#34;) logits = ( intercept[..., tf.newaxis] + coeffs @ tf.cast(state_features, tf.float32) + tf.gather( trace[7], tf.cast(state_poststrat.query(f\u0026#34;state=={i}\u0026#34;)[\u0026#34;age\u0026#34;], tf.int32), axis=-1, ) + tf.gather( coef_income, tf.cast(state_poststrat.query(f\u0026#34;state=={i}\u0026#34;)[\u0026#34;income\u0026#34;], tf.int32), axis=-1, ) + tf.gather( coef_eth, tf.cast(state_poststrat.query(f\u0026#34;state=={i}\u0026#34;)[\u0026#34;eth\u0026#34;], tf.int32), axis=-1, ) + tf.gather( coef_state, tf.cast(state_poststrat.query(f\u0026#34;state=={i}\u0026#34;)[\u0026#34;state\u0026#34;], tf.int32), axis=-1, ) ) posterior_prob = inv_logit(logits) posterior_prob = posterior_prob.reshape(-1, state_features.shape[1]) state_poststrat_prob = ( posterior_prob @ state_poststrat.query(f\u0026#34;state=={i}\u0026#34;)[\u0026#34;N\u0026#34;][:, None] / state_poststrat[\u0026#34;N\u0026#34;].sum() ) states_data.append( state_data( i, state_poststrat_prob.std(), state_poststrat_prob.mean(), sample.query(f\u0026#34;state=={i}\u0026#34;)[\u0026#34;cat_pref\u0026#34;].mean(), np.sum(true_pop.query(f\u0026#34;state=={i}\u0026#34;)[\u0026#34;cat_pref\u0026#34;] * state_poststrat[\u0026#34;N\u0026#34;]) / np.sum(state_poststrat[\u0026#34;N\u0026#34;]), sample.query(f\u0026#34;state=={i}\u0026#34;).shape[0], ) ) state_df = pd.DataFrame(states_data) state_df.head()     state model_state_sd model_state_pref sample_state_pref true_state_pref N     0 0 0.116844 0.580393 0.75 0.596565 12   1 1 0.0956771 0.583293 0.7 0.658961 20   2 2 0.0817888 0.669766 0.823529 0.69817 34   3 3 0.145332 0.505946 0.6 0.553341 5   4 4 0.0768275 0.493726 0.611111 0.443913 36    Graphically, this is how this looks like:\nf, ax = plt.subplots(figsize=(6, 6)) state_df.plot( x=\u0026#34;true_state_pref\u0026#34;, y=\u0026#34;model_state_pref\u0026#34;, yerr=\u0026#34;model_state_sd\u0026#34;, ax=ax, kind=\u0026#34;scatter\u0026#34;, label=\u0026#34;Model\u0026#34;, ) state_df.plot( x=\u0026#34;true_state_pref\u0026#34;, y=\u0026#34;sample_state_pref\u0026#34;, ax=ax, kind=\u0026#34;scatter\u0026#34;, c=\u0026#34;C1\u0026#34;, label=\u0026#34;Sample\u0026#34;, ) ax.plot([0, 1], [0, 1], c=\u0026#34;k\u0026#34;) f.tight_layout() plt.ylabel(\u0026#34;Cat preference\u0026#34;); We can see that the model predictions of state-wise preferences (blue dots) are closer to the identity line compared to the orange dots (sample per-state mean preferences).\nAnother interesting thing to see is how the model uncertainty (quantified by the standard deviation of the model predictions, per state) is related to sample size; we can see that the model is more confident (lower std) for states with higher N, which is what we would expect:\nplt.scatter(state_df[\u0026#34;N\u0026#34;], state_df[\u0026#34;model_state_sd\u0026#34;]) Summary and further reading This post was a code-oriented introduction to MRP, which is a very interesting technique that nicely leverages the built in advantages of multilevel models. We\u0026rsquo;ve also seen how taking a package\u0026rsquo;s priors for granted is not always a good idea, and how prior predictive checks can help us calibrate our priors and our beliefs.\nIn case you want to learn more, other than Lauren and Jonah\u0026rsquo;s vignette, these are all excellent reads:\n Austin Rochford\u0026rsquo;s MRPyMC3 tutorial Andrew Gelman\u0026rsquo;s post about Mister P\u0026rsquo;s secret sauce. Somewhat more technical and perhaps more political-science specific, but still interesting and relevant. Dan Simpson\u0026rsquo;s post on structured priors for MRP; this is somewhat more advanced, but Dan\u0026rsquo;s posts are always fun to read.  ","date":1574035200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574035200,"objectID":"aebac3570c357a107890d10389e18054","permalink":"https://adamhaber.github.io/post/mrp/","publishdate":"2019-11-18T00:00:00Z","relpermalink":"/post/mrp/","section":"post","summary":"TL;DR We\u0026rsquo;ll:\n Learn an interesting method for generalizing inferences from a biased sample to a population of interest See why prior predictive checks are great Implement a simple mixed-effects model in TFP  Intro This post is a TFP port of Lauren Kennedy and Jonah Gabry\u0026rsquo;s excellent MRP with rstanarm vignette. It describes a very interesting statistical method for generalizing inferences from a biased sample to a population of interest.","tags":["TFP","Multilevel Models","Bayesian Models"],"title":"Mr. P meets TFP - mixed effects model with post-stratification in TensorFlow Probability","type":"post"},{"authors":null,"categories":null,"content":"TL;DR We\u0026rsquo;ll:\n Port a great Bayesian modelling tutorial from Stan to TFP Discuss how to speed up our sampling function Use the trace_fn to produce Stan-like generated quantities Explore the results using the ArviZ library.  Intro This is a TFP-port one of of the best Bayesian modelling tutorials I\u0026rsquo;ve seen online - the Model building and expansion for golf putting Stan tutorial. It\u0026rsquo;s a beautiful example of modeling from first principles, and why the incorporation of domain knowledge into a statistical model - in this case, knowing a little bit about golf and some high-school physics - is so important. Since there\u0026rsquo;s no chance I\u0026rsquo;ll explain the subject nearly as well as Gelman, go read his tutorial and come back if you want to learn how to do this with TFP. :-)\nOther than the actual TFP code for the different models, this post will also shortly discuss the new NUTS kernel, various optimizations techniques to make sampling (much) faster, how to use trace_fn to produce Stan-style generated quantities, and the ArviZ plotting library for inspecting sampler traces and statistics. I\u0026rsquo;m not an expert on any of these topics - I\u0026rsquo;ll share what I\u0026rsquo;ve learned while trying to implement these models, and provide links for further reading.\nIf you\u0026rsquo;re more into basketball than golf, you might be interested in this case-study; it\u0026rsquo;s based on the golf tutorial, but analyzes NBA jump shots instead.\n# the necessary imports import tensorflow.compat.v2 as tf import tensorflow_probability as tfp import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import numpy as np from time import time from tensorflow_probability import distributions as tfd from tensorflow_probability import bijectors as tfb from functools import partial import arviz as az #we\u0026#39;ll get to that sns.set_palette(\u0026#34;muted\u0026#34;) np.random.seed(1324) dtype=tf.float32 params = { \u0026#39;legend.fontsize\u0026#39;: \u0026#39;x-large\u0026#39;, \u0026#39;figure.figsize\u0026#39;: (9, 6), \u0026#39;axes.labelsize\u0026#39;: \u0026#39;x-large\u0026#39;, \u0026#39;axes.titlesize\u0026#39;:\u0026#39;x-large\u0026#39;, \u0026#39;xtick.labelsize\u0026#39;:\u0026#39;x-large\u0026#39;, \u0026#39;ytick.labelsize\u0026#39;:\u0026#39;x-large\u0026#39; } plt.rcParams.update(params) %config InlineBackend.figure_format = \u0026#39;retina\u0026#39; ArviZ In the previous posts we\u0026rsquo;ve been using seaborn for plotting. Seaborn is an amazing plotting library with good defaults and well-designed API, but it was not built with MCMC simulations in mind. ArviZ was. ArviZ allows for \u0026ldquo;Exploratory analysis of Bayesian models\u0026rdquo;, and interfaces with many bayesian modeling libraries such as PyStan, PyMC3, Pyro, emcee and TFP. ArviZ prints nice dataframes with summary statistics, supports model comparison using LOO and WAIC (similar to the loo package in R), and a wide variety of diagnosis tools; it\u0026rsquo;s the most comprehensive Python package for this sort of analysis I\u0026rsquo;ve seen, and it\u0026rsquo;s maintained by top PyMC3 contributors.\nThe only drawback for using ArviZ with TFP at the moment is that the from_tfp function has troubles with multi-chain traces (which are pretty much the norm); I adjusted a code snippet from this notebook and wrote a small helper function to handle this. The tfp_trace_to_arviz function gets a StatesAndTrace object, which is a container with two elements:\n a list of samples tensors (the actual output of the sampler). a list of trace statistics.  \u0026hellip; and returns an ArviZ InferenceData object. There is a wide range of statistics we can extract from our sampler, which are important for sampling diagnosis. This is the actual function:\n# using pymc3 naming conventions, with log_likelihood instead of lp so that ArviZ can compute loo and waic sample_stats_name = [\u0026#39;log_likelihood\u0026#39;,\u0026#39;tree_size\u0026#39;,\u0026#39;diverging\u0026#39;,\u0026#39;energy\u0026#39;,\u0026#39;mean_tree_accept\u0026#39;] def tfp_trace_to_arviz( tfp_trace, var_names=None, sample_stats_name=sample_stats_name): samps, trace = tfp_trace if var_names is None: var_names = [\u0026#34;var \u0026#34; + str(x) for x in range(len(samps))] sample_stats = {k:v.numpy().T for k, v in zip(sample_stats_name, trace)} posterior = {name : tf.transpose(samp, [1, 0, 2]).numpy() for name, samp in zip(var_names, samps)} return az.from_dict(posterior=posterior, sample_stats=sample_stats) The only tricky thing here is the tf.transpose operation - we\u0026rsquo;re making sure the chain dimension is the first axis, to be consistent with ArviZ conventions (see az.data.numpy_to_data_array).\nNUTS Previous posts have used the Hamiltonian Monte Carlo sampler to sample from our posterior distributions. When I tried to use HMC to sample from the models described below (specifically, from the 3rd and 4th models) I\u0026rsquo;ve had troubles reproducing the results from the Stan tutorial. I\u0026rsquo;ve posted a question on the TFP google group (super responsive and helpful), and Junpeng Lao (PyMC3 core developer, now working on TFP) recommended I\u0026rsquo;ll try the new NUTS kernel, instead. He said NUTS requires significantly less hand-tuning for complex models, compared to HMC; he was right.\nSince the posts so far were mostly code-oriented, we haven\u0026rsquo;t really gotten into the HMC algorithm, so we\u0026rsquo;re not going to get into why NUTS is an improvement; suffice to say it traverses the posterior distribution in a more efficient way, which is good for us (the simple people who don\u0026rsquo;t know how to hand-tune the number of leapfrog steps). We\u0026rsquo;ll see below another new addition to TFP that helps with another fine-tuning problem.\nFor further reading, these are all excellent:\n The original NUTS paper. Michael Betancourt\u0026rsquo;s A Conceptual Introduction to Hamiltonian Monte Carlo paper. For the more code-oriented reader - Colin Carroll\u0026rsquo;s excellent series of posts on HMC, tuning, etc. Colin is one of the maintainers of both ArviZ and PyMC3. Sigrid Keydana\u0026rsquo;s explanation is also excellent and less intimidating than the original articles.  I\u0026rsquo;ll now go over the code we\u0026rsquo;ll use to run the NUTS sampler. We\u0026rsquo;ll start with explaining trace_fn, which is not NUTS specific but we\u0026rsquo;ll use it in our run_nuts function; then we\u0026rsquo;ll cover the run_nuts function itself.\nTracing sampler statistics TFP allows us to collect various statistics of the sampling procedure, which can be important for diagnosing different kinds of problems with our model. To tell TFP which sampler statistics we actually care about, we need to pass sample_chain a mysterious looking function called trace_fn, which takes two arguments: states, and previous_kernel_results (or pkr; took me a while understand what this stands for). In most examples (e.g., in sample_chain's docs), the states argument is discarded and some field(s) of the pkr (which is a collections.namedtuple object) are returned. To see what are the different kinds of statistics you can extract from previous_kernel_results for the NUTS sampler, see here.\nFollowing the same notebook linked above, we\u0026rsquo;re extracting the following statistics (most of this came from this PyMC3 Sampler Statistics notebook):\n target_log_prob - log likelihood of the current state. If you\u0026rsquo;re interested in using ArviZ for model comparison, you need to extract this. leapfrogs_taken - NUTS generates a binary tree during sampling; this is the number of leafs in the tree per iteration. If the tree size is large, this can imply there are strong correlations in the posterior, high curvature \u0026ldquo;funnels\u0026rdquo;, and that reparameterization of the model (for example, moving from a centered to non-centered representation) might be helpful. has_divergence - Whether the trajectory for this sample diverged. See Michael Betancourt\u0026rsquo;s excellent post for what are divergences and how you can use them to detect problems with your model. energy - The energy at the point in phase-space where the sample was accepted. Can be used to identify posteriors with problematically long tails. See here. log_accept_ratio - The mean acceptance probability for the tree that generated this sample. This can be compared to the desired target acceptance ratio for diagnosis.  def trace_fn(_, pkr): return ( pkr.inner_results.inner_results.target_log_prob, pkr.inner_results.inner_results.leapfrogs_taken, pkr.inner_results.inner_results.has_divergence, pkr.inner_results.inner_results.energy, pkr.inner_results.inner_results.log_accept_ratio ) The pkr.inner_results.inner_results part is due to the fact that we\u0026rsquo;re using a kernel-within-a-kernel-within-a-kernel - see below.\nCalling NUTS The code for running the NUTS sampler is somewhat different than the sampleHMC function we\u0026rsquo;ve used in the previous posts. Here\u0026rsquo;s a helper function for running NUTS that takes a tracing function, a log probability function, a list of initial values and an (optional) list of bijectors, and returns samples and sampler statistics.\nn_chains = 10 def run_nuts_template( trace_fn, target_log_prob_fn, inits, bijectors_list=None, num_steps=500, num_burnin=500, n_chains=n_chains): step_size = np.random.rand(n_chains, 1)*.5 + 1. if not isinstance(inits, list): inits = [inits] if bijectors_list is None: bijectors_list = [tfb.Identity()]*len(inits) kernel = tfp.mcmc.DualAveragingStepSizeAdaptation( tfp.mcmc.TransformedTransitionKernel( inner_kernel=tfp.mcmc.NoUTurnSampler( target_log_prob_fn, step_size=[step_size]*len(inits) ), bijector=bijectors_list ), target_accept_prob=.8, num_adaptation_steps=int(0.8*num_burnin), step_size_setter_fn=lambda pkr, new_step_size: pkr._replace( inner_results=pkr.inner_results._replace(step_size=new_step_size) ), step_size_getter_fn=lambda pkr: pkr.inner_results.step_size, log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio, ) res = tfp.mcmc.sample_chain( num_results=num_steps, num_burnin_steps=num_burnin, current_state=inits, kernel=kernel, trace_fn=trace_fn ) return res What have we got here?\n The NUTS kernel is hidden within the TransformedTransitionKernel, and gets as inputs the target_log_prob_fn function representing the model we want to sample from, and a list of per-variable step_size for the NUTS algorithm. TFP\u0026rsquo;s docs recommend these should be of the same order-of-magnitude as the standard deviations of the target distribution; here they\u0026rsquo;re taken to be of order 1, and jittered (this can apparently help with areas of high-curvature of the posterior - see the Stan manual on HMC parameters for more details). A TransformedTransitionKernel wraps NUTS in case we\u0026rsquo;re using unconstraining bijectors. For a more in-depth explanation on bijectors, see my previous post. If no bijectors are passed, we\u0026rsquo;re using Identity bijectors. This is wrapped by tfp.mcmc.DualAveragingStepSizeAdaptation, which, as the name suggests, adapts the sampler step size in order to make sampling more efficient. This is the 2nd addition that saves hand-tuning I\u0026rsquo;ve mentioned above. We\u0026rsquo;re setting the number of adaptation steps to be 80% of the number of burnin step, following TFP\u0026rsquo;s recommendation.  The whole kernel-within-kernel-within-kernel is passed to sample_chain, along with initial values, the trace function from above, number of burnin steps and number of results.\nSpeeding up your sampler with XLA compilation We can call run_nuts as it is and everything will work fine. However, we can use some TFP optimisation tricks to make sampling significantly faster. Optimizing the sampling function is a one liner:\nrun_nuts = partial(run_nuts_template, trace_fn) run_nuts_opt = tf.function(run_nuts) run_nuts_defun = tf.function(run_nuts, autograph=False) What\u0026rsquo;s this?\n We\u0026rsquo;re using functools.partial to \u0026ldquo;plug in\u0026rdquo; the tracing function. This simply saves writing run_nuts several times for several tracing functions. Decorating the run_nuts function with tf.function compiles it into a tf.Graph, which means faster execution and easy integration with the GPU or TPU. This is done by tracing the TensorFlow operations in run_nuts and constructing the corresponding tf.Graph, allowing TensorFlow to optimize and exploit parallelism in the computation defined by run_nuts. See here and here if you\u0026rsquo;re interested in learning more. The autograph=False is related to how control-flow statements are handled; setting it to False is the recommendation of the TFP team (we\u0026rsquo;ll benchmark all these below).  We can even have a faster version:\nrun_nuts_defun_xla = tf.function(run_nuts, autograph=False, experimental_compile=True) experimental_compile=True compiles the whole graph into XLA, which is even faster, as we\u0026rsquo;ll see below. XLA is a domain-specific compiler used by TensorFlow (and jax) to produce highly optimized code and CPU/GPU/TPU compatibility. For learning more about XLA compilation, read this and watch the talk at the bottom of the page.\nData There are two datasets in the original Stan tutorial - we call them data and new_data. The first column is the distance (x) from the hole, the second column is the number of attempts, and the last column is the number of successful putts:\ndata = np.array([[2,1443,1346], [3,694,577], [4,455,337], [5,353,208], [6,272,149], [7,256,136], [8,240,111], [9,217,69], [10,200,67], [11,237,75], [12,202,52], [13,192,46], [14,174,54], [15,167,28], [16,201,27], [17,195,31], [18,191,33], [19,147,20], [20,152,24]]) new_data = np.array([[0.28, 45198, 45183], [0.97, 183020, 182899], [1.93, 169503, 168594], [2.92, 113094, 108953], [3.93, 73855, 64740], [4.94, 53659, 41106], [5.94, 42991, 28205], [6.95, 37050, 21334], [7.95, 33275, 16615], [8.95, 30836, 13503], [9.95, 28637, 11060], [10.95, 26239, 9032], [11.95, 24636, 7687], [12.95, 22876, 6432], [14.43, 41267, 9813], [16.43, 35712, 7196], [18.44, 31573, 5290], [20.44, 28280, 4086], [21.95, 13238, 1642], [24.39, 46570, 4767], [28.40, 38422, 2980], [32.39, 31641, 1996], [36.39, 25604, 1327], [40.37, 20366, 834], [44.38, 15977, 559], [48.37, 11770, 311], [52.36, 8708, 231], [57.25, 8878, 204], [63.23, 5492, 103], [69.18, 3087, 35], [75.19, 1742, 24]]) df = pd.DataFrame(data, columns = [\u0026#39;x\u0026#39;,\u0026#39;n\u0026#39;,\u0026#39;y\u0026#39;]) new_df = pd.DataFrame(new_data, columns = [\u0026#39;x\u0026#39;,\u0026#39;n\u0026#39;,\u0026#39;y\u0026#39;]) This is how the data looks like:\nplt.scatter(df[\u0026#39;x\u0026#39;],df[\u0026#39;y\u0026#39;]/df[\u0026#39;n\u0026#39;],c=\u0026#39;b\u0026#39;,label=\u0026#39;data\u0026#39;) plt.scatter(new_df[\u0026#39;x\u0026#39;],new_df[\u0026#39;y\u0026#39;]/new_df[\u0026#39;n\u0026#39;],c=\u0026#39;r\u0026#39;,label=\u0026#39;new_data\u0026#39;) plt.legend() plt.xlabel(\u0026#34;Distance\u0026#34;) plt.ylabel(\u0026#34;% of success\u0026#34;) plt.title(\u0026#34;Original data\u0026#34;); Model 1 The first model is a simple logistic regression. Since the graph above is somewhat skewed and not symmetric around its midpoint (like a sigmoid), you can already guess logistic regression won\u0026rsquo;t be very accurate but why not:\nroot = tfd.JointDistributionCoroutine.Root def golf_logistic(): a = yield root(tfd.Sample(tfd.Normal(0,1e6),1)) b = yield root(tfd.Sample(tfd.Normal(0,1e6),1)) y = yield tfd.Independent( tfd.Binomial( total_count = tf.cast(df[\u0026#39;n\u0026#39;],dtype), logits = a+tf.cast(df[\u0026#39;x\u0026#39;],dtype)*b ) ) golf_logistic_jd = tfd.JointDistributionCoroutine(golf_logistic) Note that unlike the Stan tutorial, we\u0026rsquo;re using a super-vague but proper prior $\\mathcal{N}\\left(0,10^6\\right)$.\nWe\u0026rsquo;ll use tfd.JointDistributionCoroutine to build all 4 models in this post. JointDistributionCoroutine is a cousin of the more-intuitive JointDistributionSequential we\u0026rsquo;ve used in previous posts. Instead of a list of tfd.Distribution-like instances, we\u0026rsquo;re passing a generator that yields a sequence of tfd.Distribution-like instances. The main advantage is that with Coroutine's function syntax its easier to express intermediate calculations, compared to Sequential's list syntax. This will come in handy already in the 2nd model.\nThe main differences are that we need to use yield everytime we\u0026rsquo;re sampling from a distribution, and wrap priors (random variables in the model that don\u0026rsquo;t depend on other random variables) with root.\nOnce we have our model, we feed its log_prob method together with the observed data into run_nuts.\ngolf_logistic_log_prob = lambda *args: golf_logistic_jd.log_prob(args + (tf.cast(df[\u0026#39;y\u0026#39;],dtype),)) Let\u0026rsquo;s see how each of the run_nuts version is doing:\n%%time res = run_nuts(golf_logistic_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))]) CPU times: user 13min 5s, sys: 4.28 s, total: 13min 10s Wall time: 13min 13s  %%time res = run_nuts_opt(golf_logistic_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))]) CPU times: user 29.7 s, sys: 4.13 s, total: 33.8 s Wall time: 18.7 s  %%time res = run_nuts_defun(golf_logistic_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))]) CPU times: user 29 s, sys: 4.04 s, total: 33 s Wall time: 17.9 s  %%time res = run_nuts_defun_xla(golf_logistic_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))]) CPU times: user 6.29 s, sys: 77.9 ms, total: 6.37 s Wall time: 6.39 s  So tf.function makes a huge difference, autograph True/False doesn\u0026rsquo;t really matter here, and XLA definitely helps.\nVisualizing the results with ArviZ is now straightforward:\ntrace1 = tfp_trace_to_arviz(res,[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;]) az.plot_trace(trace1); And so is displaying summary statistics:\naz.summary(trace1) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  Let\u0026rsquo;s see how this logistic regression looks like when we use the mean parameters:\na,b = az.summary(trace1)[\u0026#39;mean\u0026#39;] plt.plot(df[\u0026#39;x\u0026#39;], [np.exp(x)/(1+np.exp(x)) for x in a+df[\u0026#39;x\u0026#39;]*b],c=\u0026#39;r\u0026#39;,label=\u0026#39;model 1\u0026#39;) plt.scatter(df[\u0026#39;x\u0026#39;], df[\u0026#39;y\u0026#39;]/df[\u0026#39;n\u0026#39;],label=\u0026#39;data\u0026#39;) plt.legend(); Model 2 Logistic regression is a good start, but we can see it\u0026rsquo;s not doing a very good job at fitting our data. The second model is a major improvement, incorporating the knowledge that this data is describing attempts to insert a small ball into a larger hole; therefore their sizes, the distance between them and the corresponding angles probably matter.\nr = (1.68/2)/12 #ball size R = (4.25/2)/12 #hole size #threshold angles df[\u0026#39;th_angle\u0026#39;] = np.arcsin((R-r)/df[\u0026#39;x\u0026#39;]) new_df[\u0026#39;th_angle\u0026#39;] = np.arcsin((R-r)/new_df[\u0026#39;x\u0026#39;]) normal_cdf = tfb.NormalCDF() def golf_angle_distance(): # priors sigma = yield root(tfd.Sample(tfd.HalfNormal(1e6),1)) # transformations phi = 2*normal_cdf.forward( tf.cast(df[\u0026#39;th_angle\u0026#39;],dtype)/sigma )-1 # likelihood y = yield tfd.Independent( tfd.Binomial( tf.cast(df[\u0026#39;n\u0026#39;],dtype), probs=phi ) ) golf_angle_distance_jd = tfd.JointDistributionCoroutine(golf_angle_distance) golf_angle_distance_jd_log_prob = lambda *args: golf_angle_distance_jd.log_prob( args + (tf.cast(df[\u0026#39;y\u0026#39;], dtype),) ) Note that something like phi would be difficult to express with Sequential, but straightforward with Coroutine.\nWe\u0026rsquo;ll use this model as an opportunity to do something different with our trace_fn. Stan has this super useful generated quantities block, in which we can use the sampled parameters to generated various kinds of quantities of interest. We\u0026rsquo;ve mentioned above that trace_fn takes a state and a pkr, and usually discards the first. We\u0026rsquo;ll now modify our trace_fn so that in each step it takes the current angle (in radians) and converts it to degrees:\ndef trace_fn_angles(current_state, pkr): return ( tf.squeeze(current_state[0]*180/np.pi), pkr.inner_results.inner_results.target_log_prob, pkr.inner_results.inner_results.leapfrogs_taken, pkr.inner_results.inner_results.has_divergence, pkr.inner_results.inner_results.energy, pkr.inner_results.inner_results.log_accept_ratio ) We\u0026rsquo;re taking the current state, representing the angle in radians, and convert it to degrees. The tf.squeeze is here to get rid of a redundant dimension that can cause broadcasting issues later.\nAs for timing - the non tf.function-ed version is so slow that we won\u0026rsquo;t even try. Let\u0026rsquo;s compare the other alternatives:\nrun_nuts_angle = partial(run_nuts_template, trace_fn_angles) run_nuts_opt_angle = tf.function(run_nuts_angle) run_nuts_defun_angle = tf.function(run_nuts_angle, autograph=False) run_nuts_defun_xla_angle = tf.function(run_nuts_angle, autograph=False, experimental_compile=True) %%time res = run_nuts_opt_angle(golf_angle_distance_jd_log_prob, [tf.ones((n_chains,1))], [tfb.Exp()]) CPU times: user 6.18 s, sys: 808 ms, total: 6.99 s Wall time: 3.96 s  %%time res = run_nuts_defun_angle(golf_angle_distance_jd_log_prob, [tf.ones((n_chains,1))], [tfb.Exp()]) CPU times: user 6.06 s, sys: 755 ms, total: 6.82 s Wall time: 3.93 s  %%time res = run_nuts_defun_xla_angle(golf_angle_distance_jd_log_prob, [tf.ones((n_chains,1))], [tfb.Exp()]) CPU times: user 5.29 s, sys: 59.1 ms, total: 5.35 s Wall time: 5.38 s  No clear winner this time. Let\u0026rsquo;s inspect the trace:\ntrace2 = tfp_trace_to_arviz(res,[\u0026#39;sigma\u0026#39;], sample_stats_name=[\u0026#39;angle\u0026#39;]+sample_stats_name) az.plot_trace(trace2); Since we traced the angles using trace_fn_angles, ArviZ treats it as another sample statistics - it\u0026rsquo;s saved as an xarray.DataArray and even has its own plotting method:\ntrace2.sample_stats.angle.plot.hist(bins=30); I found this nice and cleaner than sns.distplot(res[0][0].numpy().flatten()*180/np.pi).\nWe print the summary statistics and make sure we\u0026rsquo;re reproducing the Stan tutorial results:\naz.summary(trace2) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  Comparing models 1 \u0026amp; 2 with ArviZ ArviZ allows us to conduct model comparison using approximate Leave-One-Out cross validation and WAIC information criteria (read more here if you\u0026rsquo;re interested). To do so, our ArviZ objects must have a log_likelihood sampler stats field (this is why we\u0026rsquo;ve included target_log_prob in our tracing function):\ntrace1.sample_stats.log_likelihood.shape, trace2.sample_stats.log_likelihood.shape ((10, 500), (10, 500))  Model comparison is now as easy as:\naz.compare({\u0026#39;Model 1\u0026#39;:trace1, \u0026#39;Model 2\u0026#39;:trace2}) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  The models are ranked from best to worst, so Model 2 (not surprisingly) outperforms Model 1. For more info about model comparison, how to read this table and its visualization using az.plot_compare, see here.\nModel 3 The authors aren\u0026rsquo;t satisfied with the fit of Model 2 and incorporate yet another piece of golf knowledge - other than shooting the ball at the right angle, you need to shoot it to the right distance, as well. They describe how this can be modelled, and proceed to fit the model:\ndistance_tol = 3. overshot = 1. def golf_angle_distance_2(): # priors sigma_angle = yield root(tfd.Sample(tfd.HalfNormal(1),1)) sigma_distance = yield root(tfd.Sample(tfd.HalfNormal(1),1)) # transformations p_angle = 2 * normal_cdf.forward( tf.cast(new_df[\u0026#39;th_angle\u0026#39;],dtype)/sigma_angle )-1 p_dist = normal_cdf.forward( (distance_tol-overshot)/(tf.cast(new_df[\u0026#39;x\u0026#39;]+overshot,dtype)*sigma_distance) ) - \\ normal_cdf.forward( (-overshot)/(tf.cast(new_df[\u0026#39;x\u0026#39;]+overshot,dtype)*sigma_distance) ) # likelihood y = yield tfd.Independent( tfd.Binomial( tf.cast(new_df[\u0026#39;n\u0026#39;],dtype), probs=p_angle*p_dist ) ) golf_angle_distance_2_jd = tfd.JointDistributionCoroutine(golf_angle_distance_2) golf_angle_distance_2_jd_log_prob = lambda *args: golf_angle_distance_2_jd.log_prob( args + (tf.cast(new_df[\u0026#39;y\u0026#39;], dtype),) ) %%time res = run_nuts_opt(golf_angle_distance_2_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))], bijectors_list=[tfb.Exp(), tfb.Exp()]) CPU times: user 23min 51s, sys: 4min 30s, total: 28min 21s Wall time: 10min 13s  %%time res = run_nuts_defun(golf_angle_distance_2_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))], bijectors_list=[tfb.Exp(), tfb.Exp()]) CPU times: user 18min 56s, sys: 3min 51s, total: 22min 48s Wall time: 8min 11s  %%time res = run_nuts_defun_xla(golf_angle_distance_2_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1))], bijectors_list=[tfb.Exp(), tfb.Exp()]) CPU times: user 1min 57s, sys: 38.1 s, total: 2min 35s Wall time: 1min 6s  Here, XLA makes ~8x difference in speed, which is incredible for an inherently iterative process!\nAs for the trace:\ntrace3 = tfp_trace_to_arviz(res,[\u0026#39;sigma_angle\u0026#39;,\u0026#39;sigma_distance\u0026#39;]) az.plot_trace(trace3); This isn\u0026rsquo;t what you want to see when inspecting a trace\u0026hellip; The chains haven\u0026rsquo;t mixed at all. Surprisingly, the Stan version had divergent transitions here, while we did not:\ntrace3.sample_stats.diverging.sum() \u0026lt;xarray.DataArray 'diverging' ()\u0026gt; array(0)  Model 4 In the 4th model, instead of using a binomial likelihood, we\u0026rsquo;re using a normal approximation of the binomial distribution and adding an additional noise term (read the original for a more in-depth explanation):\ndef golf_angle_distance_3(): # priors sigma_angle = yield root(tfd.Sample(tfd.HalfNormal(1), 1)) sigma_distance = yield root(tfd.Sample(tfd.HalfNormal(1), 1)) sigma_y = yield root(tfd.Sample(tfd.HalfNormal(1), 1)) # transformations p_angle = 2 * normal_cdf.forward( tf.cast(new_df[\u0026#39;th_angle\u0026#39;],dtype)/sigma_angle ) - 1 p_dist = normal_cdf.forward( (distance_tol-overshot)/(tf.cast(new_df[\u0026#39;x\u0026#39;]+overshot,dtype)*sigma_distance) ) - \\ normal_cdf.forward( (-overshot)/(tf.cast(new_df[\u0026#39;x\u0026#39;]+overshot,dtype)*sigma_distance) ) p = p_dist*p_angle # likelihood probs = yield tfd.Independent( tfd.Normal(p, tf.sqrt(p*(1-p)/(tf.cast(new_df[\u0026#39;n\u0026#39;],dtype))+sigma_y**2)) ) golf_angle_distance_3_jd = tfd.JointDistributionCoroutine(golf_angle_distance_3) golf_angle_distance_3_jd_log_prob = lambda *args: golf_angle_distance_3_jd.log_prob( args + (tf.cast(new_df[\u0026#39;y\u0026#39;]/new_df[\u0026#39;n\u0026#39;], dtype),) ) %%time res = run_nuts_opt(golf_angle_distance_3_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1)),tf.ones((n_chains,1))], bijectors_list=[tfb.Exp()]*3) CPU times: user 3min 45s, sys: 45.6 s, total: 4min 30s Wall time: 1min 39s  %%time res = run_nuts_defun(golf_angle_distance_3_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1)),tf.ones((n_chains,1))], bijectors_list=[tfb.Exp()]*3) CPU times: user 4min 2s, sys: 48.4 s, total: 4min 50s Wall time: 1min 46s  %%time res = run_nuts_defun_xla(golf_angle_distance_3_jd_log_prob, [tf.ones((n_chains,1)), tf.ones((n_chains,1)),tf.ones((n_chains,1))], bijectors_list=[tfb.Exp()]*3) CPU times: user 15.8 s, sys: 177 ms, total: 16 s Wall time: 16.1 s  Again, XLA is simply an incredible speed up of the sampling function.\ntrace4 = tfp_trace_to_arviz(res,[\u0026#39;sigma_angle\u0026#39;,\u0026#39;sigma_distance\u0026#39;,\u0026#39;sigma_y\u0026#39;]) az.plot_trace(trace4); This looks much better:\naz.summary(trace4) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  We\u0026rsquo;ll extract the mean parameters from the summary, and plot the resulting function:\nmean_sigma_angle, mean_sigma_dist, mean_sigma_y = az.summary(trace4)[\u0026#39;mean\u0026#39;] normal_cdf = tfb.NormalCDF() p_angle = 2 * normal_cdf.forward( tf.cast(new_df[\u0026#39;th_angle\u0026#39;],dtype)/mean_sigma_angle )-1 p_dist = normal_cdf.forward( (distance_tol-overshot)/(tf.cast(new_df[\u0026#39;x\u0026#39;]+overshot,dtype)*mean_sigma_dist) ) - \\ normal_cdf.forward( (-overshot)/(tf.cast(new_df[\u0026#39;x\u0026#39;]+overshot,dtype)*mean_sigma_dist) ) mean_p = (p_dist*p_angle).numpy() std_p = (tf.sqrt(mean_p*(1-mean_p)/(tf.cast(new_df[\u0026#39;n\u0026#39;],dtype))+mean_sigma_y**2)).numpy() plt.scatter(new_df[\u0026#39;x\u0026#39;],new_df[\u0026#39;y\u0026#39;]/new_df[\u0026#39;n\u0026#39;],label=\u0026#39;data\u0026#39;) plt.errorbar(new_df[\u0026#39;x\u0026#39;],mean_p,yerr=std_p,c=\u0026#39;k\u0026#39;,label=\u0026#39;model 4\u0026#39;) plt.legend(); This is, by all means, a very impressive fit. And the errorbars are there, they\u0026rsquo;re just too small we can\u0026rsquo;t actually see them. Definitely not bad for a 3 parameters model.\nComparison summary This is a summary of the different timings:\n    Model 1 Model 2 Model 3 Model 4     without tf.function 793 - - -   tf.function, autograph=True 18.7 3.96 613 99   tf.function, autograph=False 17.9 3.93 491 106   tf.function + XLA 6.39 5.38 66 16    So XLA compilation is a clear winner. Running the same models with 256 chains instead of 10 (very easy to do with TFP) gives qualitatively similar results.\nWrapping up In this post we\u0026rsquo;ve tried to replicate Stan\u0026rsquo;s awesome golf tutorial. Along the way, we saw how to work with the new NUTS kernel, how to speed it up using tf.function and XLA compilation, how to use the trace_fn to generated quantities of interest, and how to use ArviZ to handle all the plotting for us.\n","date":1571616000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571616000,"objectID":"4b8f49e8c8314fa632a9eb4413b25c29","permalink":"https://adamhaber.github.io/post/nuts/","publishdate":"2019-10-21T00:00:00Z","relpermalink":"/post/nuts/","section":"post","summary":"TL;DR We\u0026rsquo;ll:\n Port a great Bayesian modelling tutorial from Stan to TFP Discuss how to speed up our sampling function Use the trace_fn to produce Stan-like generated quantities Explore the results using the ArviZ library.  Intro This is a TFP-port one of of the best Bayesian modelling tutorials I\u0026rsquo;ve seen online - the Model building and expansion for golf putting Stan tutorial. It\u0026rsquo;s a beautiful example of modeling from first principles, and why the incorporation of domain knowledge into a statistical model - in this case, knowing a little bit about golf and some high-school physics - is so important.","tags":["TFP","Bayesian models","NUTS","ArviZ","optimization"],"title":"Bayesian golf puttings, NUTS, and optimizing your sampling function with TensorFlow Probability","type":"post"},{"authors":null,"categories":null,"content":"TL;DR Survival analysis is a super useful technique for modelling time-to-event data; implementing a simple survival analysis using TFP requires hacking around the sampler log probability function; in this post we\u0026rsquo;ll see how to do this, and introduce the basic terminology of survival analysis.\nSurvival analysis 101 Survival analysis is an incredibly useful technique for modeling time-to-something data. \u0026ldquo;something\u0026rdquo; can be the death a patient (hence the name), the failure of some part in a machine, the churn of a customer, the fall of a regime, and tons of other problems. Since time-to-event questions are everywhere, you\u0026rsquo;ll see survival analysis (possibly under different names) in clinical studies, econometrics, epidemiology, mechnical engineering, etc.\nFor me, one of the biggest sell-points of survival analysis is that it provides an elegant solution to handle censored observations. This is a technical term, and it can be quite confusing1, so I\u0026rsquo;ll try to illustrate it with a toy example. Say you\u0026rsquo;re selling diapers, and you bought 100 diapers to begin with - that\u0026rsquo;s your stock. After one month, you\u0026rsquo;ve sold 32 diapers, and still have 68 diapers in stock. To plan the size of the warehouse you want to build, you want to estimate how long it takes you to sell a diaper. Obviously, taking the mean of selling-times of the 32 diapers you\u0026rsquo;ve sold would give you an overly optimistic estimation\u0026hellip; but what do you do with the 68 diapers you still have in stock? How can you use the information that they\u0026rsquo;ve been sitting here for some time already to improve your estimation? You call them \u0026ldquo;censored diapers\u0026rdquo;2 and use survival analysis.\nSurvival analysis mathematics Survival analysis is a huge topic and I\u0026rsquo;m obviously not going to cover everything in here. I\u0026rsquo;ll focus on the terminology needed for this post; for a more detailed introduction, I highly recommend checking out lifelines docs (we\u0026rsquo;ll use lifelines - a python package for survival analysis - in this post, as well).\nAs mentioned above, survival analysis is about estimating a time-to-event. Let\u0026rsquo;s denote this time with $T$. Ideally, we\u0026rsquo;re interested in learning a probability distribution $P$ over the possible values of $T$. Note that this already assumes $T$ happens sometimes in the future, since the distribution integrates to 1. This is a reasonable assumption when we study mortality, but not as much when studying something like conversion rates - see this post for more details if you\u0026rsquo;re interested. In this post I\u0026rsquo;ll stick to the more traditional (and morbid) survival analysis in which everyone dies eventually.\nSo we have this $P_{\\theta}\\left(T\\right)$, which is defined by some parameter $\\theta$ (there are also semi-parametric and non-parametric approaches to survival analysis; we\u0026rsquo;ll get to that below). This formulation allows us to handle censored observations naturally; given the times of the observed event $\\left\\{O_1,O_2,\u0026hellip;,O_n\\right\\}$ ($n=32$ in the diapers example; these are times until the event happened), and the times of the censored events $\\left\\{C_1,C_2,\u0026hellip;,C_m\\right\\}$ ($m=68$ in the diapers example; these are times until censoring happened), we can construct the likelihood function\n$$ \\mathcal{L}\\left(\\underbrace{\\theta}_{\\text{parameter}}\\vert \\underbrace{O_1,O_2,\u0026hellip;,O_n,C_1,C_2,\u0026hellip;,C_m}_{\\text{data}}\\right) = \\prod_{i=1}^n {P_\\theta\\left(T=O_i\\right)} \\prod_{j=1}^m {P_\\theta\\left(T\u0026gt;C_j\\right)} $$\n\u0026hellip; since the only thing we know about the censored events is that the time-of-event is greater than the time of censoring. Now add a prior on $\\theta$ and you\u0026rsquo;ve got yourself a posterior (up to normalization which we usually don\u0026rsquo;t really care about).\nLet\u0026rsquo;s cook up an example to see how this works.\nCensored diapers # the necessary imports import tensorflow as tf import tensorflow_probability as tfp import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import numpy as np from tensorflow_probability import distributions as tfd from tensorflow_probability import bijectors as tfb from matplotlib.lines import Line2D tf.compat.v1.enable_eager_execution() # for plotting sns.set_palette(\u0026#34;muted\u0026#34;) # for reproducibility np.random.seed(1324) tf.random.set_random_seed(234) Say we start stocking up on diapers on January 1st. Some arrive to us exactly on time, some arrive later - arrival times are uniformly distributed within January. For simplicity, we assume that the real underlying event times (from arrival to selling) are exponentially distributed with a mean of 50 days. This is what we would actually measure without censoring, that is - if we could\u0026rsquo;ve waited long enough until all (or enough of) the diapers were sold.\nstart_date = pd.to_datetime(\u0026#39;2019-01-01\u0026#39;) N_samples = 1000 mean_time = 50 arrival_rng = pd.date_range(start = start_date, periods=31, freq=\u0026#39;D\u0026#39;) arrival_date = np.random.choice(arrival_rng, size = N_samples) real_T = np.random.exponential(mean_time, size = N_samples).astype(int) df = pd.DataFrame({ \u0026#39;Arrival Date\u0026#39;: arrival_date, \u0026#39;real_T\u0026#39;: real_T, \u0026#39;Real Selling Date\u0026#39; : arrival_date + pd.to_timedelta(real_T, unit=\u0026#39;d\u0026#39;)}) Let\u0026rsquo;s assume censoring happens on March 1st - that\u0026rsquo;s the day in which we decide \u0026ldquo;OK, these diapers were sold after these real-selling-times, these diapers are still in stock, let\u0026rsquo;s estimate mean time-to-event\u0026rdquo;. Phrased differently - this is when we get the data. By definition, every diaper whose Real Selling Date is later than March 1st will be considered a censored observation. The times of the observed, uncensored event are from arrival to selling; The times for the censored events are from arrival to the censoring date.\ncensoring_date = pd.to_datetime(\u0026#39;2019-03-01\u0026#39;) df[\u0026#39;censored\u0026#39;] = df[\u0026#39;Real Selling Date\u0026#39;]\u0026gt;censoring_date df[\u0026#39;T\u0026#39;] = np.where(df[\u0026#39;censored\u0026#39;], (censoring_date - df[\u0026#39;Arrival Date\u0026#39;]).dt.days, real_T) df.head()    Arrival Date real_T Real Selling Date censored T     2019-01-03 36 2019-02-08 False 36   2019-01-14 325 2019-12-05 True 46   2019-01-16 69 2019-03-26 True 44   2019-01-11 62 2019-03-14 True 49   2019-01-19 40 2019-02-28 False 40    Here we can already see the problem - censoring makes us severely underestimate the mean selling time:\ndf.query(\u0026#34;censored==0\u0026#34;)[\u0026#39;T\u0026#39;].mean(), real_T.mean() (19.681, 49.236) Pictorially, this is how it looks like. We sample 20 rows of data, and plot their individual timelines. Censoring events are the red circles, and the censored part of each observation is the dashed blue line:\nplt.figure(figsize=(9,4)) n = 20 samp_df = df.sample(n) samp_cens = samp_df[\u0026#39;censored\u0026#39;] plt.hlines(np.arange(n), (samp_df[\u0026#39;Arrival Date\u0026#39;]-start_date).dt.days, (samp_df[\u0026#39;Arrival Date\u0026#39;]-start_date).dt.days + samp_df[\u0026#39;T\u0026#39;], color=\u0026#39;k\u0026#39;) plt.hlines(np.where(samp_cens), (samp_df[samp_cens][\u0026#39;Arrival Date\u0026#39;]-start_date).dt.days + samp_df[samp_cens][\u0026#39;T\u0026#39;], (samp_df[samp_cens][\u0026#39;Real Selling Date\u0026#39;]-start_date).dt.days, color=\u0026#39;darkblue\u0026#39;, ls=\u0026#39;--\u0026#39;) plt.scatter([(censoring_date-start_date).days]*samp_cens.sum(),np.where(samp_cens), s=50, facecolors=\u0026#39;none\u0026#39;, edgecolors=\u0026#39;r\u0026#39;) plt.axvline((censoring_date-start_date).days, ls=\u0026#39;--\u0026#39;,color=\u0026#39;r\u0026#39;) plt.xlabel(\u0026#34;Days from start\u0026#34;, size=15) plt.ylabel(\u0026#34;Different samples\u0026#34;, size=15) plt.yticks([]) Obviously, the mean length of the black lines is significantly shorter than that of all the lines; this is exactly the bias caused by ignoring the censored observations.\nThe model We assume a simple exponential distribution for the event times distribution:\n$$P_{\\lambda}\\left(T\\right)=\\frac{1}{\\lambda}e^{-\\frac{T}{\\lambda}}$$\nIn this parametrization, $\\lambda$ is the mean time-to-event; we want to infer $\\lambda$ from the data. We put a $\\text{Normal}\\left(\\mu=3,\\sigma=3\\right)$ prior on $\\log\\lambda$, representing our prior belief that diapers aren\u0026rsquo;t sold in nanoseconds nor in geological timescales, and the constraint that $\\lambda$ must be positive.\nSo, this means that our log probability function is:\n$$\\underbrace{\\sum_{i=1}^n \\log{P_\\lambda\\left(T=O_i\\right)}}_{\\text{likelihood of observed}} + \\underbrace{\\sum_{j=1}^m \\log{P_\\lambda\\left(T\u0026gt;C_j\\right)}}_{\\text{likelihood of censored}}+\\underbrace{\\log\\text{Normal}\\left(\\lambda\\vert\\mu=3,\\sigma=3\\right)}_{\\text{Prior on }\\lambda}$$\nThe first sum and the last term are easy - we just define an exponential model with the prior we want and feed it with the observed samples. The tricky part is how to handle with the second, censored sum.\nLCCDF The thing we need to implement in order to feed the right log_prob function to the sampler is called LCCDF: an intimidating acronym the stands for Log Complementary Cumulative Density Function. We\u0026rsquo;ll unfold this backwards:\n The cumulative density function (CDF) of our time-to-event distribution is $F_\\lambda\\left(t\\right)=P_\\lambda(T\\le t)$. The complmentary CDF (CCDF) is $1-F_\\lambda\\left(t\\right)=P_\\lambda(T\u0026gt;t)$; Its log (LCCDF) is $\\log P_\\lambda(T\u0026gt;t)$, which is exactly what we want.  Some LCCDFs are implemented in languages such as Stan (this is what we want), but in TFP (currently) we have to implement this ourselves. Luckily, the CDF of the exponential distribution is $1-e^{-\\frac{T}{\\lambda}}$, which means our LCCDF is super simple - $\\log P_\\lambda(T\u0026gt;t)=-\\frac{T}{\\lambda}$. Cases for which we don\u0026rsquo;t have an analytical expression for the LCCDF are trickier to handle; The solution in Sigrid Keydana\u0026rsquo;s post (using TFP built-in CDF functions) is more general, but I found it less numerically stable, and writing everything explicitly helped me understand what\u0026rsquo;s going on. We\u0026rsquo;ll stick with the simpler case in this introductory post.\nWe now go ahead and implement this:\n#converting the data to tf tensors obs_times = tf.convert_to_tensor(df.query(\u0026#34;censored==0\u0026#34;)[\u0026#39;T\u0026#39;]) cens_times = tf.convert_to_tensor(df.query(\u0026#34;censored==1\u0026#34;)[\u0026#39;T\u0026#39;]) This is our model, containing the normal prior on $\\log\\lambda$ and the exponential likelihood terms. This is pretty straightforward:\nobs_model = tfd.JointDistributionSequential( [ tfd.Normal(3, 3), #log_rate lambda log_rate: tfd.Independent(tfd.Sample( tfd.Exponential(rate = 1/tf.math.exp(log_rate[:,tf.newaxis]) )), reinterpreted_batch_ndims = 1) ] ) Now, given a $\\log\\lambda$, the exponential LCCDF function simply sums $-\\frac{T}{\\lambda}$ over all censored times. Note that log_rate has shape (n_chains,), and cens_times has shape (n_cens_times,), so we need to add a tf.newaxis to make sure both are broadcasted along the right dimensions. We also cast cens_times to float so the division is properly defined.\ndef exponential_lccdf(log_rate): return tf.reduce_sum( -tf.cast(cens_times, log_rate.dtype)[tf.newaxis,:]/tf.exp(log_rate[:,tf.newaxis]), axis=-1 ) Finally, we combine the likelihood of the observed times and the prior, which are given by obs_model.log_prob evaluated at the observed times, and the likelihood of the censored times, which we just defined:\ndef log_prob(log_rate): lp = obs_model.log_prob([log_rate, tf.cast(obs_times, log_rate.dtype)[tf.newaxis,:]]) censored_likelihood = exponential_lccdf(log_rate) return lp + censored_likelihood We now proceed as usual, by calling our HMC sampler helper function:\n@tf.function def sampleHMC(log_prob, inits, bijectors_list = None): inner_kernel=tfp.mcmc.HamiltonianMonteCarlo( target_log_prob_fn=log_prob, step_size=0.1, num_leapfrog_steps=8 ) if bijectors_list is not None: inner_kernel = tfp.mcmc.TransformedTransitionKernel(inner_kernel, bijectors_list) adaptive_kernel = tfp.mcmc.SimpleStepSizeAdaptation( inner_kernel=inner_kernel, num_adaptation_steps=800 ) return tfp.mcmc.sample_chain( num_results=1000, current_state=inits, kernel=adaptive_kernel, num_burnin_steps=1000, trace_fn=None ) n_chains = 4 initial_log_rate = obs_model.sample(n_chains) samps = sampleHMC(log_prob, [tf.ones_like(initial_log_rate[0])*3.]) Just for comparison, if we call the sampler without the censored likelihood (meaning we \u0026ldquo;throw away\u0026rdquo; the censored observations), this is what we get:\nsamps_ignore_censored = sampleHMC( lambda log_rate:obs_model.log_prob([log_rate, tf.cast(obs_times, log_rate.dtype)[tf.newaxis,:]]), [tf.zeros_like(initial_log_rate[0])] ) sns.distplot(np.exp(samps[0].numpy().flatten()),label=\u0026#39;With censored\u0026#39;) sns.distplot(np.exp(samps_ignore_censored[0].numpy().flatten()),label=\u0026#39;Without censored\u0026#39;) plt.axvline(real_T.mean(),ls=\u0026#39;--\u0026#39;,c=\u0026#39;k\u0026#39;,label=\u0026#39;Empirical mean of real T\u0026#39;) plt.legend() plt.xlabel(\u0026#34;$\\lambda$\u0026#34;,size=15) plt.ylabel(\u0026#39;Density\u0026#39;,size=15) pass Survival regression This was a very simple and cooked-up demonstration of survival analysis, mainly to illustrate how to account for censored observations by adding the necessary LCCDF to the sampler log probability function. However, in many cases what we actually want is to understand how different features affect survival probability. For example, we\u0026rsquo;d like to understand how a given treatment affects the survival probabilities of patients, or the age of customers affects time-to-lapse or whatnot. This is called survival regression.\nLike in the previous posts, I\u0026rsquo;m sticking to the excellent examples from McElreath\u0026rsquo;s Statistical Rethinking book. However, this example is actually not from the book itself, but from Statistical Rethinking Winter 2019 Lecture 13 from 23:43 onwards (you should probably go watch this now, the relevant part is about 10 minutes long).\nThe data in this example is from an animal care facility in Austin (source), and describes cats arrival time to the facility, when/if/how they left, breed, color, age, etc. For us, the event of interest is adoption - we\u0026rsquo;ll try to estimate time-to-adoption. But this time, we\u0026rsquo;re using the cats color as a predictor: we\u0026rsquo;ll compare the adoption times of black cats vs. non-black cats.\nWe\u0026rsquo;re using the same data as McElreath (who kindly supplied both the data and the .R script containing the processing):\n# references to original data (from the email) df = pd.read_csv(\u0026#34;https://raw.githubusercontent.com/adamhaber/adamhaber.github.io/master/assets/AustinCats.csv\u0026#34;, delimiter=\u0026#39;;\u0026#39;) df[\u0026#39;black\u0026#39;] = df.color.apply(lambda x: x==\u0026#39;Black\u0026#39;) df[\u0026#39;adopted\u0026#39;] = df.out_event.apply(lambda x: x==\u0026#39;Adoption\u0026#39;) is_black_cens = tf.convert_to_tensor(df.query(\u0026#39;adopted==0\u0026#39;).black.values.astype(float)) is_black_obs = tf.convert_to_tensor(df.query(\u0026#39;adopted==1\u0026#39;).black.values.astype(float)) y_cens = tf.convert_to_tensor(df.query(\u0026#39;adopted==0\u0026#39;).days_to_event) y_obs = tf.convert_to_tensor(df.query(\u0026#39;adopted==1\u0026#39;).days_to_event) The model is very similar to our made-up example from before - the only thing that\u0026rsquo;s different is that now $\\log\\lambda$ is a simple linear function:\n$$\\log\\lambda = \\alpha+\\beta\\cdot\\text{is_black}$$\n$\\text{is_black}$ equals one for black cats, and zero otherwise, which means the log rate equals $\\alpha+\\beta$ for black cats and $\\alpha$ otherwise. So, instead of estimating $\\log\\lambda$ directly, we\u0026rsquo;re estimating the parameters of this simple linear model. The prior for the intercept is the same as in the previous example, and the prior for the slope is centered around zero (we don\u0026rsquo;t have a-priori reason to believe black cats are bigoted against), and of the same scale.\nobs_model = tfd.JointDistributionSequential( [ tfd.Normal(3, 3), #alpha tfd.Normal(0, 3), #beta lambda beta, alpha: tfd.Independent(tfd.Sample( tfd.Exponential(rate = 1/tf.math.exp(tf.cast(is_black_obs[tf.newaxis,:], beta.dtype)*beta[:,tf.newaxis]+\\ alpha[:,tf.newaxis]) )), reinterpreted_batch_ndims = 1) ] ) The LCCDF function is again very similar, but this time in the denominator we have our simple linear function and not just a single parameter:\ndef exponential_lccdf(alpha, beta): return tf.reduce_sum( -tf.cast(y_cens[tf.newaxis,:],alpha.dtype) / tf.exp(tf.cast(is_black_cens[tf.newaxis,:], beta.dtype) * beta[:,tf.newaxis] + alpha[:,tf.newaxis]), axis=-1 ) log_prob is exactly the same, and so is the code for calling the sampler:\ndef log_prob(alpha, beta): lp = obs_model.log_prob([alpha, beta, tf.cast(y_obs, alpha.dtype)[tf.newaxis,:]]) potential = exponential_lccdf(alpha, beta) return lp + potential n_chains = 4 initial_coeffs = obs_model.sample(n_chains) alphas, betas = sampleHMC(log_prob, [tf.zeros_like(initial_coeffs[0]), tf.zeros_like(initial_coeffs[1])]) We convert samples back to numpy for easier plotting, and compute the corresponding rates:\nalphas = alphas.numpy().flatten() betas = betas.numpy().flatten() lambda_black = np.exp(alphas + betas) lambda_non_black = np.exp(alphas) sns.distplot(lambda_black,color=\u0026#39;k\u0026#39;,label=\u0026#39;black\u0026#39;) sns.distplot(lambda_non_black,color=\u0026#39;orange\u0026#39;,label=\u0026#39;non black\u0026#39;) plt.legend(fontsize=15) plt.xlabel(\u0026#34;Days to adoption\u0026#34;,size=15) plt.ylabel(\u0026#34;Density\u0026#34;,size=15) It turns out people are biased against black cats! We can also use the inferred rates to plot one of the central quantities of interest in survival analysis - the survival function. The survival function is simply the CCDF from before:\n$$S(t) = P(T\u0026gt;t)$$\n$S(t)$ quantifies the probability of surviving longer than $t$. For the minimal possible duration (0 in our case), $S(0)=1$, and $S(\\infty)=0$ (everyone dies). We can use the inferred rates to plot the estimated survival curves:\nt = np.linspace(0,200) for lam_nb, lam_b in zip(lambda_non_black[:100], lambda_black[:100]): plt.plot(t, np.exp(-t/lam_nb),c=\u0026#39;orange\u0026#39;, alpha=0.1) plt.plot(t, np.exp(-t/lam_b),c=\u0026#39;black\u0026#39;, alpha=0.1) plt.ylabel(\u0026#34;Proportion remaining\u0026#34;) plt.xlabel(\u0026#34;Days\u0026#34;) legend_elements = [Line2D([0], [0], color=\u0026#39;black\u0026#39;, label=\u0026#39;black\u0026#39;), Line2D([0], [0], color=\u0026#39;orange\u0026#39;, label=\u0026#39;orange\u0026#39;)] plt.legend(handles=legend_elements,fontsize=15) \u0026hellip; which is the same plot as in the lecture.\nOverthinking box - Kaplan Meier non-parametric estimator In all we\u0026rsquo;ve done so far, we\u0026rsquo;ve assumed a specific parametric form for the durations distributions\u0026hellip; but how can we check if this assumption makes any sense? One way is to compare it to a non-parametric estimator of the survival function.\nThe Kaplan-Meier estimator is a non-parametric estimator that does just that. It is defined as follows:\n$$S_{KM}\\left(t\\right) = \\prod_{t_i\u0026lt;t}{\\left(1-\\frac{d_i}{n_i}\\right)}$$\nWhere $t_i$ are all the event times smaller than $t$ (from the data itself); $n_i$ is the number of people \u0026ldquo;at risk\u0026rdquo; between $t_{i-1}$ and $t_i$ (which means they survived all the events up to and including $t_{i-1}$); and $d_i$ is the number of observed deaths at time $t_i$ (deaths at the interval $\\left(t_{i-1},t_i\\right]$).\nThis formula has a pretty intuitive explanation - surviving up to time $t$ means surviving all the events before $t$; For each such event, in which $d_i$ out of $n_i$ subjects died, the estimated survival probability is $1-\\frac{d_i}{n_i}$, so surviving all of them is the product of all these numbers.\nInstead of implementing KM estimator ourselves, we\u0026rsquo;ll use the wonderful lifelines library, which is the most comprehensive python package for survival analysis I know of (R has a much better survival analysis ecosystem). Implementation is easy, but if you\u0026rsquo;re interested in survival analysis, you should check out lifelines; it has a wonderful API, great docs and a wide range of models, helper functions, plotting and summary statistics.\nWe\u0026rsquo;ll fit two KM estimators - one for black cats and one for non-black cats, so we can compare the non-parametric to our parametric survival functions:\nfrom lifelines import KaplanMeierFitter plt.figure(figsize=(9,9)) ax = plt.subplot(111) kmf = KaplanMeierFitter() kmf.fit(df[df.black==1].days_to_event, event_observed=df[df.black==1].adopted,label=\u0026#39;black cats\u0026#39;) kmf.plot(ax=ax,c=\u0026#39;k\u0026#39;) kmf.fit(df[df.black==0].days_to_event, event_observed=df[df.black==0].adopted,label=\u0026#39;non black cats\u0026#39;) kmf.plot(ax=ax,c=\u0026#39;orange\u0026#39;) for lam_nb, lam_b in zip(lambda_non_black[:100], lambda_black[:100]): plt.plot(t, np.exp(-t/lam_nb),c=\u0026#39;orange\u0026#39;, alpha=0.1) plt.plot(t, np.exp(-t/lam_b),c=\u0026#39;black\u0026#39;, alpha=0.1) plt.ylabel(\u0026#34;Proportion remaining\u0026#34;,size=15) plt.xlabel(\u0026#34;Days\u0026#34;,size=15) plt.legend(fontsize=15) plt.xlim(0, 100) What are we seeing here?\n The \u0026ldquo;smooth\u0026rdquo; black and orange curves are exponential survival curves with the sampled parameters. The \u0026ldquo;staircase\u0026rdquo; curves (aka piecewise constant functions) are the non parametric KM estimates. For details about their confidence intervals, see here.  So, how good is our assumed parametric form? That, of course, depends on how much you care about capturing all the small details; It seems to capture the overall trend, but, for example, it doesn\u0026rsquo;t quite capture the \u0026ldquo;sigmoidal\u0026rdquo;-like behavior around days 0-10, and it overestimates the survival probability between days 60-100 for both groups. This is somewhat expected - we\u0026rsquo;d be surprised if a single-parameter model would be able to capture all the details we see in the non-parametric curve.\nSumming up This post was pretty introductory - its main goal was to explain what censorship is (I think this is a super important concept to understand if you\u0026rsquo;re doing any kind of data analysis), and to implement a likelihood function that can handle censored observations. In the next post we\u0026rsquo;ll dive a little deeper into survival regression, still from a bayesian modeling persepctive.\n  One possible source of confusion here is the terminology; you will find the expressions \u0026ldquo;censored observations\u0026rdquo;, \u0026ldquo;censored times\u0026rdquo;, \u0026ldquo;events whose time were censored\u0026rdquo;, etc. used pretty interchangeably. Unless stated otherwise, all of these usually refer to same thing. \u0026#x21a9;\u0026#xfe0e;\n Technically, these are called \u0026ldquo;right censored\u0026rdquo; diapers; if you think of time as going from left to right like it\u0026rsquo;s usually plotted, than the right \u0026ldquo;tail\u0026rdquo; of the plots for these diapers is censored from us. There are also other kinds of censoring, but we\u0026rsquo;ll ignore them in this post. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"cf853bec0dd33f012210c8284fb64a43","permalink":"https://adamhaber.github.io/post/survival-analysis/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/post/survival-analysis/","section":"post","summary":"TL;DR Survival analysis is a super useful technique for modelling time-to-event data; implementing a simple survival analysis using TFP requires hacking around the sampler log probability function; in this post we\u0026rsquo;ll see how to do this, and introduce the basic terminology of survival analysis.\nSurvival analysis 101 Survival analysis is an incredibly useful technique for modeling time-to-something data. \u0026ldquo;something\u0026rdquo; can be the death a patient (hence the name), the failure of some part in a machine, the churn of a customer, the fall of a regime, and tons of other problems.","tags":["TFP","Survival Analysis"],"title":"Survival analysis, censoring and hacking the log_prob in TensorFlow Probability","type":"post"},{"authors":null,"categories":null,"content":"TL;DR Covariance matrices allow us to capture parameter correlations in multivariate hierarchical models; sampling these using Hamiltonian Monte Carlo in Tensorflow Probability can be tricky and confusing; this post is about some of the math involved and how to get this right.\nIntro Hierarchical models allow us to account for variations between different groups in our data. Let\u0026rsquo;s say that, for some reason, we have different groups of tadpoles in different tanks and we want to model per-tank survival rates. Varying intercepts models allow us to fit different models to different tanks, while pooling together information between tanks. The tanks are somewhat different (they\u0026rsquo;re not the same tank), so we allow their parameters to vary; but they\u0026rsquo;re also similar (they\u0026rsquo;re all tanks with tadpoles, not oranges or ships), so we can do some \u0026ldquo;transfer learning\u0026rdquo; between tanks.\nVarying intercepts are already very powerful models. However, in many (most?) situations, the models we fit have more than just an intercept. Let\u0026rsquo;s say we have 3 groups in our data, and we want to fit a simple linear model for each group, but also to share information between groups. Each model has two parameters (a slope and an intercept), and we allow these to vary. We can also allow them to covary. For example, if higher slopes usually go with lower intercepts, we want to know that, and use that to improve our estimation of both.\nTo capture this covariance amongst parameters, we\u0026rsquo;re going to need a covariance matrix.\nThe LKJ prior Every 2x2 covariance matrix can be decomposed as a product of a diagonal matrix of standard deviations $\\sigma_\\alpha,\\sigma_\\beta$ with a correlation matrix $\\Sigma$, in the following form (same holds for higher dimensions):\n$$\\mathbb{S} = \\left(\\begin{smallmatrix} \\sigma_\\alpha \u0026amp; 0 \\\\\\ 0 \u0026amp; \\sigma_\\beta \\end{smallmatrix}\\right) \\cdot \\Sigma \\cdot \\left(\\begin{smallmatrix} \\sigma_\\alpha \u0026amp; 0 \\\\\\ 0 \u0026amp; \\sigma_\\beta \\end{smallmatrix}\\right)$$\nThe decomposition is conceptually useful - it\u0026rsquo;s usually easier to think about the variances (which are single-parameter properties, and depend on things like unit of measurement and typical scale) separately from the correlation structure (a pairwise property). Technically, putting a prior on the variances isn\u0026rsquo;t very hard - we just need to make sure the variables are non-negative.\nA priori, it\u0026rsquo;s not obvious how to put a prior on correlation matrices. We can\u0026rsquo;t sample each matrix element by itself; correlation matrices have to be postitive definite, so their elements are somewhat \u0026ldquo;entangled\u0026rdquo; - the value in the $\\left[i,j\\right]$-th entry effects the element in the $\\left[k,l\\right]$-th entry. Luckily for us, in 2009, Lewandowski, Kurowicka, and Joe published a method for generating random correlation matrices, aptly referred to as the LKJ distribution. Like other probablistic programming languages, TFP implements the LKJ distribution. It\u0026rsquo;s a distribution that gets two numbers as inputs - $N$, the dimension of the correlation matrix, and $\\eta$, a concentration parameter that controls how plausible are large correlations; Larger $\\eta$ mean correlations are more concentrated around zero 1.\n# the necessary imports import tensorflow as tf import tensorflow_probability as tfp import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import numpy as np from matplotlib.patches import Ellipse from tensorflow_probability import distributions as tfd from tensorflow_probability import bijectors as tfb tf.compat.v1.enable_eager_execution() # for plotting sns.set_palette(\u0026#34;muted\u0026#34;) # for reproducibility np.random.seed(324) tf.random.set_random_seed(234) Here\u0026rsquo;s how samples from different LKJ distributions look like. We sample 500 correltion matrices with $\\eta=1$ and 500 matrices with $\\eta=50$:\nplt.hist(tfd.LKJ(5,1).sample(500).numpy().flatten(), bins=np.linspace(-0.99,0.99), density=True, label=\u0026#34;$\\eta=1$\u0026#34;) plt.hist(tfd.LKJ(5,50).sample(500).numpy().flatten(), bins=np.linspace(-0.99,0.99), density=True, label=\u0026#34;$\\eta=50$\u0026#34;) plt.xlabel(\u0026#34;Correlation values\u0026#34;) plt.title(\u0026#34;500 5x5 correlation matrices\u0026#34;) plt.legend() Problem #1 - falling off the manifold So far so good - sampling correlation matrices seems straightforward. The problem starts when we want to use a Hamiltonian Monte Carlo (and we usually want to use Hamiltonian Monte Carlo) to sample from some larger model that contains an LKJ distribution. HMC allows us to generate samples from arbitrary joint distributions, not only from distributions for which we have explicit sampling methods. Here\u0026rsquo;s a toy example to illustrate the problem. The model is simply a single LKJ distribution within a JointDistributionSequential object:\nmodel = tfd.JointDistributionSequential( [ tfd.LKJ(2,2), ] ) model.sample() [\u0026lt;tf.Tensor: id=7897612, shape=(2, 2), dtype=float32, numpy= array([[ 1. , -0.43337458], [-0.43337458, 1. ]], dtype=float32)\u0026gt;]  model.sample() seems to work, so that\u0026rsquo;s encouraging. However, when we try to \u0026ldquo;naively\u0026rdquo; use an HMC sampler to generate samples from the model, things go wrong. We add a small helper function to avoid rewriting all the kernels everytime; see the previous post for explanations about the different function calls here.\ndef sampleHMC(log_prob, inits, bijectors_list = None): inner_kernel=tfp.mcmc.HamiltonianMonteCarlo( target_log_prob_fn=log_prob, step_size=0.1, num_leapfrog_steps=3 ) if bijectors_list is not None: inner_kernel = tfp.mcmc.TransformedTransitionKernel(inner_kernel, bijectors_list) adaptive_kernel = tfp.mcmc.SimpleStepSizeAdaptation( inner_kernel=inner_kernel, num_adaptation_steps=400 ) return tfp.mcmc.sample_chain( num_results=500, current_state=inits, kernel=adaptive_kernel, num_burnin_steps=500, trace_fn=None ) lkj_samps = sampleHMC( log_prob=lambda lkj: model.log_prob([lkj]), inits=model.sample() )[0] lkj_samps[:3] # we print the first 3 samples  \u0026lt;tf.Tensor: id=8349304, shape=(3, 2, 2), dtype=float32, numpy= array([[[ 28.062887, 81.77511 ], [-80.5103 , -68.75983 ]], [[ 65.458626, 72.01995 ], [-87.03769 , -59.71089 ]], [[104.11292 , 85.66264 ], [-83.73789 , -60.2727 ]]], dtype=float32)\u0026gt;  Here we can already see the problem; these aren\u0026rsquo;t correlation matrices by any means. What\u0026rsquo;s happening here is that HMC, which operates in an unconstrained space of real numbers, \u0026ldquo;falls off\u0026rdquo; the correlation matrices manifold. The solution for this is what\u0026rsquo;s called a bijector. Without getting into the gory mathematical details 2, a bijector can be thought of as a differentiable one-to-one mapping between the unconstrained space in which the HMC trajectories live, and the constrained manifold. HMC produces samples in the unconstrained space, and the appropriate bijector spits out a valid correlation matrix. For us, this bijector is tfb.CorrelationCholesky(). Note that we need to pass a list of bijectors to the TransformedTransitionKernel constructor; in this case, we\u0026rsquo;re passing just a single bijector:\nbij_lkj_samps = sampleHMC( log_prob=lambda lkj: model.log_prob([lkj]), inits=model.sample(), bijectors_list=[tfb.CorrelationCholesky()] )[0] bij_lkj_samps[:3] \u0026lt;tf.Tensor: id=9873388, shape=(3, 2, 2), dtype=float32, numpy= array([[[ 1. , 0. ], [-0.43139905, 0.90216124]], [[ 1. , 0. ], [-0.43139905, 0.90216124]], [[ 1. , 0. ], [-0.43139905, 0.90216124]]], dtype=float32)\u0026gt;  At first glance, these don\u0026rsquo;t look like correlation matrices either; that\u0026rsquo;s because they\u0026rsquo;re the Cholesky factors of kosher correlation matrices.\nOverthinking box - Cholesky factors 3 Every correlation matrix $\\Sigma$ can be decomposed as a product of a lower triangular matrix $L$ and its transpose $L^T$. More formally, a lower triangular matrix $L$ is the Cholesky factor of some correlation matrix $\\Sigma$ if and only if its diagonal elements are strictly positive and each of its rows has unit norm.\nCholesky factors come up in many different places in statistics, machine learning, metric learning, computational linear algebra, etc. In the context of Monte Carlo simulations, Cholesky factors are used to generate correlated quantities (which we often want) from uncorrelated samples (which are easy to generate in the computer): If $z$ is a matrix of uncorrelated normally distributed numbers, and $L$ is the Cholesky factor of some correlation matrix $\\Sigma$, then $Lz$ would have the correlation structure described by $\\Sigma$.\nHere\u0026rsquo;s a simple demonstration. We generate 1000 samples from a bivariate guassian with zero mean, unit variance and no correlation:\nz = tf.transpose(tfd.MultivariateNormalDiag(loc=[0,0], scale_diag=[1,1]).sample(1000)) We now define a correlation matrix between two variables with correlation -0.85. We compute its Cholesky factor, multiply it with the original (uncorrelated) data, and voila:\nM = tf.constant([[1,-0.85],[-0.85,1]]) L = tf.cholesky(M) Lz = L@z plt.scatter(z[0], z[1], label=\u0026#34;$z$\u0026#34;) plt.scatter(Lz[0], Lz[1], label=\u0026#34;$Lz$\u0026#34;) plt.legend(loc=\u0026#39;upper right\u0026#39;) We can see that the two components of $Lz$ are negatively correlated, as expected. More quantitatively, here\u0026rsquo;s the correlation matrix for the cholesky-tranformed data:\ntfp.stats.correlation(tf.transpose(Lz)) \u0026lt;tf.Tensor: id=9873636, shape=(2, 2), dtype=float32, numpy= array([[ 0.9999995 , -0.8532509 ], [-0.8532509 , 0.99999976]], dtype=float32)\u0026gt;  Problem #2 - the wrong log_prob So the bijector solves the constrained-unconstrained problem, and HMC can run smoothly. But things are trickier than that (and the sampler won\u0026rsquo;t tell you that). The HMC sampler works with the log probability function of the model. If we have an LKJ distribution somewhere in our model, than for every sample, HMC computes the log_prob of the correlation matrix according to LKJ. But LKJ is a distribution over correlation matrices, not Cholesky factors of correlation matrices, which is the output of our bijector! So we end up computing the wrong log_prob, which means we\u0026rsquo;re not sampling from the model we think we\u0026rsquo;re sampling. So what can we do?\nSolution number 1 is to make sure our cholesky-factors-of-correlation-matrices become correlation matrices before we compute their log_prob according to LKJ. To do so, we need two more bijectors: tfb.CholeskyOuterProduct, which maps $L$ to $LL^T$, and tfb.Chain which, surprisingly, chains (composes) the two bijectors:\nchained_bij_samps = sampleHMC( lambda lkj: model.log_prob([lkj]), model.sample(), bijectors_list=[tfb.Chain([tfb.CholeskyOuterProduct(), tfb.CorrelationCholesky()])] )[0] chained_bij_samps[:3] \u0026lt;tf.Tensor: id=12661134, shape=(3, 2, 2), dtype=float32, numpy= array([[[ 1. , -0.21354356], [-0.21354356, 1. ]], [[ 1. , -0.21354356], [-0.21354356, 1. ]], [[ 1. , 0.01905983], [ 0.01905983, 1.0000001 ]]], dtype=float32)\u0026gt;  This looks good. And this time it actually is - this is doing what we think it\u0026rsquo;s doing. But this is cumbersome, and not very readable. Even worse, when we\u0026rsquo;ll pass these correlations matrices to a multivariate gaussian (the usual case), it\u0026rsquo;ll compute their cholesky factors anyway (check out the source code, as well as the depracation warning above it). So we end up sampling cholesky factors, tranforming them back to correlation matrices just to compute their cholesky factors again\u0026hellip;\nEnter CholeskyLKJ Since tfp-nightly-0.9.0.dev20190830 (a daily-built version that contains the newest changes that have yet to made it into the latest stable release), we have a better option - the CholeskyLKJ distribution. Unlike LKJ, this is a distribution over cholesky factors of correlation matrices - so no need to go back and forth, or to chain bijectors\u0026hellip; It\u0026rsquo;s faster, numerically stabler, and it is by the book.\nTo use it, we just need a single tfb.CorrelationCholesky() bijector:\nmodel = tfd.JointDistributionSequential( [ tfd.CholeskyLKJ(2,2), ] ) cholesky_lkj_samps = sampleHMC( lambda lkj: model.log_prob([lkj]), model.sample(), bijectors_list=[tfb.CorrelationCholesky()] )[0] cholesky_lkj_samps[:3] \u0026lt;tf.Tensor: id=14269238, shape=(3, 2, 2), dtype=float32, numpy= array([[[ 1. , 0. ], [ 0.20048861, 0.97969604]], [[ 1. , 0. ], [-0.19122852, 0.9815455 ]], [[ 1. , 0. ], [ 0.18798688, 0.9821716 ]]], dtype=float32)\u0026gt;  A simple use case We\u0026rsquo;ve covered the technicalities of sampling correlation matrices (and their Cholesky factors) with TFP. To get a more complete picture of how these are actually used, let\u0026rsquo;s see an example. We\u0026rsquo;re sticking with McElreath and Statistical Rethinking; this time we\u0026rsquo;re reproducing the caf waiting times example.\nFake data Unlike the tadpoles example, this time we\u0026rsquo;re going to model fake data (aka synthetic data). This may sound strange, but it\u0026rsquo;s actually a very useful skill, and it\u0026rsquo;s considered by many to be pretty much the first step in a Bayesian data analysis workflow (see here). The reason is that unlike in a \u0026ldquo;real data analysis\u0026rdquo;, when you\u0026rsquo;re generating fake data, you know the true underlying data generating process; making sure you can recover its parameters is a very important sanity check. It also helps in verifying the model is correctly specified and that the MCMC sampler does what you think it does, which is good.\nThe data we\u0026rsquo;re generating describes the waiting times in 20 different cafs. Each caf has a different average waiting times in the morning and in the afternoon. The average morning waiting time is the intercept, and the difference between afternoon and morning average waiting times is the slope. The intercepts and slopes for each of the 20 cafs are sampled from a (surprise surprise) correlated bivariate Gaussian distribution.\n##### Inputs needed to generate the covariance matrix between intercepts and slopes ##### a = 3.5 # average morning wait time b = -1 # average difference afternoon wait time sigma_a = 1 # standard deviation in the (caf-specific) intercepts sigma_b = 0.5 # standard deviation in the (caf-specific) slopes rho = -0.7 # correlation between intercepts and slopes mu = [a,b] # the mean of our gaussian distribution sigmas = [sigma_a,sigma_b] # vector of standard deviations corr_matrix = np.array([[1,rho], [rho,1]]) # correlation matrix cov_matrix = np.diag(sigmas)@corr_matrix@np.diag(sigmas) # the covariance matrix of our gaussian distribution  After setting the true parameters, we\u0026rsquo;re generating 20 samples of cafs:\nn_cafs = 20 # 20 cafs overall caf_params = np.random.multivariate_normal(mu ,cov_matrix,size=n_cafs) caf_intercept = caf_params[:, 0] # intercepts are in the first column caf_slopes = caf_params[:, 1] # slopes are in the second And compute the actual per-caf morning and afternoon waiting times, in 10 different visits. Below is a sample of 10 rows from our dataframe (which has 200 data points overall - 10 visits in 20 cafs):\nn_visits = 10 # 10 visits per caf afternoon = np.tile([0,1], n_visits * n_cafs//2) # alternate values for mornings and afternoons in the data frame caf_id = np.repeat(np.arange(n_cafs),n_visits) # data for each caf are consecutive rows in the data frame mu = caf_intercept[caf_id] + caf_slopes[caf_id] * afternoon # the regression equation for the mean waiting time sigma = 0.5 # standard deviation of waiting time within cafs wait = np.random.normal(mu, sigma, n_visits * n_cafs) # generate instances of waiting times df = pd.DataFrame(dict(caf = caf_id, afternoon = afternoon, wait = wait)) print(df.sample(10).to_string(index=False))  caf afternoon wait 8 1 2.175858 9 0 2.364313 9 1 1.744504 14 0 3.716937 3 1 1.419163 0 1 1.959044 5 0 1.045913 4 0 1.083699 17 1 2.796278 15 1 3.430852  The model We specify in math (and latex) the model described above:\n$$\\begin{align} W_i \u0026amp; \\sim \\text{Normal}(\\alpha_{caf[i]}+\\beta_{caf[i]}\\cdot \\text{AFTERNOON}_i,\\sigma) \\\\\\\n\\binom{\\alpha_{caf}}{\\beta_{caf}} \u0026amp; \\sim \\text{MVNormal}\\left(\\binom{\\alpha}{\\beta},\\mathbb{S}\\right) \\\\\\\n\\mathbb{S} \u0026amp; = \\left(\\begin{smallmatrix} \\sigma_\\alpha \u0026amp; 0 \\\\\\ 0 \u0026amp; \\sigma_\\beta \\end{smallmatrix}\\right) \\cdot LL^T \\cdot \\left(\\begin{smallmatrix} \\sigma_\\alpha \u0026amp; 0 \\\\\\ 0 \u0026amp; \\sigma_\\beta \\end{smallmatrix}\\right) \\\\\\\n\\alpha \u0026amp; \\sim \\text{Normal}(5,2) \\\\\\\n\\beta \u0026amp; \\sim \\text{Normal}(-1,0.5) \\\\\\\n\\sigma_{\\alpha},\\sigma_{\\beta} \u0026amp; \\sim \\text{Exp}(1) \\\\\\\n\\sigma \u0026amp; \\sim \\text{Exp}(1) \\\\\\\nL \u0026amp; \\sim \\text{CholeskyLKJ}(2,2) \\\\\\\n\\end{align}$$\nmodel = tfd.JointDistributionSequential( [ tfd.CholeskyLKJ(2,2), # rho, the prior for the correlation matrix between intercepts and slopes tfd.Sample(tfd.Exponential(rate = 1),sample_shape = 1), # sigma, prior std for the waiting time tfd.Sample(tfd.Exponential(rate = 1),sample_shape = 2), # sigma_caf, prior of stds for intercepts and slopes (vector of 2) tfd.Sample(tfd.Normal(loc = -1, scale = 0.5), sample_shape = 1), # b, the prior mean for the slopes tfd.Sample(tfd.Normal(loc = 5, scale = 2), sample_shape = 1), # a, the prior mean for the intercepts lambda a,b,sigma_caf,sigma,chol_rho : tfd.Sample( # per-caf intercepts and slopes tfd.MultivariateNormalTriL( loc = tf.concat([a,b],axis=-1), scale_tril = tf.linalg.LinearOperatorDiag(sigma_caf).matmul(chol_rho) ), sample_shape=n_cafs ), lambda mvn, a, b, sigma_caf, sigma : tfd.Independent( #per-caf waiting times tfd.Normal( loc = tf.gather(mvn[:,:,0],caf_id,axis=-1) + tf.gather(mvn[:,:,1],caf_id,axis=-1)*afternoon, scale = sigma ), reinterpreted_batch_ndims=1 ) ] ) Couple of non-trivial things in the model above:\n MultivariateNormalTriL: we\u0026rsquo;ve mentioned that a covariance matrix can be specified as $\\Lambda L L^T\\Lambda$ where $\\Lambda$ is a diagonal matrix of standard deviations and $L$ is the cholesky factor of the correlation matrix. MultivariateNormalTriL is a parametrization of a multivariate normal distribution whose covariance matrix is specificied using the lower triangular matrix $\\Lambda L$. LinearOperatorDiag: this turns a sigma-caf vector of length 2 to a 2x2 diagonal matrix; very similar to tf.diag, but handles all the batching semantics for us. tf.gather: this takes each intercept (in the case of mvn[:,:,0]) and slope (in the case of mvn[:,:,1] and tiles it 10 times, so overall we get a loc vector of size 200, with which we generate 200 different waiting times, 10 per caf.  We now declare the target_log_prob function for the HMC kernel, and initial values for 4 different chains. Like before, we throw away the last sample (predicted waiting times); we want to plug the waiting times from the data into the likelihood, instead.\nn_chains = 4 log_prob_fn = lambda rho, sigma, sigma_caf, b, a, mvn : model.log_prob([rho, sigma, sigma_caf, b, a, mvn ,wait]) init_rho, init_sigma, init_sigma_caf, init_b, init_a, init_mvn, _ = model.sample(n_chains) These initial values are used to specify the shape of the initial values we actually pass, specified below:\ninit_rho = tf.stack([tf.eye(2) for _ in range(n_chains)]) init_sigma = tf.ones_like(init_sigma) init_sigma_caf = tf.ones_like(init_sigma_caf) init_b = tf.zeros_like(init_b) init_a = tf.zeros_like(init_a) init_mvn = tf.zeros_like(init_mvn) We define the list of bijectors. Note that since standard deviations are non-negative, their support is constrained, and we need a bijector here, as well. The appropriate bijector in this case is tfb.Exp. Once we specificed a bijectors list, we need to match a bijector for any distribution in our JointDistributionSequential object; since the support of a, b and mvn is unconstrained, we simply use an identity transformation:\nbijectors_list = [ tfb.CorrelationCholesky(), tfb.Exp(), tfb.Exp(), tfb.Identity(), tfb.Identity(), tfb.Identity(), ] states = sampleHMC(log_prob_fn, [init_rho, init_sigma, init_sigma_caf, init_b, init_a, init_mvn], bijectors_list) [s.shape for s in states] [TensorShape([Dimension(500), Dimension(4), Dimension(2), Dimension(2)]), TensorShape([Dimension(500), Dimension(4), Dimension(1)]), TensorShape([Dimension(500), Dimension(4), Dimension(2)]), TensorShape([Dimension(500), Dimension(4), Dimension(1)]), TensorShape([Dimension(500), Dimension(4), Dimension(1)]), TensorShape([Dimension(500), Dimension(4), Dimension(20), Dimension(2)])]  Shapes look alright. To see the posterior distribution of covariance values, we move back from Cholesky factors to correlation matrices, and multiply by the inferred sigmas (the zeroth axis is the number of samples, first is the number of the chain, so we transpose the second and third axes):\nrhos = states[0]@tf.transpose(states[0],[0,1,3,2]) Same as above, we create diagonal matrices from our sampled sigma_alpha, sigma_beta values:\nsigmas = states[2] diag_sigmas = tf.linalg.LinearOperatorDiag(sigmas) inferred_covs = tf.matmul(diag_sigmas.matmul(rhos),diag_sigmas) plt.figure(figsize=(9,4)) for (row_idx,col_idx), title in zip([(0,0),(0,1),(1,1)],[\u0026#34;$\\sigma_{\\\\alpha}$\u0026#34;,\u0026#34;Covariance\u0026#34;,\u0026#34;$\\sigma_{\\\\beta}$\u0026#34;]): plt.subplot(131+row_idx+col_idx) sns.distplot(inferred_covs[:,:,row_idx,col_idx].numpy().flatten(), label = \u0026#34;Posterior\u0026#34;) plt.axvline(cov_matrix[row_idx,col_idx],c=\u0026#39;k\u0026#39;,ls=\u0026#39;--\u0026#39;,label=\u0026#34;True value\u0026#34;) plt.legend() plt.title(title) plt.tight_layout() We can also compare empirical waiting times with sampled waiting times:\nmorning_wait_emp = df.query(\u0026#39;afternoon == 0\u0026#39;).groupby(\u0026#39;caf\u0026#39;).wait.mean() afternoon_wait_emp = df.query(\u0026#39;afternoon == 1\u0026#39;).groupby(\u0026#39;caf\u0026#39;).wait.mean() morning_wait_pred = tf.reduce_mean(states[-1][:,:,:,0], axis=(0,1)) afternoon_wait_pred = tf.reduce_mean(states[-1][:,:,:,1], axis=(0,1)) + morning_wait_pred And we get the shrinkage that decorates Statistical Rethinking\u0026rsquo;s front cover:\nplt.figure(figsize=(9,6)) ax = plt.subplot(111) vals, vecs = np.linalg.eigh(np.cov(morning_wait_emp, afternoon_wait_emp)) theta = np.degrees(np.arctan2(*vecs[:,0][::-1])) w, h = 2 * np.sqrt(vals) for contour_line in range(1,5): ell = Ellipse(xy=(np.mean(morning_wait_emp), np.mean(afternoon_wait_emp)), width=w*contour_line, height=h*contour_line, angle=theta, color=\u0026#39;black\u0026#39;) ell.set_facecolor(\u0026#39;none\u0026#39;) ax.add_artist(ell) plt.scatter(morning_wait_emp,afternoon_wait_emp,label=\u0026#34;Empirical\u0026#34;) plt.scatter(morning_wait_pred,afternoon_wait_pred, label=\u0026#34;MCMC\u0026#34;) plt.scatter(morning_wait_emp.mean(),afternoon_wait_emp.mean(),marker=\u0026#39;+\u0026#39;,c=\u0026#39;r\u0026#39;,s=100, label=\u0026#34;Grand Mean\u0026#34;) plt.legend() for a,b,c,d in zip(morning_wait_emp, afternoon_wait_emp, morning_wait_pred, afternoon_wait_pred): plt.arrow(a,b,0.7*(c.numpy()-a),0.7*(d.numpy()-b), head_width=0.05, alpha=0.3) plt.xlabel(\u0026#34;Morning wait\u0026#34;) plt.ylabel(\u0026#34;Afternoon wait\u0026#34;)   Formally, the distribution is defined as: $\\text{LKJ}\\left(\\Sigma\\vert\\eta\\right)\\propto\\det\\left(\\Sigma\\right)^{\\left(\\eta-1\\right)}$. Intuitively, the correlation matrix defines an ellipsoid in $N$ dimensions, and its determinant is the volume of the ellipsoid. So, higher correlations -\u0026gt; tighter ellipsoid -\u0026gt; smaller volume -\u0026gt; smaller determinant -\u0026gt; more likely for small $\\eta$ and less likely for large $\\eta$. \u0026#x21a9;\u0026#xfe0e;\n Sigrid Keydana did an excellent job explaining TFP bijectors, and specifcally the intuition behind the jacobian correction, in this post. \u0026#x21a9;\u0026#xfe0e;\n Overthinking boxes are specific (usually mathematical) dive-ins in Statistical Rethinking. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1567382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567382400,"objectID":"b6f183b50638468f5f57165eecbe8b04","permalink":"https://adamhaber.github.io/post/varying-slopes/","publishdate":"2019-09-02T00:00:00Z","relpermalink":"/post/varying-slopes/","section":"post","summary":"TL;DR Covariance matrices allow us to capture parameter correlations in multivariate hierarchical models; sampling these using Hamiltonian Monte Carlo in Tensorflow Probability can be tricky and confusing; this post is about some of the math involved and how to get this right.\nIntro Hierarchical models allow us to account for variations between different groups in our data. Let\u0026rsquo;s say that, for some reason, we have different groups of tadpoles in different tanks and we want to model per-tank survival rates.","tags":["TFP","Multilevel Models"],"title":"Varying Slopes Models and the CholeskyLKJ distribution in TensorFlow Probability","type":"post"},{"authors":null,"categories":null,"content":"Intro This post is about building varying intercepts models using TensorFlow Probability (\u0026ldquo;TFP\u0026rdquo;). It\u0026rsquo;s basically my attempt to translate Sigrid Keydana\u0026rsquo;s wonderful blog post from R to Python. I\u0026rsquo;m doing this for a couple of reasons: First, I\u0026rsquo;ve played with TFP before, was quite impressed by its performance and flexibility, and wanted to learn more about it; Second, I wanted to start blogging, and this seemed like an easy start; Last, TFP is rather new, and there aren\u0026rsquo;t a whole lot of resources and tutorials about it - so this might even prove useful to someone, someday.\nSigrid dedicated her post to Richard McElreath and his book; I\u0026rsquo;d like to join her on that. I was looking for a good introduction to Bayesian stats for quite some time. BDA3 was too technical for me at that point, Kruschke\u0026rsquo;s was excellent but didn\u0026rsquo;t really dive into the more sophisticated topics I wanted to learn. Statistical Rethinking was spot on - interesting, fun to read, and super helpful. It\u0026rsquo;s very code-oriented, and has already been re-written in pure stan, brms, pymc3, julia and probably many others.\nStats-wise, this post is going to be about varying intercepts models, which are perhaps the simplest kind of a multilevel model. The main idea behind them - called partial pooling - is simple and beautiful, but here I want to focus on the code, not the stats; for a nice introductory demo, check out this beautiful visualization, or this one. Better yet, get a copy of Statistical Rethinking and read the original. :-)\nThe data We\u0026rsquo;re given data about 48 different tanks containing tadpoles (pre-frogs). Each tank has a density (the initial number of tadpoles in it), a categorical feature pred (whether the tank contained a predator or not), a categorical feature size (big tank or small tank), the number of surviving tadpoles surv and the proportion of surviving tadpoles propsurv (which is simply surv/density). The original data came with the book\u0026rsquo;s R package; Luckily, it\u0026rsquo;s hosted in Osvaldo Martin\u0026rsquo;s repo:\nimport pandas as pd df = pd.read_csv(\u0026#34;https://raw.githubusercontent.com/aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3/master/Data/reedfrogs.csv\u0026#34;) df.head()    Tank density pred size surv propsurv     0 10 no big 9 0.9   1 10 no big 10 1.0   2 10 no big 7 0.7   3 10 no big 10 1.0   4 10 no small 9 0.9    Tank densities are either 10, 25 or 35.\nThe model Our goal is to compute the probability of survival in each of the tanks. propsurv is one way to do this, which is straightforward and intuitive - simply compute the per-tank ratio of surviving tadpoles. But this doesn\u0026rsquo;t make much sense, especially if you consider the small sample sizes - if I\u0026rsquo;d give you a tank with density=1, would you feel comfortable with saying that the probability of survival is either 0% (surv=0) or 100% (surv=1)? Probably not.\nA different approach would be to ignore between-tanks variations, and assume all tanks have exactly the same probability of survival. Our best estimate is then the ratio of all the surviving tadpoles (in all tanks, combined) - or sum(surv)/sum(density).\nA varying intercept model is somewhat in between - it assumes each tank has its own probability of survival, but that all these probabilities are coming from some distribution over \u0026ldquo;probabilities of survival\u0026rdquo;. This is how it looks like:\n$$ \\begin{align} \\bar{\\alpha} \u0026amp; \\sim \\text{Normal}(0,1.5) \\\\\\\n\\sigma \u0026amp; \\sim \\text{Exponential}(1) \\\\\\\n\\text{logit}\\left(p_i\\right) \u0026amp; \\sim \\text{Normal}\\left(\\bar{\\alpha},\\sigma\\right) \\\\\\\ns_i \u0026amp; \\sim \\text{Binomial}(n_i,p_i) \\\\\\\n\\end{align} $$\nWhat\u0026rsquo;s all this? In short - we assume the logits of the survival probabilities are sampled from some normal distribution, whose parameters (often called \u0026ldquo;hyperparameters\u0026rdquo;) we\u0026rsquo;re trying to infer. a_bar is the mean of this normal distribution, and we put a generic weakly informative prior on it - normal(0,1.5). sigma is the standard deviation of this normal distribution, and we put an exponential prior on it. After sampling these two numbers, we plug them into the logits distribution, sample 48 different logit values, transform them to probabilities and sample 48 survival predictions from the binomial distributions (one per tank). Now to the code itself. We begin with the necessary imports:\nimport tensorflow as tf import tensorflow_probability as tfp import seaborn as sns import matplotlib.pyplot as plt import numpy as np tfd = tfp.distributions For ease-of-use, we\u0026rsquo;re using TensorFlow in Eager mode, which allows a more interactive and iterative workflow.\ntf.compat.v1.enable_eager_execution() Some TFP\u0026rsquo;s pre-requisites Before we start implementing the model itself, we need to cover some of the basic terminology around a TensorFlow Distribution. For the purposes of this introductory post, you can think of a distribution as an object with the following two methods:\n sample() log_prob()  Both are pretty straightforward - sample() allows you to generate samples from a given distribution; log_prob() allows you to calculate the log-probability of a given value(s). There are other methods, of course, but these are the important ones for us. There are two more attributes we need to mention:\n event_shape batch_shape  These were, at least for me, quite confusing (despite their pretty good docs). event_shape is the simpler of the two - if I have some joint probability distribution over N random variables, its event_shape is N. For example, a bivariate gaussian would have an event shape of 2.\nbatch_shape is trickier: TFP allows you to create a single Distribution object, which actually contains multiple, independent distributions. For example, tfd.Bernoulli(probs=[.3, .5, .7]) is a Distribution object composed of 3 different Bernoulli random variables (RVs) with probabilities of success .3, .5 and .7. The number of the independent distributions contained in this single object is its batch_shape. Why do this? My best guess is that it gives TFP the ability to make use of the underlying TF infrastructure, in which batching (and broadcasting along a batch dimension) is a fundamental operation. We\u0026rsquo;ll get back to this in the code below.\nNow we\u0026rsquo;ll go ahead and define the model itself using TFP\u0026rsquo;s JointDistributionSequential API:\nm = tfd.JointDistributionSequential( [ tfd.Normal(loc=0, scale=1.5), tfd.Exponential(rate=1.), lambda sigma, a_bar: tfd.Sample(tfd.Normal(loc=a_bar, scale=sigma),sample_shape=[df.shape[0]]), lambda l: tfd.Independent(tfd.Binomial(total_count=df.density.astype(\u0026#39;float32\u0026#39;), logits=l), reinterpreted_batch_ndims=1) ] ) The main workhorse here is tfd.JointDistributionSequential, which is very similar to Sequential in Keras or PyTorch. It\u0026rsquo;s an object composed of list of Distribution-making functions (tfd.Distributions or Python callables that return a tfd.Distribution). The idea of sequentially stacking distributions, and adding the dependencies between them (the fact that the values sampled from tfd.Normal and tfd.Exponential are \u0026lsquo;fed\u0026rsquo; into the 3rd distribution as its mean and standard deviation) is simple and intuitive, and fits nicely in the hierarchical modeling workflow; the code above is basically a 1-to-1 translation of the model specification.\nThe tricky parts here are TFP\u0026rsquo;s Sample and Independent. What are these, then?\n Sample - The third function receives the hyper-parameters sigma and a_bar, and should return one number per tank, drawn from a normal(a_bar,sigma). tfd.Sample allows us to draw samples from the product distribution of all these 48 Gaussians; each sample from Sample is a vector of 48 (uncorrelated) numbers, all with the same mean a_bar and standard deviation sigma. Independent - the third distribution returns a vector of 48 numbers. If we simply write tfd.Binomial(total_count=df.density.astype('float32'), logits=l), we\u0026rsquo;ll get a distribution with a batch_shape of 48 and an event_shape (), representing a scalar output. Wrapping this with tfd.Independent transforms this output to be of batch_shape () and event_shape 48, representing a vector output, like we want it to be.  Another possibly-confusing issue here is the order of the parameters in the lambda expressions. The first parameter is the output of the previous distribution in the list, the second parameter is the output of the previous-previous distribution, etc\u0026hellip; This is why they third distribution gets sigma before a_bar despite the fact sigma is defined after a_bar.\nI found this API somewhat different than the \u0026ldquo;natural\u0026rdquo; way to think about the problem; however, if this ends up with superior performance, it\u0026rsquo;s probably worth the learning curve for a wide enough range of problems.\nSampling from a model The model\u0026rsquo;s sample() method gets a sample_shape argument which determines the shape of the generated sample. This, in turn, will be used to tell the MCMC sampler how many chains to run in parallel.\nn_chains = 4 initial_a, initial_s, initial_logits, init_surv = m.sample(n_chains) Since we\u0026rsquo;ve asked for 4 chains, m.sample() returns 4 samples from the a_bar hyperprior and 4 samples from the sigma hyperprior; these, in turn, generate 4 new normal distributions, from which we sample 4x48 logit values. These values are then \u0026ldquo;pushed forward\u0026rdquo;, generating 4x48 samples from the binomial survival distributions. These survival predictions can (and probably should) be used to perform prior predictive checks, but we don\u0026rsquo;t need them to define the sampler, itself.\ninitial_a.shape, initial_s.shape, initial_logits.shape, init_surv.shape (TensorShape([Dimension(4)]), TensorShape([Dimension(4)]), TensorShape([Dimension(4), Dimension(48)]), TensorShape([Dimension(4), Dimension(48)]))  Now we create the sampler object. This step is composed of 3 different TFP objects. The first is the Hamiltonian Monte Carlo transition kernel, which uses the model\u0026rsquo;s .log_prob() function:\ninner_kernel=tfp.mcmc.HamiltonianMonteCarlo( target_log_prob_fn = lambda x,y,z : m.log_prob([x,y,z,df.surv.astype(\u0026#39;float32\u0026#39;)]), step_size=0.1, num_leapfrog_steps=3 ) Note that we\u0026rsquo;re not using the model\u0026rsquo;s .log_prob() as is; instead, we make sure that the log-probability is always computed with respect to the actual, observed survival data. This is the purpose of the lambda function above. For the other two required parameters, I\u0026rsquo;m using the ones from Sigrid\u0026rsquo;s post.\nThe second part is the SimpleStepSizeAdaptation object, which takes the kernel defined above and returns a new kernel with dynamic step size adaptation:\nkernel = tfp.mcmc.SimpleStepSizeAdaptation( inner_kernel=inner_kernel, target_accept_prob = 0.8, num_adaptation_steps = 500 ) Lastly, the sampling function. This object takes as input the initial states (and through them, number of chains to run), number of burnin steps, number of steps to run after burnin, a kernel (our augmented HMC kernel), and a trace function, which determines what kind of intermediate results we want to save. After sampling ends (this can take a while, depending on the complexity of your model), the function returns the samples (and traced results). Here I\u0026rsquo;ve decided not to save intermediate results, at all; the simple diagnostics I\u0026rsquo;m interested in can be computed from the samples themselves.\na_bars, sigmas, logits = tfp.mcmc.sample_chain( current_state=[ tf.zeros_like(initial_a), tf.ones_like(initial_s), initial_logits ], num_results=500, num_burnin_steps=500, kernel=kernel, trace_fn=None ) Let\u0026rsquo;s have a look at the output shapes:\na_bars.shape, sigmas.shape, logits.shape (TensorShape([Dimension(500), Dimension(4)]), TensorShape([Dimension(500), Dimension(4)]), TensorShape([Dimension(500), Dimension(4), Dimension(48)]))  The sampler returned 500 samples per chain per parameter - exactly what we want.\nTFP provides standard MCMC diagnostics, such as effective sample size per logit parameter (we average over chains):\ntf.reduce_mean(tfp.mcmc.effective_sample_size(logits),axis=0) \u0026lt;tf.Tensor: id=1643926, shape=(48,), dtype=float32, numpy= array([ 39.01448 , 27.656044, 64.033554, 23.641933, 38.67304 , 43.81818 , 27.42485 , 56.60047 , 86.46597 , 53.400955, 62.463234, 68.98154 , 71.84833 , 85.98772 , 53.90014 , 45.368874, 57.142807, 64.70456 , 80.501144, 30.96955 , 51.123882, 90.971016, 83.67827 , 133.95776 , 147.53087 , 237.56706 , 124.73306 , 213.96054 , 255.63586 , 127.86496 , 169.16728 , 222.58665 , 57.26799 , 62.313004, 59.934887, 140.44281 , 126.62906 , 44.229973, 80.57881 , 100.344055, 102.71631 , 307.0775 , 298.0421 , 298.77765 , 275.2672 , 241.8357 , 134.39154 , 334.7177 ], dtype=float32)\u0026gt;  And R-hat values:\ntfp.mcmc.potential_scale_reduction(logits) \u0026lt;tf.Tensor: id=1643986, shape=(48,), dtype=float32, numpy= array([1.0393666, 1.0419586, 1.014595 , 1.0326122, 1.0066991, 1.0365033, 1.1032237, 1.0193528, 1.0026469, 1.03286 , 1.0212902, 1.0046616, 1.0046593, 1.0190336, 1.0491707, 1.0185002, 1.0236404, 1.0240865, 1.0135043, 1.0091226, 1.0240618, 1.0212263, 1.0040884, 1.0057993, 1.0115193, 1.0074626, 1.0053723, 1.0013644, 1.0038955, 1.0128344, 1.0199273, 1.0040274, 1.1276014, 1.0033313, 1.0127679, 1.0017091, 1.0118763, 1.0570774, 1.04308 , 1.0189458, 1.0144566, 1.0009695, 1.0063009, 1.0008804, 1.0011569, 1.0057343, 1.0079254, 1.0071955], dtype=float32)\u0026gt;  We can easily inspect the traceplots of the hyperparameters (each color stands for a different chain):\nplt.subplot(121) plt.plot(a_bars.numpy(),alpha=0.3) plt.subplot(122) plt.plot(sigmas.numpy(),alpha=0.3) We get nicely mixed chains, which is good. We can also plot the posterior distributions of the logits for the different tanks:\nplt.figure(figsize=(12,9)) for i in range(df.shape[0]): plt.subplot(7,7,i+1) for j in range(n_chains): sns.kdeplot(np.array(logits[:,j,i])) plt.tight_layout() Here, each subplot corresponds to one tank, and different colors represent different chains. Just by eye-balling the posteriors, we can see a lot of variability between tanks; this is obvious when we compute posterior survival probabilities themselves:\nps = tf.sigmoid(logits).numpy() plt.figure(figsize=(12,9)) for i in range(df.shape[0]): current_ps = ps[:,:,i] pred = plt.errorbar(x=[i],y=[current_ps.mean()], yerr=np.array([current_ps.mean()-np.quantile(current_ps,0.25), np.quantile(current_ps,0.75)-current_ps.mean()]).reshape(2,-1), fmt=\u0026#39;o\u0026#39;,c=\u0026#39;k\u0026#39;) act = plt.scatter(i,df.loc[i,\u0026#39;propsurv\u0026#39;],c=\u0026#39;r\u0026#39;) plt.grid() plt.xlabel(\u0026#34;Tank number\u0026#34;,fontsize=20) plt.ylabel(\u0026#34;Survival probability\u0026#34;,fontsize=20) plt.axhline(df.surv.sum()/df.density.sum(),lw=1) for density_change in np.where(df.density.diff())[0][1:]: plt.axvline(density_change,ls=\u0026#39;--\u0026#39;,c=\u0026#39;k\u0026#39;,lw=1) plt.legend([pred,act],[\u0026#39;50%Prediction Interval\u0026#39;,\u0026#39;propsurv\u0026#39;]) The black dots are the posterior mean probabilities, the errorbars represent the interquartile range, the red dots are propsurv (the no-pooling estimate), and the blue horizontal line is the grand mean (the complete-pooling estimate). Vertical lines split the tanks to densities 10, 25 and 35. We can see that, as expected, posterior probabilities are shrunk towards the grand mean. We can also plot the difference between the posterior means and propsurv, to observe that shrinkage is indeed larger when the sample size is smaller:\nfor i in range(df.shape[0]): current_ps = ps[:,:,i] plt.scatter(i,(df.loc[i,\u0026#39;propsurv\u0026#39;]-current_ps.mean()),c=\u0026#39;k\u0026#39;) plt.axhline(0,lw=1) for density_change in np.where(df.density.diff())[0][1:]: plt.axvline(density_change,ls=\u0026#39;--\u0026#39;,c=\u0026#39;k\u0026#39;,lw=1) plt.xlabel(\u0026#34;Tank number\u0026#34;,fontsize=20) plt.ylabel(\u0026#34;Shrinkage\u0026#34;,fontsize=20) Wrapping up TFP certainly has a different feel to it compared to other probabilistic programming frameworks like PyMC3 or Stan; specifically, the introduction of batching semantics, and the complexity of the API that is exposed, are very different and pose a real learning curve. The slope, I guess, depends on one\u0026rsquo;s background.\n","date":1562544000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562544000,"objectID":"56b1e524d2c3906c861bff245c5733a3","permalink":"https://adamhaber.github.io/post/varying-intercepts/","publishdate":"2019-07-08T00:00:00Z","relpermalink":"/post/varying-intercepts/","section":"post","summary":"Intro This post is about building varying intercepts models using TensorFlow Probability (\u0026ldquo;TFP\u0026rdquo;). It\u0026rsquo;s basically my attempt to translate Sigrid Keydana\u0026rsquo;s wonderful blog post from R to Python. I\u0026rsquo;m doing this for a couple of reasons: First, I\u0026rsquo;ve played with TFP before, was quite impressed by its performance and flexibility, and wanted to learn more about it; Second, I wanted to start blogging, and this seemed like an easy start; Last, TFP is rather new, and there aren\u0026rsquo;t a whole lot of resources and tutorials about it - so this might even prove useful to someone, someday.","tags":["TFP","Multilevel Models"],"title":"A Tutorial on Varying Intercepts Models with TensorFlow Probability","type":"post"}]