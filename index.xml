<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Adam Haber</title>
    <link>https://adamhaber.github.io/</link>
      <atom:link href="https://adamhaber.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Adam Haber</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 21 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://adamhaber.github.io/img/icon-192.png</url>
      <title>Adam Haber</title>
      <link>https://adamhaber.github.io/</link>
    </image>
    
    <item>
      <title>Introducing Stan2tfp - a lightweight interface for the Stan-to-TensorFlow Probability compiler</title>
      <link>https://adamhaber.github.io/post/stan2tfp-post1/</link>
      <pubDate>Thu, 21 May 2020 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/stan2tfp-post1/</guid>
      <description>&lt;h1 id=&#34;tldr&#34;&gt;TL;DR&lt;/h1&gt;
&lt;p&gt;The new &lt;a href=&#34;https://github.com/stan-dev/stanc3&#34;&gt;Stan compiler&lt;/a&gt; has an alternative backend that allows you to do this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;stan2tfp.jpg&#34; alt=&#34;pdf&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;stan2tfp&lt;/code&gt; is a lightwight interface for this compiler, that allows you to do this with one line of code, and fit the model to data with another.&lt;/p&gt;
&lt;h2 id=&#34;why-stan2tfp&#34;&gt;Why stan2tfp&lt;/h2&gt;
&lt;p&gt;In short - to get the convenience of Stan programs and the scalability of TensorFlow. The model is written in Stan, which means you get a lot of the benefits of having the Stan compiler behind your shoulder (types, bounds, etc). This comes practically for free, since there&amp;rsquo;s no C++ compilation. After the model is converted to TensorFlow Probability code, you sit on top of the entire TF infrastructure, which has many advantages. For example, moving from 4 chains to more than a thousand is &lt;a href=&#34;https://colindcarroll.com/2019/08/18/very-parallel-mcmc-sampling/&#34;&gt;practically free&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note that the TFP backend of the Stan compiler is still in its infancy. It only supports a subset of the &lt;a href=&#34;https://github.com/adamhaber/stan2tfp/blob/master/distributions.md&#34;&gt;distributions&lt;/a&gt; covered by Stan, and only minimal parts of the language. Expect bugs and sharp edges. Please help by trying it out, reporting bugs, and letting me know what you think!&lt;/p&gt;
&lt;h2 id=&#34;how-stan2tfp-works&#34;&gt;How stan2tfp works&lt;/h2&gt;
&lt;p&gt;stan2tfp is just a wrapper, it doesn&amp;rsquo;t do anything smart by itself; all the actual work is done by the compiler, which was written the Stan Development Team. The core functionality can be summarized as follows:&lt;/p&gt;
&lt;h3 id=&#34;code-generation&#34;&gt;Code generation&lt;/h3&gt;
&lt;p&gt;We first create a Stan2tfp Python object. It &amp;ldquo;eats&amp;rdquo; a Stan program (string/file), calls the compiler, &amp;ldquo;catches&amp;rdquo; the emitted TFP code (from stdout) and saves it as a Python string. In the process, it checks for the compiler - if it&amp;rsquo;s not found, stan2tfp will download it for you. This only needs to happen once.&lt;/p&gt;
&lt;h3 id=&#34;evaluation-by-the-interpreter&#34;&gt;Evaluation by the interpreter&lt;/h3&gt;
&lt;p&gt;The string that represents the model is then &lt;code&gt;eval&lt;/code&gt;ed by the Python interpreter. This creates a Python object in the current namespace. Note that the model is still not instantiated - we haven&amp;rsquo;t passed any data, so we can&amp;rsquo;t sample from the model. The &lt;code&gt;eval&lt;/code&gt; is packed within the constructor, and the compiler doesn&amp;rsquo;t emit any &amp;ldquo;hazardous code&amp;rdquo;, so using it is safe.&lt;/p&gt;
&lt;h3 id=&#34;instantiating-and-fitting-the-model&#34;&gt;Instantiating and fitting the model&lt;/h3&gt;
&lt;p&gt;To fit the model, we need to pass a data dictionary either to the &lt;code&gt;Stan2tfp&lt;/code&gt; constructor, or to the &lt;code&gt;init_model&lt;/code&gt; function. After the data is passed, we can call &lt;code&gt;sample&lt;/code&gt;, which wraps TFP&amp;rsquo;s MCMC machinery, aiming for sensible defaults and ease-of-use. At this point, we left Stan-world completely, and everything is TFP-ed - the model, the inference algorithm, etc.&lt;/p&gt;
&lt;h2 id=&#34;basic-example&#34;&gt;Basic example&lt;/h2&gt;
&lt;p&gt;To illustrate the basic functionallity, we&amp;rsquo;ll fit the eight schools model (the &amp;ldquo;hello world&amp;rdquo; of bayesian models) using stan2tfp.&lt;/p&gt;
&lt;p&gt;We begin by importing stan2tfp, and some plotting functionality:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; stan2tfp &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Stan2tfp
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; arviz &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; az
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here&amp;rsquo;s the original Stan model:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;data {
  int&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;lower&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; J;
  real y[J];
  real&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;lower&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; sigma[J];
}

parameters {
  real mu;
  real&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;lower&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; tau;
  vector[J] theta_tilde;
}

transformed parameters {
  vector[J] theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mu &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tau &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; theta_tilde;
}

model {
  mu &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;);
  tau &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;);
  theta_tilde &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
  y &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; normal(theta, sigma);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The data is specified using a Python dictionary:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;eight_schools_data_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dict(
    J&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,
    y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;18&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;],
    sigma&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;18&lt;/span&gt;]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, the model object itself is created:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Stan2tfp(
  stan_file_path&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eight_schools.stan&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
  data_dict&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;eight_schools_data_dict
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;Downloading the latest stan2tfp compiler...
Download complete, saved to: /Users/adamhaber/projects/stan2tfp/stan2tfp/stan2tfp_compiler.exe
Compiling stan file to tfp file...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The emitted TFP code is accessible via &lt;code&gt;get_tfp_code()&lt;/code&gt; (see the picture at the top of the post). This code is then &lt;code&gt;eval&lt;/code&gt;ed by the interpreter and creates the necessary &lt;em&gt;Python&lt;/em&gt; objects in the current namespace. We can now call &lt;code&gt;sample&lt;/code&gt; to fit the model:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;mcmc_trace, kernel_results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;model.sample&lt;/code&gt; returns the actual samples (&lt;code&gt;mcmc_trace&lt;/code&gt;) and TFP&amp;rsquo;s &lt;code&gt;kernel_results&lt;/code&gt; (holding important sampler diagnostics). Since we&amp;rsquo;re in TFP-world now, we can use any tool from the TFP ecosystem we like; specifically, we can use the excellent &lt;a href=&#34;https://arviz-devs.github.io&#34;&gt;Arviz&lt;/a&gt; library for plotting the results:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;data_for_az &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_tfp(posterior&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mcmc_trace, var_names&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;mu&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;trace&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;theta_tilde&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_forest(data_for_az)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_19_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s it. I&amp;rsquo;ll probably post some benchmarks and comparisons in the near future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mr. P meets TFP - mixed effects model with post-stratification in TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/mrp/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/mrp/</guid>
      <description>&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ll:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learn an interesting method for generalizing inferences from a biased sample to a population of interest&lt;/li&gt;
&lt;li&gt;See why prior predictive checks are great&lt;/li&gt;
&lt;li&gt;Implement a simple mixed-effects model in TFP&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;p&gt;This post is a TFP port of Lauren Kennedy and Jonah Gabry&amp;rsquo;s excellent &lt;a href=&#34;http://mc-stan.org/rstanarm/articles/mrp.html&#34;&gt;MRP with rstanarm&lt;/a&gt; vignette. It describes a very interesting statistical method for generalizing inferences from a biased sample to a population of interest. The method is called multilevel regression with poststratification, or MRP if you prefer acronyms, or Mister P if you prefer statisticians jokes. Along the way, we&amp;rsquo;ll see why prior predictive checks are so nice and important, how to implement a mixed-effect model in TFP, and how to make predictions for smaller sub-populations.&lt;/p&gt;
&lt;p&gt;I chose to port the vignette because the problem MRP address - generalizing from a biased sample to a population - is so prevalent and important, that knowing what are the possible tools to handle it seemed valuable. I found that porting models from one language to another is an excellent way to learn the model, the problem, and the languages themselves, so it&amp;rsquo;s kind of a win-win-win and publishing it might also help others so why not.&lt;/p&gt;
&lt;p&gt;I strongly recommend reading the original vignette; the people who wrote it are much more knowledgeable than I am about this subject, and I also chose to focus on slightly different things so they&amp;rsquo;re not 100% overlapping. At the end of this post you can find links for further reading.&lt;/p&gt;
&lt;h3 id=&#34;imports-and-helper-functions---data-generation&#34;&gt;Imports and helper functions - data generation&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; collections &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; namedtuple
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; itertools &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; it
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.special &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; expit &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; inv_logit
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sem
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;98&lt;/span&gt;)

sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_palette(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;muted&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;legend.fontsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;figure.figsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: (&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;),
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;axes.labelsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;axes.titlesize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;xtick.labelsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ytick.labelsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;
}
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rcParams&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;update(params)
&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;config InlineBackend&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure_format &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;retina&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;the-data&#34;&gt;The data&lt;/h1&gt;
&lt;p&gt;The data we&amp;rsquo;ll work with is simulated data; this has the obvious advantage that we know the ground truth so we&amp;rsquo;ll be able to assess just how well our method generalizes to the population. The data describes the proportion of the population who would choose to adopt a cat over a dog, given the opportunity. Our outcome variable in this example is binary (cat/dog), but MRP is not restricted to such outcomes and can be used for discrete outcomes with more than two values, as well as continuous outcomes.&lt;/p&gt;
&lt;p&gt;These are the variables we&amp;rsquo;ll be working with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;)
income &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;They&amp;rsquo;re all categorical; we use zero-based indexing to enumerate them (instead of calling them &amp;lsquo;Male&amp;rsquo;, &amp;lsquo;Female&amp;rsquo; etc) because it&amp;rsquo;ll make all the indexing gymnastics in the actual implementation somewhat simpler.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;poststrat&lt;/code&gt; is a dataframe containing all $2\times3\times7\times3\times50=6300$ possible combinations of these variables:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;poststrat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    list(it&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;product(sex, eth, age, income, state)),
    columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;],
)
poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4675&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1749&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2460&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(6300, 5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below are the different proportions of the different variables &lt;em&gt;in the population&lt;/em&gt;. For example, 20% of the population are in the first age group, 10% are in the second, etc. For each combination of variables we&amp;rsquo;ll compute the number of people that share this specific combination by multiplying the total number of people in the population (assumed to be 250 million) with the different probabilities (this means we&amp;rsquo;re assuming the joint probability distribution factorizes, that is - that the different variables are independent).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;p_age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;])
p_sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.52&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.48&lt;/span&gt;])
p_eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;])
p_income &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.50&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.35&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.15&lt;/span&gt;])
p_state_tmp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(low&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, high&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)
p_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(p_state_tmp &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; p_state_tmp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum())

poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    &lt;span style=&#34;color:#ae81ff&#34;&gt;250e6&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_sex[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_eth[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_age[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_income[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_state[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We also assume that different groups have different probabilities of being included in the sample; in a way, that&amp;rsquo;s the entire point (if all groups had the same probability of being included in the sample then the sample was representative of the population). There&amp;rsquo;s a baseline probability of being in the sample, but it cancels out in the weighted average; what determines who is in our sample is &lt;code&gt;p_response_weighted&lt;/code&gt;, which is &lt;code&gt;p_response&lt;/code&gt; weighted by the number of people in each group:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;p_response_baseline &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;
p_response_sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2.8&lt;/span&gt;
p_response_eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4.7&lt;/span&gt; 
p_response_age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;18.9&lt;/span&gt;
p_response_inc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2.7&lt;/span&gt;
p_response_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;beta(a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, b&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)
p_response_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p_response_state &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; p_response_state&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()

p_response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    p_response_baseline
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_sex[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_eth[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_age[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_inc[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response_state[poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
)

p_response_weighted &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p_response)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We now sample 1200 individuals from the entire population. This means we&amp;rsquo;re actually sampling rows from our &lt;code&gt;poststrat&lt;/code&gt; dataframe with different probabilities given by &lt;code&gt;p_response_weighted&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1200&lt;/span&gt;
people &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]), size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n, replace&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;p_response_weighted
)
sample &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[people]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()
sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;index&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;520&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;287&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2626&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;870&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;69&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1517&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;169&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4104&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now we&amp;rsquo;re getting to the thing we&amp;rsquo;ll actually measure in the sample (and then try to generalize to the population) - cat preference. Below are the coefficients of a regression model that determines the log-odds of cat preference, $\log\frac{P(\text{prefers cats})}{P(\text{prefers dogs})}$ for each group in the population. We&amp;rsquo;ll use these coefficients to compute the actual probability of cats preference for each group:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;coef_sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;])
coef_eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;])
coef_age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;])
coef_income &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;])
coef_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;insert(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
coef_age_sex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vstack(
    [
        np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.23&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.43&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;]),
        np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.23&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.43&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;]),
    ]
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;true_pop &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inv_logit(
    coef_sex[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_eth[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_age[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_income[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_state[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coef_age_sex[true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]
)
true_pop&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cat_pref&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;6124&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.71095&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;177&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.549834&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;5755&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.331812&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2102&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.802184&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3931&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.524979&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We now use the computed probabilities to determine, for each individual in our sample, whether she&amp;rsquo;s a cats person or a dogs person. Note that this is still the fake data generation part; we&amp;rsquo;re not modelling anything yet.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;binomial(n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;][people], size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n)
sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;index&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;eth&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;income&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cat_pref&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;671&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;906&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3062&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Just to get a glimpse of the problem Mr. P is trying to solve, the sample mean is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0.7083333333333334
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While the true mean in the population (which is a weighted sum of the per-group probabilities and the group sizes) is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;true_pop_pref &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sum(true_pop[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; sum(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;])
true_pop_pref
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;0.5941253009200917
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So our sample overestimates cats-lovin&amp;rsquo; in the population by 18% - people who like cats also like taking surveys.&lt;/p&gt;
&lt;h2 id=&#34;visualizations&#34;&gt;Visualizations&lt;/h2&gt;
&lt;p&gt;To get a better understanding of the problem (unrepresentativeness of the sample), we&amp;rsquo;ll plot some summary statistics and see how they differ:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;f, ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;))

pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    dict(pop&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Series(p_age), sample&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;age&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_index() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; n))
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    dict(pop&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Series(p_eth), sample&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eth&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_index() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; n))
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], legend&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ethnicity&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    dict(
        pop&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Series(p_income), sample&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;income&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_index() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; n)
    )
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], legend&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    dict(pop&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Series(p_sex), sample&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sex&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;value_counts()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_index() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; n))
)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], legend&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_33_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;At least by eyeballing the charts, the differences seem substantial; for example, if there&amp;rsquo;s a big difference in cats preference between males and females, we expect to see a substantial difference between the cats preference in the sample and in the population.&lt;/p&gt;
&lt;p&gt;We can also plot how cats preference changes between different groups &lt;em&gt;within&lt;/em&gt; our sample - for example, is there a difference in cats preference between different age groups? (yes there is)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;f, axes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), sharey&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; key, ax &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip([&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], axes):
    sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(key)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;agg(dict(mean&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean, std&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sem))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(
        kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;bar&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;key, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, yerr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;std&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax, legend&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False
    )
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_36_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;the-model&#34;&gt;The model&lt;/h1&gt;
&lt;p&gt;We now turn to the MR part of MRP - the multilevel regression part. More specifically, we&amp;rsquo;ll build a Bayesian multilevel logistic regression model of cats preference. Even more specifically, we&amp;rsquo;ll build what&amp;rsquo;s called a &amp;ldquo;mixed
effects&amp;rdquo; model. Mixed effects models are one of those places that, at least for me, the statisticians terminology is &lt;em&gt;extremely&lt;/em&gt; confusing; it also seems to be inconsistent between different academic fields.  I usually find it easier to look at the actual model specification to understand what&amp;rsquo;s going on:&lt;/p&gt;
&lt;p&gt;For each group $j\in\left[1,&amp;hellip;,6300\right]$ we model the probability of cats preference as&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\theta_j &amp;amp; = logit^{-1}(
\alpha +
X_{j}\beta&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\alpha_{\rm state[j]}^{\rm state}&lt;/li&gt;
&lt;li&gt;\alpha_{\rm age[j]}^{\rm age}&lt;/li&gt;
&lt;li&gt;\alpha_{\rm eth[j]}^{\rm eth}&lt;/li&gt;
&lt;li&gt;\alpha_{\rm inc[j]}^{\rm inc}
) \\\&lt;br&gt;
\alpha_{\rm state[j]}^{\rm state} &amp;amp; \sim N(0,\sigma^{\rm state}) \\\&lt;br&gt;
\alpha_{\rm age[j]}^{\rm age} &amp;amp; \sim N(0,\sigma^{\rm age})\\\&lt;br&gt;
\alpha_{\rm eth[j]}^{\rm eth} &amp;amp; \sim N(0,\sigma^{\rm eth})\\\&lt;br&gt;
\alpha_{\rm inc[j]}^{\rm inc} &amp;amp;\sim N(0,\sigma^{\rm inc}) \\\&lt;br&gt;
\sigma^{\rm state} &amp;amp; \sim {\rm HalfNormal}(1) \\\&lt;br&gt;
\sigma^{\rm age} &amp;amp; \sim {\rm HalfNormal}(1) \\\&lt;br&gt;
\sigma^{\rm eth} &amp;amp; \sim {\rm HalfNormal}(1) \\\&lt;br&gt;
\sigma^{\rm income} &amp;amp; \sim {\rm HalfNormal}(1) \\\&lt;br&gt;
\beta &amp;amp; \sim N(0,2.5) \\\&lt;br&gt;
\alpha &amp;amp; \sim N(0,10) \\\&lt;br&gt;
\end{align}
$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We&amp;rsquo;ve seen expressions like $\alpha_{\rm state[j]}^{\rm state}$ when we&amp;rsquo;ve implemented &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34;&gt;varying intercepts models&lt;/a&gt;. What makes this a &amp;ldquo;mixed effects&amp;rdquo; models is that $\beta$ is the same $\beta$ for all groups, while the different $\alpha^*$-s vary between groups. I&amp;rsquo;m sure there are subtleties and nuances that this doesn&amp;rsquo;t capture, but for me this is a simple-to-read, simple-to-implement explanation of mixed effects models.&lt;/p&gt;
&lt;p&gt;As for the model itself:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$X$ is a (binary) design matrix that holds indicators for sex, age and sex-age interactions - we&amp;rsquo;ll construct it in a second.&lt;/li&gt;
&lt;li&gt;$\alpha$ is an intercept term.&lt;/li&gt;
&lt;li&gt;$\beta$ is a coefficient vector.&lt;/li&gt;
&lt;li&gt;The different $\alpha^*$-s are per-group varying intercepts.&lt;/li&gt;
&lt;li&gt;The different $\sigma^*$-s are hyperpriors for variation between groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The priors on $\alpha,\beta$ are rstanarm&amp;rsquo;s default priors; I couldn&amp;rsquo;t find rstanarm&amp;rsquo;s default prior on the $\sigma^*$ so I chose to use a halfnormal(1) prior.&lt;/p&gt;
&lt;p&gt;Our design matrix $X$ will represent a one-hot-encoded representation of the sampled individuals sex, age, and sex-age interaction term. Here&amp;rsquo;s how it looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;factors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_dummies(sample[[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;category&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(
    [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
)
interactions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    factors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; factors[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values[:, None],
    columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1*age_{i+1}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)],
)
features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([factors, interactions], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age_6&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sex_1*age_6&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(1200, 13)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make TF shape issues simpler, we convert it to a numpy array and transpose it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;imports-and-helper-functions---inference&#34;&gt;Imports and helper functions - inference&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfp
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; distributions &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; bijectors &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfb
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; arviz &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; az
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
dtype &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step_size_setter_fn&lt;/span&gt;(pkr, new_step_size):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_replace(
        inner_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_replace(step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;new_step_size)
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;factors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_dummies(sample[[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;category&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(
    [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
)
interactions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    factors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; factors[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values[:, None],
    columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1*age_{i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)],
)
features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([factors, interactions], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trace_fn&lt;/span&gt;(current_samp, pkr):

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;target_log_prob,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;leapfrogs_taken,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;has_divergence,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;energy,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_accept_ratio,
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;(experimental_compile&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;run_nuts&lt;/span&gt;(target_log_prob_fn, initial_states, bijectors_list):
    step_sizes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones_like(i) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; initial_states]
    kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TransformedTransitionKernel(
        tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nuts&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;NoUTurnSampler(target_log_prob_fn, step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;step_sizes),
        bijector&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bijectors_list,
    )

    kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DualAveragingStepSizeAdaptation(
        kernel,
        target_accept_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;dtype),
        num_adaptation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;800&lt;/span&gt;,
        step_size_setter_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;step_size_setter_fn,
        step_size_getter_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; pkr: pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step_size,
        log_accept_prob_getter_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; pkr: pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_accept_ratio,
    )

    &lt;span style=&#34;color:#75715e&#34;&gt;# Sampling from the chain.&lt;/span&gt;
    mcmc_trace, pkr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_chain(
        num_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;,
        num_burnin_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;,
        current_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[
            bijector&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(state)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; bijector, state &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(bijectors_list, initial_states)
        ],
        kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kernel,
        trace_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;trace_fn,
    )

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; mcmc_trace, pkr
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# using pymc3 naming conventions, with log_likelihood instead of lp so that ArviZ can compute loo and waic&lt;/span&gt;
sample_stats_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;log_likelihood&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;tree_size&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;diverging&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;energy&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;mean_tree_accept&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
]


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tfp_trace_to_arviz&lt;/span&gt;(tfp_trace, var_names&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, sample_stats_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sample_stats_name):

    samps, trace &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp_trace
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; var_names &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; None:
        var_names &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;var &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(x) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(samps))]

    sample_stats &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {k: v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k, v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(sample_stats_name, trace)}
    posterior &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
        name: tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(samp, [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name, samp &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(var_names, samps)
    }
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_dict(posterior&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;posterior, sample_stats&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sample_stats)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more details about calling TFP&amp;rsquo;s NUTS sampler, and the helper functions defined above, see &lt;a href=&#34;https://adamhaber.github.io/2019/10/21/Bayesian-golf-puttings,-NUTS,-and-optimizing-your-sampling-function-with-TensorFlow-Probability.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;first-implemetation&#34;&gt;First implemetation&lt;/h2&gt;
&lt;p&gt;We now turn to implement the whole model in TFP. Since there aren&amp;rsquo;t many complicated intermediate calculations, a &lt;code&gt;JointDistributionSequential&lt;/code&gt; is a reasonable choice for implementing the model. For a more detailed explanation on the different &lt;code&gt;JointDistribution&lt;/code&gt; alternatives, see &lt;a href=&#34;https://adamhaber.github.io/2019/10/21/Bayesian-golf-puttings,-NUTS,-and-optimizing-your-sampling-function-with-TensorFlow-Probability.html#model-1&#34;&gt;this post&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_state&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_state: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_state), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_eth&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_eth: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_eth), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_income&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_income: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_income), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_age&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_age: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_age), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# intercept&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# coeffs&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; coeffs, intercept, coef_age, sigma_age, coef_income, sigma_income, coef_eth, sigma_eth, coef_state: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(
            tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Binomial(
                total_count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
                logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;intercept[:, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_age, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                ),
            ),
            reinterpreted_batch_ndims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        ),
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The model description isn&amp;rsquo;t short, but it doesn&amp;rsquo;t contain anything we haven&amp;rsquo;t covered in previous posts. Let&amp;rsquo;s call &lt;code&gt;.sample&lt;/code&gt; and &lt;code&gt;.log_prob&lt;/code&gt; just to make sure everything works:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;[s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[TensorShape([4]),
 TensorShape([4, 50]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 7]),
 TensorShape([4]),
 TensorShape([4, 13]),
 TensorShape([4, 1200])]
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-121.06135 ,   21.950146,  -69.38415 , -224.08742 ], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So our model technically works&amp;hellip; but does it makes sense?&lt;/p&gt;
&lt;h2 id=&#34;prior-predictive-checks&#34;&gt;Prior predictive checks&lt;/h2&gt;
&lt;p&gt;Prior predictive checks are an extremely valuable technique to assess your model and your priors, before seeing any data. To learn more about PPCs (horrible acronym as the first P can also stand for &lt;em&gt;posterior&lt;/em&gt;), I highly recommend Michael Betancourt&amp;rsquo;s &lt;a href=&#34;https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html&#34;&gt;principled bayesian workflow&lt;/a&gt; case study.&lt;/p&gt;
&lt;p&gt;Anyway, let&amp;rsquo;s generate samples from our model, and use the samples to compute the logits (the linear expression within the &lt;code&gt;inv_logit&lt;/code&gt; function):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inits[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;][
    ::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    intercept[:, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_age, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Each chain gives us 1200 different numbers - the log-odds for cat preference for our 1200 sampled individuals. Let&amp;rsquo;s plot these four histograms:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, l &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(logits):
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(l, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;from chain {i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;rm logit}&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;left(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;theta_j&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;right)$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
lim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlim();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_67_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note that it&amp;rsquo;s OK that each color (each chain) is multimodal - this just means that we&amp;rsquo;re inferring different &amp;ldquo;types&amp;rdquo; of cats preference across groups.&lt;/p&gt;
&lt;p&gt;The problem with what we got is the &lt;em&gt;scale&lt;/em&gt; - having ${\rm logit}\left(\theta_j\right)=-15$ means $\theta_j=0.000000003&amp;hellip;$ which doesn&amp;rsquo;t really makes sense, even for a group that &lt;em&gt;really&lt;/em&gt; likes dogs. This implies that our priors are way too diffuse, the normal(0,10) being the primary suspect. So let&amp;rsquo;s make everything normal(0,1) and do this again:&lt;/p&gt;
&lt;h1 id=&#34;same-likelihood-better-priors&#34;&gt;Same likelihood, better priors&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_state&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_state: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_state), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_eth&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_eth: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_eth), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_income&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_income: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_income), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_age&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma_age: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, sigma_age), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# intercept&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# coeffs&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; coeffs, intercept, coef_age, a, coef_income, b, coef_eth, c, coef_state: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(
            tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Binomial(
                total_count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
                logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;intercept[:, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_age, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                )
                &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(
                    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                ),
            ),
            reinterpreted_batch_ndims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        ),
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;coeffs, intercept, coef_age, _, coef_income, _, coef_eth, _, coef_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inits[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;][
    ::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    intercept[:, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_age, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, l &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(logits):
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(l, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;from chain {i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;rm logit}&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;left(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;theta_j&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;right)$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlim(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;lim);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_74_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This makes much more sense. The variance between groups is still there but it doesn&amp;rsquo;t spread across several order of magnitude (that is, with this prior it&amp;rsquo;s no longer plausible that some groups love cats 10 million times more than other groups). This seems like a good starting point.&lt;/p&gt;
&lt;p&gt;Note that the overly wide priors are also very problematic, inference wise - running the same notebook with the first model returns all sorts of sampling problems (divergent transitions, bad mixing, random seed dependence etc) while the 2nd, more informed version does not.&lt;/p&gt;
&lt;h2 id=&#34;getting-the-shapes-right&#34;&gt;Getting the shapes right&lt;/h2&gt;
&lt;p&gt;This is, by far, the hardest thing for me when building a probablistic model with TFP. Knowing where to put &lt;code&gt;[...,],  tf.newaxis&lt;/code&gt; or &lt;code&gt;[None,]&lt;/code&gt; requires some trial and error - here are some checks to verify we got this right (after &lt;em&gt;a lot&lt;/em&gt; of failed attempts and some help from Junpeng Lao):&lt;/p&gt;
&lt;p&gt;First, we want to make sure the model can evaluate the log probability of its own samples, and that we get &lt;code&gt;n_chains&lt;/code&gt; different numbers:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(inits)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-619.5229 , -520.8101 , -460.97076, -609.21765], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, we want to make sure that all shapes of the different parameters in our samples are as we expect, which basically should be the number of chains in the first axis and the shape of whatever it is we&amp;rsquo;re sampling in the rest - or nothing, if it&amp;rsquo;s just a scalar:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;[s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; inits]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[TensorShape([4]),
 TensorShape([4, 50]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 3]),
 TensorShape([4]),
 TensorShape([4, 7]),
 TensorShape([4]),
 TensorShape([4, 13]),
 TensorShape([4, 1200])]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main thing to look out for here are redundant extra dimensions (for example, &lt;code&gt;TensorShape([4, 1])&lt;/code&gt; instead of &lt;code&gt;TensorShape([4])&lt;/code&gt; - these will almost always cause broadcasting issues.&lt;/p&gt;
&lt;p&gt;Next, we want to add an extra axis for the data we condition on. Again, this is for broadcasting purposes - we want to make sure &lt;code&gt;tf&lt;/code&gt; &amp;ldquo;replicates&amp;rdquo; the data across different chains.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis, &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;TensorShape([1, 1200])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, the &lt;code&gt;log_prob&lt;/code&gt; function closure - we want to make sure our &lt;code&gt;log_prob&lt;/code&gt; function gets as inputs all the different parameters, concatenates them with the data we&amp;rsquo;re conditioning on, and then uses the original model &lt;code&gt;log_prob&lt;/code&gt; function to evaluate; practically, we want to verify that if we pass all the parameters (&lt;em&gt;without&lt;/em&gt; the conditioning data), we get &lt;code&gt;n_chains&lt;/code&gt; different numbers:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;lp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;x: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(
    list(x) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis, &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;]]
)
lp(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;inits[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1315.5156, -1436.2715, -1799.2578, -1901.1874], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;inference&#34;&gt;Inference&lt;/h2&gt;
&lt;p&gt;With sensible priors and TFP shape issues dealt with, we can proceed with actually runnning the sampler.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32, name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;initializer&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; inits
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace, kr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts(
    lp,
    inits[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],
    bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
        tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
    ],
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Always&lt;/em&gt; check your TF shapes:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;[s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; trace]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[TensorShape([1000, 4]),
 TensorShape([1000, 4, 50]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 3]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 3]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 7]),
 TensorShape([1000, 4]),
 TensorShape([1000, 4, 13])]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This looks good; for arviz intergration purposes, we&amp;rsquo;ll add an extra axis for the parameters whose tensor shape is &lt;code&gt;TensorShape([1000, 4])&lt;/code&gt;, and then call our &lt;code&gt;tfp_trace_to_arviz&lt;/code&gt; helper function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace_ex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [s[&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis] &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; s &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; trace]
az_trace &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp_trace_to_arviz((trace_ex, kr))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary(az_trace)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hpd_3%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hpd_97%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mcse_mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mcse_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_bulk&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ess_tail&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r_hat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 0[0]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.056&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.153&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.779&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.338&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1771&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1806&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2668&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[0]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.016&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.607&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.173&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.155&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.011&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.009&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2822&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2235&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2843&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2538&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[1]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.025&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.505&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.997&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.927&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3978&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4013&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2918&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[2]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.477&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.463&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.362&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.38&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.007&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4207&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2794&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4232&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2521&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;var 1[3]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.764&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.896&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.017&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.013&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2102&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1745&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2132&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1908&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Sampling diagnostics look good; we have no divergent transitions, and $\hat{R}$ values are all close to 1:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary(az_trace)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r_hat&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;count    81.0
mean      1.0
std       0.0
min       1.0
25%       1.0
50%       1.0
75%       1.0
max       1.0
Name: r_hat, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We won&amp;rsquo;t go down the model-diagnostics-rabbit-hole now; we&amp;rsquo;re here to learn about Mister P.&lt;/p&gt;
&lt;h2 id=&#34;p-part&#34;&gt;P part&lt;/h2&gt;
&lt;p&gt;So far we&amp;rsquo;ve defined, critisized and fitted a multilevel logisitic regression model. Now comes the poststratification part. Poststratification is a technical and intimidating word; it basically means &amp;ldquo;adjusting the inferences from my sample to the population by using additional knowledge about proportions in the population&amp;rdquo;. To do so, we&amp;rsquo;ll:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Compute a design matrix $X$ for the population.&lt;/li&gt;
&lt;li&gt;Use our 4000 sampled parameters to compute 4000 different logits for each group in the population. This will yield a 4000x6300 matrix.&lt;/li&gt;
&lt;li&gt;For each row (representing a single draw from our posterior), we&amp;rsquo;ll compute the population mean as a weighted sum of per-group cat preference and group&amp;rsquo;s size. This will give us a vector of 4000 numbers.&lt;/li&gt;
&lt;li&gt;The mean of these 4000 numbers will be our estimate for the population mean.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;post_factors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_dummies(poststrat[[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;category&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(
    [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age_0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
)
post_interactions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(
    post_factors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; post_factors[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values[:, None],
    columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sex_1*age_{i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)],
)
post_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([post_factors, post_interactions], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;intercept &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;]
coeffs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;]
coef_age &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;]
coef_income &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
coef_eth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
coef_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]

logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
    intercept[&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(post_features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_income, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_eth, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(coef_state, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
)
posterior_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inv_logit(logits)
posterior_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posterior_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6300&lt;/span&gt;)
posterior_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(4000, 6300)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;poststrat_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posterior_prob &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;][:, None] &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
poststrat_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(4000, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So how good is MRP? We plot the histogram of our 4000 different estimates of the population mean, together with the estimate from the sample (dashed line) and the true mean:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(poststrat_prob, bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(true_pop_pref, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;population mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(sample[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sample mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_106_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can see that the posterior mean is much closer to the true mean - so MRP definitely helps!&lt;/p&gt;
&lt;h1 id=&#34;estimates-for-states&#34;&gt;Estimates for states&lt;/h1&gt;
&lt;p&gt;The nice thing about having a model is that we can use it to answer all sorts of different questions. For example, we can repeat the analysis we just did and estimate per-state means. We&amp;rsquo;re still computing the design matrix, logits etc as before but we&amp;rsquo;re constraining ourselves to one state at a time. For each state, we&amp;rsquo;ll compute the model&amp;rsquo;s mean and standard deviations, together with the true mean and the sample mean:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;state_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; namedtuple(
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state_data&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    [
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_sd&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sample_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;true_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    ],
)
states_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;):
    state_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(post_features[:, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;state &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; i)])
    state_poststrat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
    logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
        intercept[&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; coeffs &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_features, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(
            trace[&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;],
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;age&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32),
            axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        )
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(
            coef_income,
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;income&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32),
            axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        )
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(
            coef_eth,
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eth&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32),
            axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        )
        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(
            coef_state,
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32),
            axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
        )
    )
    posterior_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inv_logit(logits)
    posterior_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posterior_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, state_features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    state_poststrat_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
        posterior_prob
        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; state_poststrat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;][:, None]
        &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; state_poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
    )
    states_data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(
        state_data(
            i,
            state_poststrat_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std(),
            state_poststrat_prob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(),
            sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(),
            np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(true_pop&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;cat_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; state_poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;])
            &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(state_poststrat[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]),
            sample&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(f&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;state=={i}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
        )
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;state_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(states_data)
state_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;state&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;model_state_sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;model_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sample_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;true_state_pref&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;N&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.116844&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.580393&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.596565&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0956771&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.583293&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.658961&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0817888&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.669766&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.823529&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.69817&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.145332&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.505946&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.553341&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0768275&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.493726&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.611111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.443913&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Graphically, this is how this looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;f, ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))
state_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(
    x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;true_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    yerr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_sd&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax,
    kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;scatter&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Model&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
)
state_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(
    x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;true_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sample_state_pref&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax,
    kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;scatter&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;C1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
    label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Sample&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,
)
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Cat preference&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_113_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can see that the model predictions of state-wise preferences (blue dots) are closer to the identity line compared to the orange dots (sample per-state mean preferences).&lt;/p&gt;
&lt;p&gt;Another interesting thing to see is how the model uncertainty (quantified by the standard deviation of the model predictions, per state) is related to sample size; we can see that the model is more confident (lower std) for states with higher N, which is what we would expect:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(state_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;N&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], state_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model_state_sd&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_116_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;summary-and-further-reading&#34;&gt;Summary and further reading&lt;/h1&gt;
&lt;p&gt;This post was a code-oriented introduction to MRP, which is a very interesting technique that nicely leverages the built in advantages of multilevel models. We&amp;rsquo;ve also seen how taking a package&amp;rsquo;s priors for granted is not always a good idea, and how prior predictive checks can help us calibrate our priors and our beliefs.&lt;/p&gt;
&lt;p&gt;In case you want to learn more, other than Lauren and Jonah&amp;rsquo;s vignette, these are all excellent reads:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Austin Rochford&amp;rsquo;s &lt;a href=&#34;https://austinrochford.com/posts/2017-07-09-mrpymc3.html&#34;&gt;MRPyMC3&lt;/a&gt; tutorial&lt;/li&gt;
&lt;li&gt;Andrew Gelman&amp;rsquo;s post about Mister P&amp;rsquo;s &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2013/10/09/mister-p-whats-its-secret-sauce/&#34;&gt;secret sauce&lt;/a&gt;. Somewhat more technical and perhaps more political-science specific, but still interesting and relevant.&lt;/li&gt;
&lt;li&gt;Dan Simpson&amp;rsquo;s post on &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2019/08/22/multilevel-structured-regression-and-post-stratification/&#34;&gt;structured priors&lt;/a&gt; for MRP; this is somewhat more advanced, but Dan&amp;rsquo;s posts are always fun to read.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian golf puttings, NUTS, and optimizing your sampling function with TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/nuts/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/nuts/</guid>
      <description>&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ll:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Port a great Bayesian modelling tutorial from Stan to TFP&lt;/li&gt;
&lt;li&gt;Discuss how to speed up our sampling function&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;trace_fn&lt;/code&gt; to produce Stan-like &lt;code&gt;generated quantities&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Explore the results using the ArviZ library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;p&gt;This is a TFP-port one of of the best Bayesian modelling tutorials I&amp;rsquo;ve seen online - the &lt;a href=&#34;https://mc-stan.org/users/documentation/case-studies/golf.html&#34;&gt;Model building and expansion for golf putting&lt;/a&gt; Stan tutorial. It&amp;rsquo;s a beautiful example of modeling from first principles, and why the incorporation of domain knowledge into a statistical model - in this case, knowing a little bit about golf and some high-school physics - is so important. Since there&amp;rsquo;s no chance I&amp;rsquo;ll explain the subject nearly as well as Gelman, go read his tutorial and come back if you want to learn how to do this with TFP. :-)&lt;/p&gt;
&lt;p&gt;Other than the actual TFP code for the different models, this post will also shortly discuss the new NUTS kernel, various optimizations techniques to make sampling (much) faster, how to use &lt;code&gt;trace_fn&lt;/code&gt; to produce Stan-style generated quantities, and the ArviZ plotting library for inspecting sampler traces and statistics. I&amp;rsquo;m not an expert on any of these topics - I&amp;rsquo;ll share what I&amp;rsquo;ve learned while trying to implement these models, and provide links for further reading.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re more into basketball than golf, you might be interested in &lt;a href=&#34;https://jamesblandecon.github.io/NBAJumpShotsIndividual.html&#34;&gt;this&lt;/a&gt; case-study; it&amp;rsquo;s based on the golf tutorial, but analyzes NBA jump shots instead.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# the necessary imports&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow.compat.v2 &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfp

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt 
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; time &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; distributions &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; bijectors &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfb
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; functools &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; partial

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; arviz &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; az  &lt;span style=&#34;color:#75715e&#34;&gt;#we&amp;#39;ll get to that&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_palette(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;muted&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;1324&lt;/span&gt;)
dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32
params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;legend.fontsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;figure.figsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: (&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;),
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;axes.labelsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;axes.titlesize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;xtick.labelsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ytick.labelsize&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x-large&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;
}
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rcParams&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;update(params)
&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;config InlineBackend&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure_format &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;retina&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;arviz&#34;&gt;ArviZ&lt;/h1&gt;
&lt;p&gt;In the previous posts we&amp;rsquo;ve been using &lt;a href=&#34;https://seaborn.pydata.org&#34;&gt;seaborn&lt;/a&gt; for plotting. Seaborn is an amazing plotting library with good defaults and well-designed API, but it was not built with MCMC simulations in mind. &lt;a href=&#34;https://arviz-devs.github.io/arviz/&#34;&gt;ArviZ&lt;/a&gt; was. ArviZ allows for &amp;ldquo;Exploratory analysis of Bayesian models&amp;rdquo;, and interfaces with many bayesian modeling libraries such as PyStan, PyMC3, Pyro, emcee and TFP. ArviZ prints nice dataframes with summary statistics, supports model comparison using LOO and WAIC (similar to the &lt;a href=&#34;https://cran.r-project.org/web/packages/loo/loo.pdf&#34;&gt;loo&lt;/a&gt; package in R), and a wide variety of diagnosis tools; it&amp;rsquo;s the most comprehensive Python package for this sort of analysis I&amp;rsquo;ve seen, and it&amp;rsquo;s maintained by top PyMC3 contributors.&lt;/p&gt;
&lt;p&gt;The only drawback for using ArviZ with TFP at the moment is that the &lt;code&gt;from_tfp&lt;/code&gt; function has troubles with multi-chain traces (which are pretty much the norm); I adjusted a code snippet from &lt;a href=&#34;https://colab.research.google.com/gist/junpenglao/51cd25c6372f8d2ab3490d4af8f97401/tfp_nuts_demo.ipynb&#34;&gt;this&lt;/a&gt; notebook and wrote a small helper function to handle this. The &lt;code&gt;tfp_trace_to_arviz&lt;/code&gt; function gets a &lt;code&gt;StatesAndTrace&lt;/code&gt; object, which is a container with two elements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a list of samples tensors (the actual output of the sampler).&lt;/li&gt;
&lt;li&gt;a list of trace statistics.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;hellip; and returns an ArviZ &lt;code&gt;InferenceData&lt;/code&gt; object. There is a wide range of statistics we can extract from our sampler, which are important for sampling diagnosis. This is the actual function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# using pymc3 naming conventions, with log_likelihood instead of lp so that ArviZ can compute loo and waic&lt;/span&gt;
sample_stats_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;log_likelihood&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;tree_size&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;diverging&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;energy&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;mean_tree_accept&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tfp_trace_to_arviz&lt;/span&gt;(
    tfp_trace,
    var_names&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, 
    sample_stats_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sample_stats_name):
    
    samps, trace &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp_trace
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; var_names &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; None:
        var_names &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;var &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(x) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(samps))]
        
    sample_stats &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {k:v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k, v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(sample_stats_name, trace)}
    posterior &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {name : tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(samp, [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy() &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name, samp &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(var_names, samps)}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_dict(posterior&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;posterior, sample_stats&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sample_stats)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The only tricky thing here is the &lt;code&gt;tf.transpose&lt;/code&gt; operation - we&amp;rsquo;re making sure the chain dimension is the first axis, to be consistent with ArviZ conventions (see &lt;a href=&#34;https://github.com/arviz-devs/arviz/blob/24f8268844cf3cc5cf10d152e955c3122ec477c0/arviz/data/base.py#L103&#34;&gt;&lt;code&gt;az.data.numpy_to_data_array&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;h1 id=&#34;nuts&#34;&gt;NUTS&lt;/h1&gt;
&lt;p&gt;Previous posts have used the Hamiltonian Monte Carlo sampler to sample from our posterior distributions. When I tried to use HMC to sample from the models described below (specifically, from the 3rd and 4th models) I&amp;rsquo;ve had troubles reproducing the results from the Stan tutorial. I&amp;rsquo;ve posted a question on the TFP google group (super responsive and helpful), and Junpeng Lao (PyMC3 core developer, now working on TFP) recommended I&amp;rsquo;ll try the new NUTS kernel, instead. He said NUTS requires significantly less hand-tuning for complex models, compared to HMC; he was right.&lt;/p&gt;
&lt;p&gt;Since the posts so far were mostly code-oriented, we haven&amp;rsquo;t really gotten into the HMC algorithm, so we&amp;rsquo;re not going to get into why NUTS is an improvement; suffice to say it traverses the posterior distribution in a more efficient way, which is good for us (the simple people who don&amp;rsquo;t know how to hand-tune the number of leapfrog steps). We&amp;rsquo;ll see below another new addition to TFP that helps with another fine-tuning problem.&lt;/p&gt;
&lt;p&gt;For further reading, these are all excellent:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The original &lt;a href=&#34;http://jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf&#34;&gt;NUTS&lt;/a&gt; paper.&lt;/li&gt;
&lt;li&gt;Michael Betancourt&amp;rsquo;s &lt;a href=&#34;https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=2&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=2ahUKEwisvufdvJflAhWl5OAKHctkBaYQFjABegQIAhAB&amp;amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1701.02434&amp;amp;usg=AOvVaw0KCc_YNSmoxjpHQOaZP2IN&#34;&gt;A Conceptual Introduction to Hamiltonian Monte Carlo&lt;/a&gt; paper.&lt;/li&gt;
&lt;li&gt;For the more code-oriented reader - Colin Carroll&amp;rsquo;s excellent &lt;a href=&#34;https://colindcarroll.com/2019/04/11/hamiltonian-monte-carlo-from-scratch/&#34;&gt;series&lt;/a&gt; of posts on HMC, tuning, etc. Colin is one of the maintainers of both ArviZ and PyMC3.&lt;/li&gt;
&lt;li&gt;Sigrid Keydana&amp;rsquo;s &lt;a href=&#34;https://blogs.rstudio.com/tensorflow/posts/2019-10-03-intro-to-hmc/&#34;&gt;explanation&lt;/a&gt; is also excellent and less intimidating than the original articles.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;rsquo;ll now go over the code we&amp;rsquo;ll use to run the NUTS sampler. We&amp;rsquo;ll start with explaining &lt;code&gt;trace_fn&lt;/code&gt;, which is not NUTS specific but we&amp;rsquo;ll use it in our &lt;code&gt;run_nuts&lt;/code&gt; function; then we&amp;rsquo;ll cover the &lt;code&gt;run_nuts&lt;/code&gt; function itself.&lt;/p&gt;
&lt;h2 id=&#34;tracing-sampler-statistics&#34;&gt;Tracing sampler statistics&lt;/h2&gt;
&lt;p&gt;TFP allows us to collect various statistics of the sampling procedure, which can be important for diagnosing different kinds of problems with our model. To tell TFP which sampler statistics we actually care about, we need to pass &lt;code&gt;sample_chain&lt;/code&gt; a mysterious looking function called &lt;code&gt;trace_fn&lt;/code&gt;, which takes two arguments: &lt;code&gt;states&lt;/code&gt;, and &lt;code&gt;previous_kernel_results&lt;/code&gt; (or &lt;code&gt;pkr&lt;/code&gt;; took me a while understand what this stands for). In most examples (e.g., in &lt;code&gt;sample_chain&lt;/code&gt;&#39;s docs), the &lt;code&gt;states&lt;/code&gt; argument is discarded and some field(s) of the &lt;code&gt;pkr&lt;/code&gt; (which is a &lt;code&gt;collections.namedtuple&lt;/code&gt; object) are returned. To see what are the different kinds of statistics you can extract from &lt;code&gt;previous_kernel_results&lt;/code&gt; for the NUTS sampler, see &lt;a href=&#34;https://github.com/tensorflow/probability/blob/b959b26b7b3eee31711096d140b01cf58768e5e1/tensorflow_probability/python/mcmc/nuts.py#L73&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Following the same notebook linked above, we&amp;rsquo;re extracting the following statistics (most of this came from this PyMC3 &lt;a href=&#34;https://docs.pymc.io/notebooks/sampler-stats.html&#34;&gt;Sampler Statistics&lt;/a&gt; notebook):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;target_log_prob&lt;/code&gt; - log likelihood of the current state. If you&amp;rsquo;re interested in using ArviZ for model comparison, you need to extract this.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;leapfrogs_taken&lt;/code&gt; - NUTS generates a binary tree during sampling; this is the number of leafs in the tree per iteration. If the tree size is large, this can imply there are strong correlations in the posterior, high curvature &amp;ldquo;funnels&amp;rdquo;, and that &lt;a href=&#34;https://mc-stan.org/docs/2_18/stan-users-guide/reparameterization-section.html&#34;&gt;reparameterization&lt;/a&gt; of the model (for example, moving from a centered to non-centered representation) might be helpful.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;has_divergence&lt;/code&gt; - Whether the trajectory for this sample diverged. See Michael Betancourt&amp;rsquo;s excellent &lt;a href=&#34;https://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html&#34;&gt;post&lt;/a&gt; for what are divergences and how you can use them to detect problems with your model.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;energy&lt;/code&gt; - The energy at the point in phase-space where the sample was accepted. Can be used to identify posteriors with problematically long tails. See &lt;a href=&#34;https://discourse.pymc.io/t/about-nuts-sampling-and-energy-plot/831&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;log_accept_ratio&lt;/code&gt; - The mean acceptance probability for the tree that generated this sample. This can be compared to the desired target acceptance ratio for diagnosis.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trace_fn&lt;/span&gt;(_, pkr):  
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;target_log_prob,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;leapfrogs_taken,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;has_divergence,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;energy,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_accept_ratio
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;pkr.inner_results.inner_results&lt;/code&gt; part is due to the fact that we&amp;rsquo;re using a kernel-within-a-kernel-within-a-kernel - see below.&lt;/p&gt;
&lt;h2 id=&#34;calling-nuts&#34;&gt;Calling NUTS&lt;/h2&gt;
&lt;p&gt;The code for running the NUTS sampler is somewhat different than the &lt;code&gt;sampleHMC&lt;/code&gt; function we&amp;rsquo;ve used in the previous posts. Here&amp;rsquo;s a helper function for running NUTS that takes a tracing function, a log probability function, a list of initial values and an (optional) list of bijectors, and returns samples and sampler statistics.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;run_nuts_template&lt;/span&gt;(
    trace_fn,
    target_log_prob_fn,
    inits,
    bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, 
    num_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
    num_burnin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
    n_chains&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_chains):
    
    step_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(n_chains, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; isinstance(inits, list):
        inits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [inits]
        
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; None:
        bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity()]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;len(inits)

    kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DualAveragingStepSizeAdaptation(
        tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TransformedTransitionKernel(
            inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;NoUTurnSampler(
                target_log_prob_fn,
                step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[step_size]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;len(inits)
            ),
            bijector&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bijectors_list
        ),
        target_accept_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,
        num_adaptation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;int(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;num_burnin),
        step_size_setter_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; pkr, new_step_size: pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_replace(
              inner_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_replace(step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;new_step_size)
          ),
        step_size_getter_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; pkr: pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step_size,
        log_accept_prob_getter_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; pkr: pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_accept_ratio,
    )
    
    res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_chain(
        num_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;num_steps,
        num_burnin_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;num_burnin,
        current_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inits,
        kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kernel,
        trace_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;trace_fn
    )
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; res
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;What have we got here?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;NUTS&lt;/code&gt; kernel is hidden within the &lt;code&gt;TransformedTransitionKernel&lt;/code&gt;, and gets as inputs the &lt;code&gt;target_log_prob_fn&lt;/code&gt; function representing the model we want to sample from, and a list of per-variable &lt;code&gt;step_size&lt;/code&gt; for the NUTS algorithm. TFP&amp;rsquo;s docs recommend these should be of the same order-of-magnitude as the standard deviations of the target distribution; here they&amp;rsquo;re taken to be of order 1, and jittered (this can apparently help with areas of high-curvature of the posterior - see the Stan manual on &lt;a href=&#34;https://mc-stan.org/docs/2_18/reference-manual/hmc-algorithm-parameters.html&#34;&gt;HMC parameters&lt;/a&gt; for more details).&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;TransformedTransitionKernel&lt;/code&gt; wraps &lt;code&gt;NUTS&lt;/code&gt; in case we&amp;rsquo;re using unconstraining bijectors. For a more in-depth explanation on bijectors, see my previous &lt;a href=&#34;https://adamhaber.github.io/2019/09/02/Varying-Slopes-Models-and-the-CholeskyLKJ-Distribution-in-TensorFlow-Probability.html&#34;&gt;post&lt;/a&gt;. If no bijectors are passed, we&amp;rsquo;re using Identity bijectors.&lt;/li&gt;
&lt;li&gt;This is wrapped by &lt;code&gt;tfp.mcmc.DualAveragingStepSizeAdaptation&lt;/code&gt;, which, as the name suggests, adapts the sampler step size in order to make sampling more efficient. This is the 2nd addition that saves hand-tuning I&amp;rsquo;ve mentioned above. We&amp;rsquo;re setting the number of adaptation steps to be 80% of the number of burnin step, following TFP&amp;rsquo;s &lt;a href=&#34;https://github.com/tensorflow/probability/blob/b959b26b7b3eee31711096d140b01cf58768e5e1/tensorflow_probability/python/mcmc/dual_averaging_step_size_adaptation.py#L113&#34;&gt;recommendation&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The whole kernel-within-kernel-within-kernel is passed to &lt;code&gt;sample_chain&lt;/code&gt;, along with initial values, the trace function from above, number of burnin steps and number of results.&lt;/p&gt;
&lt;h2 id=&#34;speeding-up-your-sampler-with-xla-compilation&#34;&gt;Speeding up your sampler with XLA compilation&lt;/h2&gt;
&lt;p&gt;We can call &lt;code&gt;run_nuts&lt;/code&gt; as it is and everything will work fine. However, we can use some TFP optimisation tricks to make sampling &lt;em&gt;significantly&lt;/em&gt; faster. Optimizing the sampling function is a one liner:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;run_nuts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; partial(run_nuts_template, trace_fn)

run_nuts_opt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;function(run_nuts)
run_nuts_defun &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;function(run_nuts, autograph&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;What&amp;rsquo;s this?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We&amp;rsquo;re using &lt;code&gt;functools.partial&lt;/code&gt; to &amp;ldquo;plug in&amp;rdquo; the tracing function. This simply saves writing &lt;code&gt;run_nuts&lt;/code&gt; several times for several tracing functions.&lt;/li&gt;
&lt;li&gt;Decorating the &lt;code&gt;run_nuts&lt;/code&gt; function with &lt;code&gt;tf.function&lt;/code&gt; compiles it into a &lt;code&gt;tf.Graph&lt;/code&gt;, which means faster execution and easy integration with the GPU or TPU. This is done by tracing the TensorFlow operations in &lt;code&gt;run_nuts&lt;/code&gt; and constructing the corresponding &lt;code&gt;tf.Graph&lt;/code&gt;, allowing TensorFlow to optimize and exploit parallelism in the computation defined by &lt;code&gt;run_nuts&lt;/code&gt;. See &lt;a href=&#34;https://www.tensorflow.org/guide/function&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/function&#34;&gt;here&lt;/a&gt; if you&amp;rsquo;re interested in learning more.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;autograph=False&lt;/code&gt; is related to how control-flow statements are handled; setting it to &lt;code&gt;False&lt;/code&gt; is the recommendation of the TFP team (we&amp;rsquo;ll benchmark all these below).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can even have a faster version:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;run_nuts_defun_xla &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;function(run_nuts, autograph&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, experimental_compile&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;experimental_compile=True&lt;/code&gt; compiles the whole graph into XLA, which is even faster, as we&amp;rsquo;ll see below. XLA is a domain-specific compiler used by TensorFlow (and jax) to produce highly optimized code and CPU/GPU/TPU compatibility. For learning more about XLA compilation, read &lt;a href=&#34;https://www.tensorflow.org/xla&#34;&gt;this&lt;/a&gt; and watch the talk at the bottom of the page.&lt;/p&gt;
&lt;h1 id=&#34;data&#34;&gt;Data&lt;/h1&gt;
&lt;p&gt;There are two datasets in the original Stan tutorial - we call them &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;new_data&lt;/code&gt;. The first column is the distance (&lt;code&gt;x&lt;/code&gt;) from the hole, the second column is the number of attempts, and the last column is the number of successful putts:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1443&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1346&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;694&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;577&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;455&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;337&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;353&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;208&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;272&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;149&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;240&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;111&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;217&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;69&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;237&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;75&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;202&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;52&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;192&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;46&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;174&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;54&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;167&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;201&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;27&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;17&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;195&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;18&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;191&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;33&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;19&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;147&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;152&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;]])

new_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0.28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;45198&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;45183&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;0.97&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;183020&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;182899&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;1.93&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;169503&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;168594&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;2.92&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;113094&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;108953&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;3.93&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;73855&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;64740&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;4.94&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;53659&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;41106&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;5.94&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;42991&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28205&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;6.95&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;37050&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;21334&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;7.95&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;33275&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16615&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;8.95&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;30836&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;13503&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;9.95&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28637&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11060&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;10.95&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;26239&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;9032&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;11.95&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;24636&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7687&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;12.95&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;22876&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6432&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;14.43&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;41267&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;9813&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;16.43&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;35712&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7196&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;18.44&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;31573&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5290&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;20.44&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28280&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4086&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;21.95&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;13238&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1642&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;24.39&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;46570&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4767&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;28.40&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;38422&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2980&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;32.39&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;31641&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1996&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;36.39&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;25604&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1327&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;40.37&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20366&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;834&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;44.38&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;15977&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;559&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;48.37&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11770&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;311&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;52.36&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8708&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;231&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;57.25&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8878&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;204&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;63.23&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5492&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;103&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;69.18&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3087&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;35&lt;/span&gt;],
[&lt;span style=&#34;color:#ae81ff&#34;&gt;75.19&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1742&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;]])

df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(data, columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
new_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(new_data, columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is how the data looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;new_data&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Distance&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;% o&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;f success&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Original data&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_28_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;model-1&#34;&gt;Model 1&lt;/h1&gt;
&lt;p&gt;The first model is a simple logistic regression. Since the graph above is somewhat skewed and not symmetric around its midpoint (like a sigmoid), you can already guess logistic regression won&amp;rsquo;t be very accurate but why not:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionCoroutine&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Root

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;golf_logistic&lt;/span&gt;():
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; root(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1e6&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; root(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1e6&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Binomial(
            total_count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype),
            logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;b
        )
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;golf_logistic_jd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionCoroutine(golf_logistic)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that unlike the Stan tutorial, we&amp;rsquo;re using a super-vague but proper prior $\mathcal{N}\left(0,10^6\right)$.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll use &lt;code&gt;tfd.JointDistributionCoroutine&lt;/code&gt; to build all 4 models in this post. &lt;code&gt;JointDistributionCoroutine&lt;/code&gt; is a cousin of the more-intuitive &lt;code&gt;JointDistributionSequential&lt;/code&gt; we&amp;rsquo;ve used in previous posts. Instead of a list of &lt;code&gt;tfd.Distribution&lt;/code&gt;-like instances, we&amp;rsquo;re passing a generator that yields a sequence of &lt;code&gt;tfd.Distribution&lt;/code&gt;-like instances. The main advantage is that with &lt;code&gt;Coroutine&lt;/code&gt;&#39;s function syntax its easier to express intermediate calculations, compared to &lt;code&gt;Sequential&lt;/code&gt;&#39;s list syntax. This will come in handy already in the 2nd model.&lt;/p&gt;
&lt;p&gt;The main differences are that we need to use &lt;code&gt;yield&lt;/code&gt; everytime we&amp;rsquo;re sampling from a distribution, and wrap priors (random variables in the model that don&amp;rsquo;t depend on other random variables) with &lt;code&gt;root&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once we have our model, we feed its &lt;code&gt;log_prob&lt;/code&gt; method together with the observed data into &lt;code&gt;run_nuts&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;golf_logistic_log_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;args: golf_logistic_jd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(args &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype),))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s see how each of the &lt;code&gt;run_nuts&lt;/code&gt; version is doing:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts(golf_logistic_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 13min 5s, sys: 4.28 s, total: 13min 10s
Wall time: 13min 13s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_opt(golf_logistic_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 29.7 s, sys: 4.13 s, total: 33.8 s
Wall time: 18.7 s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_defun(golf_logistic_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 29 s, sys: 4.04 s, total: 33 s
Wall time: 17.9 s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_defun_xla(golf_logistic_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 6.29 s, sys: 77.9 ms, total: 6.37 s
Wall time: 6.39 s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So &lt;code&gt;tf.function&lt;/code&gt; makes a &lt;em&gt;huge&lt;/em&gt; difference, &lt;code&gt;autograph&lt;/code&gt; True/False doesn&amp;rsquo;t really matter here, and XLA definitely helps.&lt;/p&gt;
&lt;p&gt;Visualizing the results with ArviZ is now straightforward:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp_trace_to_arviz(res,[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_trace(trace1);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_42_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;And so is displaying summary statistics:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary(trace1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Let&amp;rsquo;s see how this logistic regression looks like when we use the mean parameters:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;a,b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary(trace1)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;], [np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(x)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(x)) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; a&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;b],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model 1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;) 
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;], df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;) 
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_46_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;model-2&#34;&gt;Model 2&lt;/h1&gt;
&lt;p&gt;Logistic regression is a good start, but we can see it&amp;rsquo;s not doing a very good job at fitting our data. The second model is a major improvement, incorporating the knowledge that this data is describing attempts to insert a small ball into a larger hole; therefore their sizes, the distance between them and the corresponding angles probably matter.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;r &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1.68&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#ball size&lt;/span&gt;
R &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;4.25&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#hole size&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;#threshold angles&lt;/span&gt;
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;th_angle&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arcsin((R&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;r)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])          
new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;th_angle&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arcsin((R&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;r)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;normal_cdf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;NormalCDF()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;golf_angle_distance&lt;/span&gt;():
    &lt;span style=&#34;color:#75715e&#34;&gt;# priors&lt;/span&gt;
    sigma &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; root(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1e6&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# transformations&lt;/span&gt;
    phi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
        tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;th_angle&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;sigma
    )&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# likelihood&lt;/span&gt;
    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Binomial(
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype),
            probs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;phi
        )
    )

golf_angle_distance_jd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionCoroutine(golf_angle_distance)
golf_angle_distance_jd_log_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;args: golf_angle_distance_jd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(
    args &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;], dtype),)
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that something like &lt;code&gt;phi&lt;/code&gt; would be difficult to express with &lt;code&gt;Sequential&lt;/code&gt;, but straightforward with &lt;code&gt;Coroutine&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll use this model as an opportunity to do something different with our &lt;code&gt;trace_fn&lt;/code&gt;. Stan has this super useful &lt;code&gt;generated quantities&lt;/code&gt; block, in which we can use the sampled parameters to generated various kinds of quantities of interest. We&amp;rsquo;ve mentioned above that &lt;code&gt;trace_fn&lt;/code&gt; takes a &lt;code&gt;state&lt;/code&gt; and a &lt;code&gt;pkr&lt;/code&gt;, and usually discards the first. We&amp;rsquo;ll now modify our &lt;code&gt;trace_fn&lt;/code&gt; so that in each step it takes the current angle (in radians) and converts it to degrees:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trace_fn_angles&lt;/span&gt;(current_state, pkr):  
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (
        tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(current_state[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;180&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pi),
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;target_log_prob,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;leapfrogs_taken,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;has_divergence,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;energy,
        pkr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inner_results&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_accept_ratio
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We&amp;rsquo;re taking the current state, representing the angle in radians, and convert it to degrees. The &lt;code&gt;tf.squeeze&lt;/code&gt; is here to get rid of a redundant dimension that can cause broadcasting issues later.&lt;/p&gt;
&lt;p&gt;As for timing - the non &lt;code&gt;tf.function&lt;/code&gt;-ed version is so slow that we won&amp;rsquo;t even try. Let&amp;rsquo;s compare the other alternatives:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;run_nuts_angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; partial(run_nuts_template, trace_fn_angles)

run_nuts_opt_angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;function(run_nuts_angle)
run_nuts_defun_angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;function(run_nuts_angle, autograph&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
run_nuts_defun_xla_angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;function(run_nuts_angle, autograph&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, experimental_compile&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_opt_angle(golf_angle_distance_jd_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))], [tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp()])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 6.18 s, sys: 808 ms, total: 6.99 s
Wall time: 3.96 s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_defun_angle(golf_angle_distance_jd_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))], [tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp()])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 6.06 s, sys: 755 ms, total: 6.82 s
Wall time: 3.93 s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_defun_xla_angle(golf_angle_distance_jd_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))], [tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp()])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 5.29 s, sys: 59.1 ms, total: 5.35 s
Wall time: 5.38 s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;No clear winner this time. Let&amp;rsquo;s inspect the trace:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp_trace_to_arviz(res,[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],
                            sample_stats_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;angle&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;sample_stats_name)
az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_trace(trace2);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_60_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Since we traced the angles using &lt;code&gt;trace_fn_angles&lt;/code&gt;, ArviZ treats it as another sample statistics - it&amp;rsquo;s saved as an &lt;code&gt;xarray.DataArray&lt;/code&gt; and even has its own plotting method:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;angle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_62_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;I found this nice and cleaner than &lt;code&gt;sns.distplot(res[0][0].numpy().flatten()*180/np.pi)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We print the summary statistics and make sure we&amp;rsquo;re reproducing the Stan tutorial results:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary(trace2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;comparing-models-1--2-with-arviz&#34;&gt;Comparing models 1 &amp;amp; 2 with ArviZ&lt;/h2&gt;
&lt;p&gt;ArviZ allows us to conduct model comparison using approximate Leave-One-Out cross validation and WAIC information criteria (read more &lt;a href=&#34;https://mc-stan.org/loo/&#34;&gt;here&lt;/a&gt; if you&amp;rsquo;re interested). To do so, our ArviZ objects must have a &lt;code&gt;log_likelihood&lt;/code&gt; sampler stats field (this is why we&amp;rsquo;ve included &lt;code&gt;target_log_prob&lt;/code&gt; in our tracing function):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_likelihood&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, trace2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_likelihood&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;((10, 500), (10, 500))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Model comparison is now as easy as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compare({&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Model 1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:trace1, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Model 2&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;:trace2})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;The models are ranked from best to worst, so Model 2 (not surprisingly) outperforms Model 1. For more info about model comparison, how to read this table and its visualization using &lt;code&gt;az.plot_compare&lt;/code&gt;, see &lt;a href=&#34;https://docs.pymc.io/notebooks/model_comparison.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;model-3&#34;&gt;Model 3&lt;/h1&gt;
&lt;p&gt;The authors aren&amp;rsquo;t satisfied with the fit of Model 2 and incorporate yet another piece of golf knowledge - other than shooting the ball at the right angle, you need to shoot it to the right distance, as well. They describe how this can be modelled, and proceed to fit the model:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;distance_tol &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3.&lt;/span&gt;
overshot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;golf_angle_distance_2&lt;/span&gt;():
    &lt;span style=&#34;color:#75715e&#34;&gt;# priors&lt;/span&gt;
    sigma_angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; root(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    sigma_distance &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; root(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))

    &lt;span style=&#34;color:#75715e&#34;&gt;# transformations&lt;/span&gt;
    p_angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
        tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;th_angle&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;sigma_angle
    )&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    
    p_dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
        (distance_tol&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;overshot)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;overshot,dtype)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;sigma_distance)
    ) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; \
    normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
        (&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;overshot)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;overshot,dtype)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;sigma_distance)
    )
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# likelihood&lt;/span&gt;
    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Binomial(
            tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype),
            probs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;p_angle&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;p_dist
        )
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;golf_angle_distance_2_jd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionCoroutine(golf_angle_distance_2)
golf_angle_distance_2_jd_log_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;args: golf_angle_distance_2_jd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(
    args &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;], dtype),)
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_opt(golf_angle_distance_2_jd_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))],
                              bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(), tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp()])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 23min 51s, sys: 4min 30s, total: 28min 21s
Wall time: 10min 13s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_defun(golf_angle_distance_2_jd_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))],
                              bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(), tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp()])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 18min 56s, sys: 3min 51s, total: 22min 48s
Wall time: 8min 11s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_defun_xla(golf_angle_distance_2_jd_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))],
                              bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(), tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp()])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 1min 57s, sys: 38.1 s, total: 2min 35s
Wall time: 1min 6s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, XLA makes ~8x difference in speed, which is incredible for an inherently iterative process!&lt;/p&gt;
&lt;p&gt;As for the trace:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp_trace_to_arviz(res,[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma_angle&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma_distance&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_trace(trace3);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_80_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This isn&amp;rsquo;t what you want to see when inspecting a trace&amp;hellip; The chains haven&amp;rsquo;t mixed at all. Surprisingly, the Stan version had divergent transitions here, while we did not:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace3&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;diverging&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;xarray.DataArray &#39;diverging&#39; ()&amp;gt;
array(0)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;model-4&#34;&gt;Model 4&lt;/h1&gt;
&lt;p&gt;In the 4th model, instead of using a binomial likelihood, we&amp;rsquo;re using a normal approximation of the binomial distribution and adding an additional noise term (read the original for a more in-depth explanation):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;golf_angle_distance_3&lt;/span&gt;(): 
    &lt;span style=&#34;color:#75715e&#34;&gt;# priors&lt;/span&gt;
    sigma_angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; root(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    sigma_distance &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; root(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    sigma_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; root(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HalfNormal(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# transformations&lt;/span&gt;
    p_angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
      tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;th_angle&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;sigma_angle
    ) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    p_dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
      (distance_tol&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;overshot)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;overshot,dtype)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;sigma_distance)
    ) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; \
    normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
      (&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;overshot)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;overshot,dtype)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;sigma_distance)
    )
    p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p_dist&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;p_angle
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# likelihood&lt;/span&gt;
    probs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(p, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(p&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;p)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype))&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;sigma_y&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;golf_angle_distance_3_jd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionCoroutine(golf_angle_distance_3)

golf_angle_distance_3_jd_log_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;args: golf_angle_distance_3_jd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob(
    args &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;], dtype),)
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_opt(golf_angle_distance_3_jd_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))],
                 bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp()]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 3min 45s, sys: 45.6 s, total: 4min 30s
Wall time: 1min 39s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_defun(golf_angle_distance_3_jd_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))],
                 bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp()]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 4min 2s, sys: 48.4 s, total: 4min 50s
Wall time: 1min 46s
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;time
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; run_nuts_defun_xla(golf_angle_distance_3_jd_log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)),tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((n_chains,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))],
                 bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp()]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;CPU times: user 15.8 s, sys: 177 ms, total: 16 s
Wall time: 16.1 s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, XLA is simply an incredible speed up of the sampling function.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;trace4 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp_trace_to_arviz(res,[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma_angle&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma_distance&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma_y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot_trace(trace4);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_91_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This looks much better:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary(trace4)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;We&amp;rsquo;ll extract the mean parameters from the summary, and plot the resulting function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;mean_sigma_angle, mean_sigma_dist, mean_sigma_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; az&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary(trace4)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;normal_cdf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;NormalCDF()

p_angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;th_angle&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;mean_sigma_angle
)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

p_dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
    (distance_tol&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;overshot)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;overshot,dtype)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;mean_sigma_dist)
) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; \
normal_cdf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(
    (&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;overshot)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;overshot,dtype)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;mean_sigma_dist)
)
mean_p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (p_dist&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;p_angle)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()
std_p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(mean_p&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;mean_p)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],dtype))&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;mean_sigma_y&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;errorbar(new_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],mean_p,yerr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;std_p,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;model 4&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_97_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This is, by all means, a very impressive fit. And the errorbars are there, they&amp;rsquo;re just too small we can&amp;rsquo;t actually see them. Definitely not bad for a 3 parameters model.&lt;/p&gt;
&lt;h1 id=&#34;comparison-summary&#34;&gt;Comparison summary&lt;/h1&gt;
&lt;p&gt;This is a summary of the different timings:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Model 1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Model 2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Model 3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Model 4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;without tf.function&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;793&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;tf.function, autograph=True&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18.7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.96&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;613&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;tf.function, autograph=False&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17.9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;strong&gt;3.93&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;491&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;106&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;tf.function + XLA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;strong&gt;6.39&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.38&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;strong&gt;66&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;strong&gt;16&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So XLA compilation is a clear winner. Running the same models with 256 chains instead of 10 (very easy to do with TFP) gives qualitatively similar results.&lt;/p&gt;
&lt;h1 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h1&gt;
&lt;p&gt;In this post we&amp;rsquo;ve tried to replicate Stan&amp;rsquo;s awesome golf tutorial. Along the way, we saw how to work with the new NUTS kernel, how to speed it up using &lt;code&gt;tf.function&lt;/code&gt; and XLA compilation, how to use the &lt;code&gt;trace_fn&lt;/code&gt; to generated quantities of interest, and how to use ArviZ to handle all the plotting for us.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Survival analysis, censoring and hacking the log_prob in TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/survival-analysis/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/survival-analysis/</guid>
      <description>&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;Survival analysis is a super useful technique for modelling time-to-event data; implementing a simple survival analysis using TFP requires hacking around the sampler log probability function; in this post we&amp;rsquo;ll see how to do this, and introduce the basic terminology of survival analysis.&lt;/p&gt;
&lt;h1 id=&#34;survival-analysis-101&#34;&gt;Survival analysis 101&lt;/h1&gt;
&lt;p&gt;Survival analysis is an &lt;em&gt;incredibly&lt;/em&gt; useful technique for modeling time-to-something data. &amp;ldquo;something&amp;rdquo; can be the death a patient (hence the name), the &lt;a href=&#34;https://github.com/gm-spacagna/deep-ttf&#34;&gt;failure&lt;/a&gt; of some part in a machine, the &lt;a href=&#34;https://ragulpr.github.io/2016/12/22/WTTE-RNN-Hackless-churn-modeling/&#34;&gt;churn&lt;/a&gt; of a customer, the &lt;a href=&#34;https://lifelines.readthedocs.io/en/latest/Survival%20analysis%20with%20lifelines.html&#34;&gt;fall&lt;/a&gt; of a regime, and tons of other problems. Since time-to-event questions are everywhere, you&amp;rsquo;ll see survival analysis (possibly under different names) in clinical studies, econometrics, epidemiology, mechnical engineering, etc.&lt;/p&gt;
&lt;p&gt;For me, one of the biggest sell-points of survival analysis is that it provides an elegant solution to handle &lt;em&gt;censored&lt;/em&gt; observations. This is a technical term, and it can be quite confusing&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, so I&amp;rsquo;ll try to illustrate it with a toy example. Say you&amp;rsquo;re selling diapers, and you bought 100 diapers to begin with - that&amp;rsquo;s your stock. After one month, you&amp;rsquo;ve sold 32 diapers, and still have 68 diapers in stock. To plan the size of the warehouse you want to build, you want to estimate how long it takes you to sell a diaper. Obviously, taking the mean of selling-times of the 32 diapers you&amp;rsquo;ve sold would give you an overly optimistic estimation&amp;hellip; but what do you do with the 68 diapers you still have in stock? How can you use the information that they&amp;rsquo;ve been sitting here for some time already to improve your estimation? You call them &amp;ldquo;censored diapers&amp;rdquo;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; and use survival analysis.&lt;/p&gt;
&lt;h1 id=&#34;survival-analysis-mathematics&#34;&gt;Survival analysis mathematics&lt;/h1&gt;
&lt;p&gt;Survival analysis is a huge topic and I&amp;rsquo;m obviously not going to cover everything in here. I&amp;rsquo;ll focus on the terminology needed for this post; for a more detailed introduction, I highly recommend checking out &lt;a href=&#34;https://lifelines.readthedocs.io/en/latest/Quickstart.html&#34;&gt;lifelines docs&lt;/a&gt; (we&amp;rsquo;ll use lifelines - a python package for survival analysis - in this post, as well).&lt;/p&gt;
&lt;p&gt;As mentioned above, survival analysis is about estimating a time-to-event. Let&amp;rsquo;s denote this time with $T$. Ideally, we&amp;rsquo;re interested in learning a probability distribution $P$ over the possible values of $T$. Note that this already assumes $T$ happens &lt;em&gt;sometimes&lt;/em&gt; in the future, since the distribution integrates to 1. This is a reasonable assumption when we study mortality, but not as much when studying something like conversion rates - see &lt;a href=&#34;https://erikbern.com/2019/08/05/modeling-conversion-rates-using-weibull-and-gamma-distributions.html&#34;&gt;this&lt;/a&gt; post for more details if you&amp;rsquo;re interested. In this post I&amp;rsquo;ll stick to the more traditional (and morbid) survival analysis in which everyone dies eventually.&lt;/p&gt;
&lt;p&gt;So we have this $P_{\theta}\left(T\right)$, which is defined by some parameter $\theta$ (there are also semi-parametric and non-parametric approaches to survival analysis; we&amp;rsquo;ll get to that below). This formulation allows us to handle censored observations naturally; given the times of the observed event $\left\{O_1,O_2,&amp;hellip;,O_n\right\}$ ($n=32$ in the diapers example; these are times until the event happened), and the times of the censored events $\left\{C_1,C_2,&amp;hellip;,C_m\right\}$ ($m=68$ in the diapers example; these are times until censoring happened), we can construct the likelihood function&lt;/p&gt;
&lt;p&gt;$$
\mathcal{L}\left(\underbrace{\theta}_{\text{parameter}}\vert \underbrace{O_1,O_2,&amp;hellip;,O_n,C_1,C_2,&amp;hellip;,C_m}_{\text{data}}\right) = \prod_{i=1}^n {P_\theta\left(T=O_i\right)} \prod_{j=1}^m {P_\theta\left(T&amp;gt;C_j\right)}
$$&lt;/p&gt;
&lt;p&gt;&amp;hellip; since the only thing we know about the censored events is that the time-of-event is greater than the time of censoring. Now add a prior on $\theta$ and you&amp;rsquo;ve got yourself a posterior (up to normalization which we usually don&amp;rsquo;t really care about).&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s cook up an example to see how this works.&lt;/p&gt;
&lt;h1 id=&#34;censored-diapers&#34;&gt;Censored diapers&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# the necessary imports&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfp
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt 
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; distributions &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; bijectors &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfb
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; matplotlib.lines &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Line2D
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;enable_eager_execution()

&lt;span style=&#34;color:#75715e&#34;&gt;# for plotting&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_palette(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;muted&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# for reproducibility&lt;/span&gt;
np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;1324&lt;/span&gt;)
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_random_seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;234&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Say we start stocking up on diapers on January 1st. Some arrive to us exactly on time, some arrive later - arrival times are uniformly distributed within January.
For simplicity, we assume that the real underlying event times (from arrival to selling) are exponentially distributed with a mean of 50 days. This is what we would actually measure without censoring, that is - if we could&amp;rsquo;ve waited long enough until all (or enough of) the diapers were sold.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;start_date &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_datetime(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;2019-01-01&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
N_samples &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;
mean_time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
arrival_rng &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;date_range(start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start_date, periods&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;, freq&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
arrival_date &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(arrival_rng, size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; N_samples)
real_T &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exponential(mean_time, size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; N_samples)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame({ &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Arrival Date&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: arrival_date, &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;real_T&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;: real_T, 
                  &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Real Selling Date&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt; : arrival_date &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_timedelta(real_T, unit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s assume censoring happens on March 1st - that&amp;rsquo;s the day in which we decide &amp;ldquo;OK, these diapers were sold after these real-selling-times, these diapers are still in stock, let&amp;rsquo;s estimate mean time-to-event&amp;rdquo;. Phrased differently - this is when we get the data. By definition, every diaper whose &lt;code&gt;Real Selling Date&lt;/code&gt; is later than March 1st will be considered a censored observation. The times of the observed, uncensored event are from arrival to selling; The times for the censored events are from arrival to the censoring date.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;censoring_date &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_datetime(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;2019-03-01&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)

df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;censored&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Real Selling Date&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;censoring_date
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;T&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;censored&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;], (censoring_date &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Arrival Date&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days, real_T)
df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Arrival Date&lt;/th&gt;
&lt;th&gt;real_T&lt;/th&gt;
&lt;th&gt;Real Selling Date&lt;/th&gt;
&lt;th&gt;censored&lt;/th&gt;
&lt;th&gt;T&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2019-01-03&lt;/td&gt;
&lt;td&gt;36&lt;/td&gt;
&lt;td&gt;2019-02-08&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;td&gt;36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2019-01-14&lt;/td&gt;
&lt;td&gt;325&lt;/td&gt;
&lt;td&gt;2019-12-05&lt;/td&gt;
&lt;td&gt;True&lt;/td&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2019-01-16&lt;/td&gt;
&lt;td&gt;69&lt;/td&gt;
&lt;td&gt;2019-03-26&lt;/td&gt;
&lt;td&gt;True&lt;/td&gt;
&lt;td&gt;44&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2019-01-11&lt;/td&gt;
&lt;td&gt;62&lt;/td&gt;
&lt;td&gt;2019-03-14&lt;/td&gt;
&lt;td&gt;True&lt;/td&gt;
&lt;td&gt;49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2019-01-19&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;2019-02-28&lt;/td&gt;
&lt;td&gt;False&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here we can already see the problem - censoring makes us &lt;em&gt;severely&lt;/em&gt; underestimate the mean selling time:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;censored==0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;T&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(), real_T&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
(&lt;span style=&#34;color:#ae81ff&#34;&gt;19.681&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;49.236&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Pictorially, this is how it looks like. We sample 20 rows of data, and plot their individual timelines. Censoring events are the red circles, and the censored part of each observation is the dashed blue line:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))
n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;
samp_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n)
samp_cens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; samp_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;censored&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hlines(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(n), 
           (samp_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Arrival Date&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start_date)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days,
           (samp_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Arrival Date&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start_date)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; samp_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;T&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],
           color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hlines(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(samp_cens), 
           (samp_df[samp_cens][&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Arrival Date&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start_date)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; samp_df[samp_cens][&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;T&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],
           (samp_df[samp_cens][&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Real Selling Date&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start_date)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days,
           color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;darkblue&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter([(censoring_date&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start_date)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;samp_cens&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(),np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(samp_cens),
            s&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;, facecolors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;none&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, edgecolors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline((censoring_date&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;start_date)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days, ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Days from start&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Different samples&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;yticks([])

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Obviously, the mean length of the black lines is significantly shorter than that of &lt;em&gt;all&lt;/em&gt; the lines; this is exactly the bias caused by ignoring the censored observations.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_15_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;the-model&#34;&gt;The model&lt;/h1&gt;
&lt;p&gt;We assume a simple exponential distribution for the event times distribution:&lt;/p&gt;
&lt;p&gt;$$P_{\lambda}\left(T\right)=\frac{1}{\lambda}e^{-\frac{T}{\lambda}}$$&lt;/p&gt;
&lt;p&gt;In this parametrization, $\lambda$ is the mean time-to-event; we want to infer $\lambda$ from the data.
We put a $\text{Normal}\left(\mu=3,\sigma=3\right)$ prior on $\log\lambda$, representing our prior belief that diapers aren&amp;rsquo;t sold in nanoseconds nor in geological timescales, and the constraint that $\lambda$ must be positive.&lt;/p&gt;
&lt;p&gt;So, this means that our log probability function is:&lt;/p&gt;
&lt;p&gt;$$\underbrace{\sum_{i=1}^n \log{P_\lambda\left(T=O_i\right)}}_{\text{likelihood of observed}} + \underbrace{\sum_{j=1}^m \log{P_\lambda\left(T&amp;gt;C_j\right)}}_{\text{likelihood of censored}}+\underbrace{\log\text{Normal}\left(\lambda\vert\mu=3,\sigma=3\right)}_{\text{Prior on }\lambda}$$&lt;/p&gt;
&lt;p&gt;The first sum and the last term are easy - we just define an exponential model with the prior we want and feed it with the observed samples. The tricky part is how to handle with the second, censored sum.&lt;/p&gt;
&lt;h1 id=&#34;lccdf&#34;&gt;LCCDF&lt;/h1&gt;
&lt;p&gt;The thing we need to implement in order to feed the right &lt;code&gt;log_prob&lt;/code&gt; function to the sampler is called LCCDF: an intimidating acronym the stands for &lt;strong&gt;L&lt;/strong&gt;og &lt;strong&gt;C&lt;/strong&gt;omplementary  &lt;strong&gt;C&lt;/strong&gt;umulative &lt;strong&gt;D&lt;/strong&gt;ensity &lt;strong&gt;F&lt;/strong&gt;unction. We&amp;rsquo;ll unfold this backwards:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The cumulative density function (CDF) of our time-to-event distribution is $F_\lambda\left(t\right)=P_\lambda(T\le t)$.&lt;/li&gt;
&lt;li&gt;The complmentary CDF (CCDF) is $1-F_\lambda\left(t\right)=P_\lambda(T&amp;gt;t)$;&lt;/li&gt;
&lt;li&gt;Its log (LCCDF) is $\log P_\lambda(T&amp;gt;t)$, which is exactly what we want.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some LCCDFs are implemented in languages such as Stan (&lt;a href=&#34;https://mc-stan.org/docs/2_18/functions-reference/exponential-distribution.html&#34;&gt;this&lt;/a&gt; is what we want), but in TFP (currently) we have to implement this ourselves. Luckily, the CDF of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Exponential_distribution#Cumulative_distribution_function&#34;&gt;exponential distribution&lt;/a&gt; is $1-e^{-\frac{T}{\lambda}}$, which means our LCCDF is super simple - $\log P_\lambda(T&amp;gt;t)=-\frac{T}{\lambda}$. Cases for which we don&amp;rsquo;t have an analytical expression for the LCCDF are trickier to handle; The solution in Sigrid Keydana&amp;rsquo;s &lt;a href=&#34;https://blogs.rstudio.com/tensorflow/posts/2019-07-31-censored-data/&#34;&gt;post&lt;/a&gt; (using TFP built-in CDF functions) is more general, but I found it less numerically stable, and writing everything explicitly helped me understand what&amp;rsquo;s going on. We&amp;rsquo;ll stick with the simpler case in this introductory post.&lt;/p&gt;
&lt;p&gt;We now go ahead and implement this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#converting the data to tf tensors&lt;/span&gt;
obs_times &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_to_tensor(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;censored==0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;T&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
cens_times &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_to_tensor(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;censored==1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;T&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is our model, containing the normal prior on $\log\lambda$ and the exponential likelihood terms. This is pretty straightforward:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;obs_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
  [
    tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), &lt;span style=&#34;color:#75715e&#34;&gt;#log_rate&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; log_rate:
      tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exponential(rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 
            &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(log_rate[:,tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis])
        )), reinterpreted_batch_ndims &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now, given a $\log\lambda$, the exponential LCCDF function simply sums $-\frac{T}{\lambda}$ over all censored times. Note that &lt;code&gt;log_rate&lt;/code&gt; has shape &lt;code&gt;(n_chains,)&lt;/code&gt;, and &lt;code&gt;cens_times&lt;/code&gt; has shape &lt;code&gt;(n_cens_times,)&lt;/code&gt;, so we need to add a &lt;code&gt;tf.newaxis&lt;/code&gt; to make sure both are broadcasted along the right dimensions. We also cast &lt;code&gt;cens_times&lt;/code&gt; to float so the division is properly defined.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exponential_lccdf&lt;/span&gt;(log_rate):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(
        &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(cens_times, log_rate&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dtype)[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis,:]&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(log_rate[:,tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]),
        axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, we combine the likelihood of the observed times and the prior, which are given by &lt;code&gt;obs_model.log_prob&lt;/code&gt; evaluated at the observed times, and the likelihood of the censored times, which we just defined:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;log_prob&lt;/span&gt;(log_rate):
    lp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; obs_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([log_rate, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(obs_times, log_rate&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dtype)[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis,:]])
    censored_likelihood &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; exponential_lccdf(log_rate)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; lp &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; censored_likelihood
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We now proceed as usual, by calling our HMC sampler helper function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.function&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sampleHMC&lt;/span&gt;(log_prob, inits, bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None):
    inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HamiltonianMonteCarlo(
        target_log_prob_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;log_prob,
        step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;,
        num_leapfrog_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;
    )
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
        inner_kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TransformedTransitionKernel(inner_kernel, bijectors_list)
        
    adaptive_kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SimpleStepSizeAdaptation(
        inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inner_kernel,
        num_adaptation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;800&lt;/span&gt;
    )
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_chain(
        num_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;,
        current_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inits,
        kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;adaptive_kernel,
        num_burnin_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;,
        trace_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
initial_log_rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; obs_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)

samps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones_like(initial_log_rate[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3.&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Just for comparison, if we call the sampler without the censored likelihood (meaning we &amp;ldquo;throw away&amp;rdquo; the censored observations), this is what we get:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;samps_ignore_censored &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(
    &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; log_rate:obs_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([log_rate, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(obs_times, log_rate&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dtype)[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis,:]]),
    [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(initial_log_rate[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(samps[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten()),label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;With censored&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(samps_ignore_censored[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten()),label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Without censored&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(real_T&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(),ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Empirical mean of real T&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;lambda$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Density&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_32_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;survival-regression&#34;&gt;Survival regression&lt;/h1&gt;
&lt;p&gt;This was a very simple and cooked-up demonstration of survival analysis, mainly to illustrate how to account for censored observations by adding the necessary LCCDF to the sampler log probability function. However, in many cases what we actually want is to understand how different features affect survival probability. For example, we&amp;rsquo;d like to understand how a given treatment affects the survival probabilities of patients, or the age of customers affects time-to-lapse or whatnot. This is called survival regression.&lt;/p&gt;
&lt;p&gt;Like in the previous posts, I&amp;rsquo;m sticking to the excellent examples from McElreath&amp;rsquo;s Statistical Rethinking book. However, this example is actually not from the book itself, but from &lt;a href=&#34;https://www.youtube.com/watch?v=p7g-CgGCS34&#34;&gt;Statistical Rethinking Winter 2019 Lecture 13&lt;/a&gt; from 23:43 onwards (you should probably go watch this now, the relevant part is about 10 minutes long).&lt;/p&gt;
&lt;p&gt;The data in this example is from an animal care facility in Austin (&lt;a href=&#34;https://data.austintexas.gov/browse?q=animal&amp;amp;sortBy=relevance&#34;&gt;source&lt;/a&gt;), and describes cats arrival time to the facility, when/if/how they left, breed, color, age, etc. For us, the event of interest is adoption - we&amp;rsquo;ll try to estimate time-to-adoption. But this time, we&amp;rsquo;re using the cats color as a predictor: we&amp;rsquo;ll compare the adoption times of black cats vs. non-black cats.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re using the same data as McElreath (who kindly supplied both the data and the .R script containing the processing):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# references to original data (from the email)&lt;/span&gt;
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;https://raw.githubusercontent.com/adamhaber/adamhaber.github.io/master/assets/AustinCats.csv&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, delimiter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;adopted&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;out_event&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Adoption&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)

is_black_cens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_to_tensor(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;adopted==0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;black&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(float))
is_black_obs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_to_tensor(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;adopted==1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;black&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(float))

y_cens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_to_tensor(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;adopted==0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days_to_event)
y_obs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_to_tensor(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;adopted==1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days_to_event)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The model is very similar to our made-up example from before - the only thing that&amp;rsquo;s different is that now $\log\lambda$ is a simple linear function:&lt;/p&gt;
&lt;p&gt;$$\log\lambda = \alpha+\beta\cdot\text{is_black}$$&lt;/p&gt;
&lt;p&gt;$\text{is_black}$ equals one for black cats, and zero otherwise, which means the log rate equals $\alpha+\beta$ for black cats and $\alpha$ otherwise. So, instead of estimating $\log\lambda$ directly, we&amp;rsquo;re estimating the parameters of this simple linear model. The prior for the intercept is the same as in the previous example, and the prior for the slope is centered around zero (we don&amp;rsquo;t have a-priori reason to believe black cats are bigoted against), and of the same scale.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;obs_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
  [
    tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), &lt;span style=&#34;color:#75715e&#34;&gt;#alpha&lt;/span&gt;
    tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), &lt;span style=&#34;color:#75715e&#34;&gt;#beta&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; beta, alpha:
      tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exponential(rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 
            &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(is_black_obs[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis,:], beta&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dtype)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;beta[:,tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;\
                        alpha[:,tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis])
        )), reinterpreted_batch_ndims &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
  ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The LCCDF function is again very similar, but this time in the denominator we have our simple linear function and not just a single parameter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exponential_lccdf&lt;/span&gt;(alpha, beta):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(
        &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(y_cens[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis,:],alpha&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dtype) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(is_black_cens[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis,:], beta&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dtype) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; beta[:,tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; alpha[:,tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis]),
        axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;log_prob&lt;/code&gt; is exactly the same, and so is the code for calling the sampler:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;log_prob&lt;/span&gt;(alpha, beta):
    lp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; obs_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([alpha, beta, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(y_obs, alpha&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dtype)[tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis,:]])
    potential &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  exponential_lccdf(alpha, beta)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; lp &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; potential
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
initial_coeffs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; obs_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)
alphas, betas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(log_prob, [tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(initial_coeffs[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]), tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(initial_coeffs[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We convert samples back to &lt;code&gt;numpy&lt;/code&gt; for easier plotting, and compute the corresponding rates:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;alphas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; alphas&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten()
betas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; betas&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten()

lambda_black &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(alphas &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; betas)
lambda_non_black &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(alphas)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(lambda_black,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(lambda_non_black,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;orange&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;non black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend(fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Days to adoption&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Density&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_49_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;It turns out people &lt;em&gt;are&lt;/em&gt; biased against black cats! We can also use the inferred rates to plot one of the central quantities of interest in survival analysis - the &lt;strong&gt;survival function&lt;/strong&gt;. The survival function is simply the CCDF from before:&lt;/p&gt;
&lt;p&gt;$$S(t) = P(T&amp;gt;t)$$&lt;/p&gt;
&lt;p&gt;$S(t)$ quantifies the probability of surviving longer than $t$. For the minimal possible duration (0 in our case), $S(0)=1$, and $S(\infty)=0$ (everyone dies). We can use the inferred rates to plot the estimated survival curves:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;t &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linspace(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; lam_nb, lam_b &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(lambda_non_black[:&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;], lambda_black[:&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;]):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(t, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;t&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;lam_nb),c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;orange&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)    
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(t, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;t&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;lam_b),c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)    
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Proportion remaining&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Days&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
legend_elements &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [Line2D([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;),
                   Line2D([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;orange&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;orange&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)]
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend(handles&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;legend_elements,fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_51_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&amp;hellip; which is the same plot as in the lecture.&lt;/p&gt;
&lt;h1 id=&#34;overthinking-box---kaplan-meier-non-parametric-estimator&#34;&gt;Overthinking box - Kaplan Meier non-parametric estimator&lt;/h1&gt;
&lt;p&gt;In all we&amp;rsquo;ve done so far, we&amp;rsquo;ve assumed a specific parametric form for the durations distributions&amp;hellip; but how can we check if this assumption makes any sense? One way is to compare it to a non-parametric estimator of the survival function.&lt;/p&gt;
&lt;p&gt;The Kaplan-Meier estimator is a non-parametric estimator that does just that. It is defined as follows:&lt;/p&gt;
&lt;p&gt;$$S_{KM}\left(t\right) = \prod_{t_i&amp;lt;t}{\left(1-\frac{d_i}{n_i}\right)}$$&lt;/p&gt;
&lt;p&gt;Where $t_i$ are all the event times smaller than $t$ (from the data itself); $n_i$ is the number of people &amp;ldquo;at risk&amp;rdquo; between $t_{i-1}$ and $t_i$ (which means they survived all the events up to and including $t_{i-1}$); and $d_i$ is the number of observed deaths at time $t_i$ (deaths at the interval $\left(t_{i-1},t_i\right]$).&lt;/p&gt;
&lt;p&gt;This formula has a pretty intuitive explanation - surviving up to time $t$ means surviving all the events before $t$;
For each such event, in which $d_i$ out of $n_i$ subjects died, the estimated survival probability is $1-\frac{d_i}{n_i}$, so surviving &lt;em&gt;all of them&lt;/em&gt; is the product of all these numbers.&lt;/p&gt;
&lt;p&gt;Instead of implementing KM estimator ourselves, we&amp;rsquo;ll use the wonderful &lt;a href=&#34;https://lifelines.readthedocs.io/en/latest/index.html&#34;&gt;lifelines&lt;/a&gt; library, which is the most comprehensive python package for survival analysis I know of (R has a much better survival analysis ecosystem). Implementation is easy, but if you&amp;rsquo;re interested in survival analysis, you should check out &lt;code&gt;lifelines&lt;/code&gt;; it has a wonderful API, great docs and a wide range of models, helper functions, plotting and summary statistics.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll fit two KM estimators - one for black cats and one for non-black cats, so we can compare the non-parametric to our parametric survival functions:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; lifelines &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; KaplanMeierFitter
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;))
ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;111&lt;/span&gt;)

kmf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; KaplanMeierFitter()
kmf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(df[df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;black&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days_to_event, event_observed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;df[df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;black&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;adopted,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;black cats&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
kmf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
kmf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(df[df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;black&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;days_to_event, event_observed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;df[df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;black&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;adopted,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;non black cats&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
kmf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ax,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;orange&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; lam_nb, lam_b &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(lambda_non_black[:&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;], lambda_black[:&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;]):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(t, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;t&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;lam_nb),c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;orange&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)    
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(t, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;t&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;lam_b),c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)    
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Proportion remaining&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Days&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend(fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlim(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_58_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;What are we seeing here?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &amp;ldquo;smooth&amp;rdquo; black and orange curves are exponential survival curves with the sampled parameters.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;staircase&amp;rdquo; curves (aka piecewise constant functions) are the non parametric KM estimates. For details about their confidence intervals, see &lt;a href=&#34;https://www.math.wustl.edu/%7Esawyer/handouts/greenwood.pdf&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, how good is our assumed parametric form? That, of course, depends on how much you care about capturing all the small details; It seems to capture the overall trend, but, for example, it doesn&amp;rsquo;t quite capture the &amp;ldquo;sigmoidal&amp;rdquo;-like behavior around days 0-10, and it overestimates the survival probability between days 60-100 for both groups. This is somewhat expected - we&amp;rsquo;d be surprised if a single-parameter model would be able to capture all the details we see in the non-parametric curve.&lt;/p&gt;
&lt;h1 id=&#34;summing-up&#34;&gt;Summing up&lt;/h1&gt;
&lt;p&gt;This post was pretty introductory - its main goal was to explain what censorship is (I think this is a super important concept to understand if you&amp;rsquo;re doing any kind of data analysis), and to implement a likelihood function that can handle censored observations. In the next post we&amp;rsquo;ll dive a little deeper into survival regression, still from a bayesian modeling persepctive.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;One possible source of confusion here is the terminology; you will find the expressions &amp;ldquo;censored observations&amp;rdquo;, &amp;ldquo;censored times&amp;rdquo;, &amp;ldquo;events whose time were censored&amp;rdquo;, etc. used pretty interchangeably. Unless stated otherwise, all of these usually refer to same thing. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Technically, these are called &amp;ldquo;right censored&amp;rdquo; diapers; if you think of time as going from left to right like it&amp;rsquo;s usually plotted, than the right &amp;ldquo;tail&amp;rdquo; of the plots for these diapers is censored from us. There are also other kinds of censoring, but we&amp;rsquo;ll ignore them in this post. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Varying Slopes Models and the CholeskyLKJ distribution in TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/varying-slopes/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/varying-slopes/</guid>
      <description>&lt;h4 id=&#34;tldr&#34;&gt;TL;DR&lt;/h4&gt;
&lt;p&gt;Covariance matrices allow us to capture parameter correlations in multivariate hierarchical models; sampling these using Hamiltonian Monte Carlo in Tensorflow Probability can be tricky and confusing; this post is about some of the math involved and how to get this right.&lt;/p&gt;
&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;p&gt;Hierarchical models allow us to account for variations between different groups in our data. Let&amp;rsquo;s say that, for some reason, we have &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34;&gt;different groups of tadpoles&lt;/a&gt; in different tanks and we want to model per-tank survival rates. Varying intercepts models allow us to fit different models to different tanks, while pooling together information &lt;em&gt;between&lt;/em&gt; tanks. The tanks are somewhat different (they&amp;rsquo;re not the same tank), so we allow their parameters to vary; but they&amp;rsquo;re also similar (they&amp;rsquo;re all tanks with tadpoles, not oranges or ships), so we can do some &amp;ldquo;transfer learning&amp;rdquo; between tanks.&lt;/p&gt;
&lt;p&gt;Varying &lt;em&gt;intercepts&lt;/em&gt; are already very powerful models. However, in many (most?) situations, the models we fit have more than just an intercept. Let&amp;rsquo;s say we have 3 groups in our data, and we want to fit a simple linear model for each group, but also to share information between groups. Each model has two parameters (a slope and an intercept), and we allow these to &lt;em&gt;vary&lt;/em&gt;. We can also allow them to &lt;em&gt;covary&lt;/em&gt;. For example, if higher slopes usually go with lower intercepts, we want to know that, and use that to improve our estimation of both.&lt;/p&gt;
&lt;p&gt;To capture this covariance amongst parameters, we&amp;rsquo;re going to need a covariance matrix.&lt;/p&gt;
&lt;h1 id=&#34;the-lkj-prior&#34;&gt;The LKJ prior&lt;/h1&gt;
&lt;p&gt;Every 2x2 covariance matrix can be decomposed as a product of a diagonal matrix of standard deviations $\sigma_\alpha,\sigma_\beta$ with a correlation matrix $\Sigma$, in the following form (same holds for higher dimensions):&lt;/p&gt;
&lt;p&gt;$$\mathbb{S} = \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right) \cdot \Sigma \cdot \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right)$$&lt;/p&gt;
&lt;p&gt;The decomposition is conceptually useful - it&amp;rsquo;s usually easier to think about the variances (which are single-parameter properties, and depend on things like unit of measurement and typical scale) separately from the correlation structure (a pairwise property). Technically, putting a prior on the variances isn&amp;rsquo;t very hard - we just need to make sure the variables are non-negative.&lt;/p&gt;
&lt;p&gt;A priori, it&amp;rsquo;s not obvious how to put a prior on correlation matrices. We can&amp;rsquo;t sample each matrix element by itself; correlation matrices have to be postitive definite, so their elements are somewhat &amp;ldquo;entangled&amp;rdquo; - the value in the $\left[i,j\right]$-th entry effects the element in the $\left[k,l\right]$-th entry. Luckily for us, in 2009, Lewandowski, Kurowicka, and Joe &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0047259X09000876&#34;&gt;published&lt;/a&gt; a method for generating random correlation matrices, aptly referred to as the LKJ distribution. Like other probablistic programming languages, TFP implements the LKJ distribution. It&amp;rsquo;s a distribution that gets two numbers as inputs - $N$, the dimension of the correlation matrix, and $\eta$, a concentration parameter that controls how plausible are large correlations; Larger $\eta$ mean correlations are more concentrated around zero &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# the necessary imports&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfp
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt 
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; matplotlib.patches &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Ellipse
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; distributions &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; bijectors &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tfb
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;enable_eager_execution()

&lt;span style=&#34;color:#75715e&#34;&gt;# for plotting&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_palette(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;muted&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# for reproducibility&lt;/span&gt;
np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;324&lt;/span&gt;)
tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_random_seed(&lt;span style=&#34;color:#ae81ff&#34;&gt;234&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here&amp;rsquo;s how samples from different LKJ distributions look like. We sample 500 correltion matrices with $\eta=1$ and 500 matrices with $\eta=50$:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten(), bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linspace(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;), density&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eta=1$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten(), bins&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linspace(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99&lt;/span&gt;), density&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;eta=50$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Correlation values&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;500 5x5 correlation matrices&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;problem-1---falling-off-the-manifold&#34;&gt;Problem #1 - falling off the manifold&lt;/h2&gt;
&lt;p&gt;So far so good - sampling correlation matrices seems straightforward. The problem starts when we want to use a Hamiltonian Monte Carlo (and we usually want to use Hamiltonian Monte Carlo) to sample from some larger model that contains an LKJ distribution. HMC allows us to generate samples from arbitrary joint distributions, not only from distributions for which we have explicit sampling methods. Here&amp;rsquo;s a toy example to illustrate the problem. The model is simply a single LKJ distribution within a &lt;code&gt;JointDistributionSequential&lt;/code&gt; object:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;),
    ]
)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&amp;lt;tf.Tensor: id=7897612, shape=(2, 2), dtype=float32, numpy=
 array([[ 1.        , -0.43337458],
        [-0.43337458,  1.        ]], dtype=float32)&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;model.sample()&lt;/code&gt; seems to work, so that&amp;rsquo;s encouraging. However, when we try to &amp;ldquo;naively&amp;rdquo; use an HMC sampler to generate samples from the model, things go wrong. We add a small helper function to avoid rewriting all the kernels everytime; see the &lt;a href=&#34;https://adamhaber.github.io/2019/07/08/A-Tutorial-on-Varying-Intercepts-Models-with-TensorFlow-Probability.html&#34;&gt;previous post&lt;/a&gt; for explanations about the different function calls here.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sampleHMC&lt;/span&gt;(log_prob, inits, bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None):
    inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HamiltonianMonteCarlo(
        target_log_prob_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;log_prob,
        step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;,
        num_leapfrog_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
    )
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
        inner_kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TransformedTransitionKernel(inner_kernel, bijectors_list)
        
    adaptive_kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SimpleStepSizeAdaptation(
        inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inner_kernel,
        num_adaptation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;
    )
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_chain(
        num_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
        current_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inits,
        kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;adaptive_kernel,
        num_burnin_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
        trace_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;lkj_samps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(
    log_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; lkj: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([lkj]),
    inits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample()
)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
lkj_samps[:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;# we print the first 3 samples &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=8349304, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 28.062887,  81.77511 ],
        [-80.5103  , -68.75983 ]],

       [[ 65.458626,  72.01995 ],
        [-87.03769 , -59.71089 ]],

       [[104.11292 ,  85.66264 ],
        [-83.73789 , -60.2727  ]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we can already see the problem; these aren&amp;rsquo;t correlation matrices by any means. What&amp;rsquo;s happening here is that HMC, which operates in an unconstrained space of real numbers, &amp;ldquo;falls off&amp;rdquo; the correlation matrices manifold. The solution for this is what&amp;rsquo;s called a &lt;strong&gt;bijector&lt;/strong&gt;. Without getting into the gory mathematical details &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, a bijector can be thought of as a differentiable one-to-one mapping between the unconstrained space in which the HMC trajectories live, and the constrained manifold. HMC produces samples in the unconstrained space, and the appropriate bijector spits out a valid correlation matrix. For us, this bijector is &lt;code&gt;tfb.CorrelationCholesky()&lt;/code&gt;. Note that we need to pass a list of bijectors to the &lt;code&gt;TransformedTransitionKernel&lt;/code&gt; constructor; in this case, we&amp;rsquo;re passing just a single bijector:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;bij_lkj_samps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(
    log_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; lkj: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([lkj]),
    inits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(),
    bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CorrelationCholesky()]
)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
bij_lkj_samps[:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=9873388, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 1.        ,  0.        ],
        [-0.43139905,  0.90216124]],

       [[ 1.        ,  0.        ],
        [-0.43139905,  0.90216124]],

       [[ 1.        ,  0.        ],
        [-0.43139905,  0.90216124]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At first glance, these don&amp;rsquo;t look like correlation matrices either; that&amp;rsquo;s because they&amp;rsquo;re the &lt;em&gt;Cholesky factors&lt;/em&gt; of kosher correlation matrices.&lt;/p&gt;
&lt;h2 id=&#34;overthinking-box---cholesky-factors-3&#34;&gt;Overthinking box - Cholesky factors &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;p&gt;Every correlation matrix $\Sigma$ can be decomposed as a product of a lower triangular matrix $L$ and its transpose $L^T$. More formally, a lower triangular matrix $L$ is the Cholesky factor of some correlation matrix $\Sigma$ if and only if its diagonal elements are strictly positive and each of its rows has unit norm.&lt;/p&gt;
&lt;p&gt;Cholesky factors come up in many different places in statistics, machine learning, metric learning, computational linear algebra, etc. In the context of Monte Carlo simulations, Cholesky factors are used to generate correlated quantities (which we often want) from uncorrelated samples (which are easy to generate in the computer): If $z$ is a matrix of uncorrelated normally distributed numbers, and $L$ is the Cholesky factor of some correlation matrix $\Sigma$, then $Lz$ would have the correlation structure described by $\Sigma$.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a simple demonstration. We generate 1000 samples from a bivariate guassian with zero mean, unit variance and no correlation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MultivariateNormalDiag(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], scale_diag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We now define a correlation matrix between two variables with correlation -0.85. We compute its Cholesky factor, multiply it with the original (uncorrelated) data, and voila:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;M &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;constant([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;],[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
L &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cholesky(M)
Lz &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; L&lt;span style=&#34;color:#a6e22e&#34;&gt;@z&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(z[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], z[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$z$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(Lz[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], Lz[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$Lz$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;upper right&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can see that the two components of $Lz$ are negatively correlated, as expected. More quantitatively, here&amp;rsquo;s the correlation matrix for the cholesky-tranformed data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;correlation(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(Lz))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=9873636, shape=(2, 2), dtype=float32, numpy=
array([[ 0.9999995 , -0.8532509 ],
       [-0.8532509 ,  0.99999976]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;problem-2---the-wrong-log_prob&#34;&gt;Problem #2 - the wrong log_prob&lt;/h2&gt;
&lt;p&gt;So the bijector solves the constrained-unconstrained problem, and HMC can run smoothly. But things are trickier than that (and the sampler won&amp;rsquo;t tell you that). The HMC sampler works with the log probability function of the model. If we have an LKJ distribution somewhere in our model, than for every sample, HMC computes the &lt;code&gt;log_prob&lt;/code&gt; of the correlation matrix according to LKJ. But LKJ is a distribution over correlation matrices, not Cholesky factors of correlation matrices, which is the output of our bijector! So we end up computing the wrong &lt;code&gt;log_prob&lt;/code&gt;, which means we&amp;rsquo;re not sampling from the model we think we&amp;rsquo;re sampling. So what can we do?&lt;/p&gt;
&lt;p&gt;Solution number 1 is to make sure our cholesky-factors-of-correlation-matrices become correlation matrices before we compute their &lt;code&gt;log_prob&lt;/code&gt; according to LKJ. To do so, we need two more bijectors: &lt;code&gt;tfb.CholeskyOuterProduct&lt;/code&gt;, which maps $L$ to $LL^T$, and &lt;code&gt;tfb.Chain&lt;/code&gt; which, surprisingly, chains (composes) the two bijectors:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;chained_bij_samps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(
    &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; lkj: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([lkj]), 
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(), 
    bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Chain([tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CholeskyOuterProduct(), tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CorrelationCholesky()])]
)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
chained_bij_samps[:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=12661134, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 1.        , -0.21354356],
        [-0.21354356,  1.        ]],

       [[ 1.        , -0.21354356],
        [-0.21354356,  1.        ]],

       [[ 1.        ,  0.01905983],
        [ 0.01905983,  1.0000001 ]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This looks good. And this time it actually is - this is doing what we think it&amp;rsquo;s doing. But this is cumbersome, and not very readable. Even worse, when we&amp;rsquo;ll pass these correlations matrices to a multivariate gaussian (the usual case), it&amp;rsquo;ll compute their cholesky factors anyway (check out the &lt;a href=&#34;https://github.com/tensorflow/probability/blob/4dd589ba945db902d28dbb75dc0a795706814d45/tensorflow_probability/python/distributions/mvn_full_covariance.py#L189&#34;&gt;source code&lt;/a&gt;, as well as the depracation warning above it). So we end up sampling cholesky factors, tranforming them back to correlation matrices just to compute their cholesky factors again&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;enter-choleskylkj&#34;&gt;Enter CholeskyLKJ&lt;/h2&gt;
&lt;p&gt;Since &lt;code&gt;tfp-nightly-0.9.0.dev20190830&lt;/code&gt; (a daily-built version that contains the newest changes that have yet to made it into the latest stable release), we have a better option - the &lt;code&gt;CholeskyLKJ&lt;/code&gt; distribution. Unlike LKJ, this is a distribution over &lt;em&gt;cholesky factors&lt;/em&gt; of correlation matrices - so no need to go back and forth, or to chain bijectors&amp;hellip; It&amp;rsquo;s faster, numerically stabler, and it is by the &lt;a href=&#34;https://mc-stan.org/docs/2_19/functions-reference/cholesky-lkj-correlation-distribution.html&#34;&gt;book&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To use it, we just need a single &lt;code&gt;tfb.CorrelationCholesky()&lt;/code&gt; bijector:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CholeskyLKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;),
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;cholesky_lkj_samps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(
    &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; lkj: model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([lkj]),
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(),
    bijectors_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CorrelationCholesky()]
)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
cholesky_lkj_samps[:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=14269238, shape=(3, 2, 2), dtype=float32, numpy=
array([[[ 1.        ,  0.        ],
        [ 0.20048861,  0.97969604]],

       [[ 1.        ,  0.        ],
        [-0.19122852,  0.9815455 ]],

       [[ 1.        ,  0.        ],
        [ 0.18798688,  0.9821716 ]]], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;a-simple-use-case&#34;&gt;A simple use case&lt;/h1&gt;
&lt;p&gt;We&amp;rsquo;ve covered the technicalities of sampling correlation matrices (and their Cholesky factors) with TFP. To get a more complete picture of how these are actually used, let&amp;rsquo;s see an example. We&amp;rsquo;re sticking with McElreath and Statistical Rethinking; this time we&amp;rsquo;re reproducing the caf waiting times example.&lt;/p&gt;
&lt;h2 id=&#34;fake-data&#34;&gt;Fake data&lt;/h2&gt;
&lt;p&gt;Unlike the tadpoles example, this time we&amp;rsquo;re going to model fake data (aka synthetic data). This may sound strange, but it&amp;rsquo;s actually a &lt;em&gt;very&lt;/em&gt; useful skill, and it&amp;rsquo;s considered by many to be pretty much the first step in a Bayesian data analysis workflow (see &lt;a href=&#34;https://khakieconomics.github.io/2017/04/30/An-easy-way-to-simulate-fake-data-in-stan.html&#34;&gt;here&lt;/a&gt;). The reason is that unlike in a &amp;ldquo;real data analysis&amp;rdquo;, when you&amp;rsquo;re generating fake data, you &lt;em&gt;know&lt;/em&gt; the true underlying data generating process; making sure you can recover its parameters is a very important sanity check. It also helps in verifying the model is correctly specified and that the MCMC sampler does what you think it does, which is good.&lt;/p&gt;
&lt;p&gt;The data we&amp;rsquo;re generating describes the waiting times in 20 different cafs. Each caf has a different average waiting times in the morning and in the afternoon. The average morning waiting time is the intercept, and the difference between afternoon and morning average waiting times is the slope. The intercepts and slopes for each of the 20 cafs are sampled from a (surprise surprise) correlated bivariate Gaussian distribution.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;##### Inputs needed to generate the covariance matrix between intercepts and slopes #####&lt;/span&gt;


a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3.5&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# average morning wait time&lt;/span&gt;
b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# average difference afternoon wait time&lt;/span&gt;
sigma_a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# standard deviation in the (caf-specific) intercepts&lt;/span&gt;
sigma_b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# standard deviation in the (caf-specific) slopes&lt;/span&gt;
rho &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# correlation between intercepts and slopes&lt;/span&gt;

mu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [a,b] &lt;span style=&#34;color:#75715e&#34;&gt;# the mean of our gaussian distribution&lt;/span&gt;
sigmas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [sigma_a,sigma_b] &lt;span style=&#34;color:#75715e&#34;&gt;# vector of standard deviations&lt;/span&gt;
corr_matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,rho], [rho,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]]) &lt;span style=&#34;color:#75715e&#34;&gt;# correlation matrix&lt;/span&gt;
cov_matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;diag(sigmas)&lt;span style=&#34;color:#a6e22e&#34;&gt;@corr_matrix&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@np.diag&lt;/span&gt;(sigmas)  &lt;span style=&#34;color:#75715e&#34;&gt;# the covariance matrix of our gaussian distribution &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After setting the true parameters, we&amp;rsquo;re generating 20 samples of cafs:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_cafs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 20 cafs overall&lt;/span&gt;

caf_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multivariate_normal(mu ,cov_matrix,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_cafs) 
caf_intercept &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; caf_params[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#75715e&#34;&gt;# intercepts are in the first column&lt;/span&gt;
caf_slopes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; caf_params[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#75715e&#34;&gt;# slopes are in the second&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And compute the actual per-caf morning and afternoon waiting times, in 10 different visits. Below is a sample of 10 rows from our dataframe (which has 200 data points overall - 10 visits in 20 cafs):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_visits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 10 visits per caf&lt;/span&gt;

afternoon &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tile([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], n_visits &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; n_cafs&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# alternate values for mornings and afternoons in the data frame&lt;/span&gt;
caf_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(n_cafs),n_visits) &lt;span style=&#34;color:#75715e&#34;&gt;# data for each caf are consecutive rows in the data frame&lt;/span&gt;

mu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; caf_intercept[caf_id] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; caf_slopes[caf_id] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; afternoon &lt;span style=&#34;color:#75715e&#34;&gt;# the regression equation for the mean waiting time&lt;/span&gt;
sigma &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# standard deviation of waiting time within cafs&lt;/span&gt;
wait &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(mu, sigma, n_visits &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; n_cafs) &lt;span style=&#34;color:#75715e&#34;&gt;# generate instances of waiting times&lt;/span&gt;
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(dict(caf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; caf_id, afternoon &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; afternoon, wait &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wait))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_string(index&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt; caf  afternoon      wait
    8          1  2.175858
    9          0  2.364313
    9          1  1.744504
   14          0  3.716937
    3          1  1.419163
    0          1  1.959044
    5          0  1.045913
    4          0  1.083699
   17          1  2.796278
   15          1  3.430852
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;the-model&#34;&gt;The model&lt;/h2&gt;
&lt;p&gt;We specify in math (and latex) the model described above:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
W_i &amp;amp; \sim \text{Normal}(\alpha_{caf[i]}+\beta_{caf[i]}\cdot \text{AFTERNOON}_i,\sigma) \\\&lt;br&gt;
\binom{\alpha_{caf}}{\beta_{caf}} &amp;amp; \sim \text{MVNormal}\left(\binom{\alpha}{\beta},\mathbb{S}\right) \\\&lt;br&gt;
\mathbb{S} &amp;amp; = \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right) \cdot LL^T \cdot \left(\begin{smallmatrix} \sigma_\alpha &amp;amp; 0 \\\ 0 &amp;amp; \sigma_\beta \end{smallmatrix}\right)  \\\&lt;br&gt;
\alpha &amp;amp; \sim \text{Normal}(5,2) \\\&lt;br&gt;
\beta &amp;amp; \sim \text{Normal}(-1,0.5) \\\&lt;br&gt;
\sigma_{\alpha},\sigma_{\beta} &amp;amp; \sim \text{Exp}(1) \\\&lt;br&gt;
\sigma &amp;amp; \sim \text{Exp}(1) \\\&lt;br&gt;
L &amp;amp; \sim \text{CholeskyLKJ}(2,2) \\\&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CholeskyLKJ(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;),  &lt;span style=&#34;color:#75715e&#34;&gt;# rho, the prior for the correlation matrix between intercepts and slopes&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exponential(rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),sample_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#75715e&#34;&gt;# sigma, prior std for the waiting time&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exponential(rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),sample_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), &lt;span style=&#34;color:#75715e&#34;&gt;# sigma_caf, prior of stds for intercepts and slopes (vector of 2)&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(loc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;), sample_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),   &lt;span style=&#34;color:#75715e&#34;&gt;# b, the prior mean for the slopes&lt;/span&gt;
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(loc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), sample_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),   &lt;span style=&#34;color:#75715e&#34;&gt;# a, the prior mean for the intercepts&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; a,b,sigma_caf,sigma,chol_rho : tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample( &lt;span style=&#34;color:#75715e&#34;&gt;# per-caf intercepts and slopes&lt;/span&gt;
            tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MultivariateNormalTriL(
                loc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([a,b],axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
                scale_tril &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LinearOperatorDiag(sigma_caf)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(chol_rho)
            ),
            sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_cafs
        ),
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; mvn, a, b, sigma_caf, sigma : tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(  &lt;span style=&#34;color:#75715e&#34;&gt;#per-caf waiting times&lt;/span&gt;
            tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(
                loc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(mvn[:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],caf_id,axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gather(mvn[:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],caf_id,axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;afternoon,
                scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sigma
            ),
            reinterpreted_batch_ndims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        )
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Couple of non-trivial things in the model above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MultivariateNormalTriL&lt;/code&gt;: we&amp;rsquo;ve mentioned that a covariance matrix can be specified as $\Lambda L L^T\Lambda$ where $\Lambda$ is a diagonal matrix of standard deviations and $L$ is the cholesky factor of the correlation matrix. &lt;code&gt;MultivariateNormalTriL&lt;/code&gt; is a parametrization of a multivariate normal distribution whose covariance matrix is specificied using the lower triangular matrix $\Lambda L$.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LinearOperatorDiag&lt;/code&gt;: this turns a &lt;code&gt;sigma-caf&lt;/code&gt; vector of length 2 to a 2x2 diagonal matrix; very similar to &lt;code&gt;tf.diag&lt;/code&gt;, but handles all the batching semantics for us.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tf.gather&lt;/code&gt;: this takes each intercept (in the case of &lt;code&gt;mvn[:,:,0]&lt;/code&gt;) and slope (in the case of &lt;code&gt;mvn[:,:,1]&lt;/code&gt; and tiles it 10 times, so overall we get a loc vector of size 200, with which we generate 200 different waiting times, 10 per caf.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We now declare the &lt;code&gt;target_log_prob&lt;/code&gt; function for the HMC kernel, and initial values for 4 different chains. Like before, we throw away the last sample (predicted waiting times); we want to plug the waiting times from the data into the likelihood, instead.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
log_prob_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; rho, sigma, sigma_caf, b, a, mvn : model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([rho, sigma, sigma_caf, b, a, mvn ,wait])
init_rho, init_sigma, init_sigma_caf, init_b, init_a, init_mvn, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These initial values are used to specify the shape of the initial values we actually pass, specified below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;init_rho &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stack([tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n_chains)])
init_sigma &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones_like(init_sigma)
init_sigma_caf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones_like(init_sigma_caf)
init_b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(init_b)
init_a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(init_a)
init_mvn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(init_mvn)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We define the list of bijectors. Note that since standard deviations are non-negative, their support is constrained, and we need a bijector here, as well. The appropriate bijector in this case is &lt;code&gt;tfb.Exp&lt;/code&gt;. Once we specificed a bijectors list, we need to match a bijector for any distribution in our &lt;code&gt;JointDistributionSequential&lt;/code&gt; object; since the support of &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt; and &lt;code&gt;mvn&lt;/code&gt; is unconstrained, we simply use an identity transformation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;bijectors_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CorrelationCholesky(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exp(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
    tfb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Identity(),
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;states &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sampleHMC(log_prob_fn,
                [init_rho, init_sigma, init_sigma_caf, init_b, init_a, init_mvn],
                bijectors_list)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;[s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; s &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; states]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[TensorShape([Dimension(500), Dimension(4), Dimension(2), Dimension(2)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(1)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(2)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(1)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(1)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(20), Dimension(2)])]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Shapes look alright. To see the posterior distribution of covariance values, we move back from Cholesky factors to correlation matrices, and multiply by the inferred sigmas (the zeroth axis is the number of samples, first is the number of the chain, so we transpose the second and third axes):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;rhos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; states[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#a6e22e&#34;&gt;@tf.transpose&lt;/span&gt;(states[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Same as above, we create diagonal matrices from our sampled &lt;code&gt;sigma_alpha&lt;/code&gt;, &lt;code&gt;sigma_beta&lt;/code&gt; values:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;sigmas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; states[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
diag_sigmas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LinearOperatorDiag(sigmas)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inferred_covs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(diag_sigmas&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(rhos),diag_sigmas)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (row_idx,col_idx), title &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip([(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;),(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)],[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma_{&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;alpha}$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Covariance&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;sigma_{&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;beta}$&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;]):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;131&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;row_idx&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;col_idx)
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(inferred_covs[:,:,row_idx,col_idx]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten(), label &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Posterior&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(cov_matrix[row_idx,col_idx],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;True value&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(title)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can also compare empirical waiting times with sampled waiting times:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;morning_wait_emp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;afternoon == 0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;caf&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;wait&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
afternoon_wait_emp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;afternoon == 1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;caf&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;wait&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;morning_wait_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(states[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:,:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
afternoon_wait_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(states[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][:,:,:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; morning_wait_pred
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And we get the shrinkage that decorates Statistical Rethinking&amp;rsquo;s front cover:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))
ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;111&lt;/span&gt;)
vals, vecs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eigh(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cov(morning_wait_emp, afternoon_wait_emp))
theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;degrees(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arctan2(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;vecs[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]))
w, h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(vals)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; contour_line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;):
    ell &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Ellipse(xy&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(morning_wait_emp), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(afternoon_wait_emp)),
                  width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;w&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;contour_line, height&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;h&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;contour_line,
                  angle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;theta, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;black&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
    ell&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_facecolor(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;none&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
    ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_artist(ell)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(morning_wait_emp,afternoon_wait_emp,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Empirical&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(morning_wait_pred,afternoon_wait_pred, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;MCMC&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(morning_wait_emp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(),afternoon_wait_emp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(),marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,s&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Grand Mean&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; a,b,c,d &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(morning_wait_emp, afternoon_wait_emp,  morning_wait_pred, afternoon_wait_pred):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arrow(a,b,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(c&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;a),&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(d&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;b), head_width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;, alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Morning wait&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Afternoon wait&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;4.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Formally, the distribution is defined as: $\text{LKJ}\left(\Sigma\vert\eta\right)\propto\det\left(\Sigma\right)^{\left(\eta-1\right)}$. Intuitively, the correlation matrix defines an ellipsoid in $N$ dimensions, and its determinant is the volume of the ellipsoid. So, higher correlations -&amp;gt; tighter ellipsoid -&amp;gt; smaller volume -&amp;gt; smaller determinant -&amp;gt; more likely for small $\eta$ and less likely for large $\eta$. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Sigrid Keydana did an excellent job explaining TFP bijectors, and specifcally the intuition behind the jacobian correction, in &lt;a href=&#34;https://blogs.rstudio.com/tensorflow/posts/2019-04-05-bijectors-flows/&#34;&gt;this&lt;/a&gt; post. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Overthinking boxes are specific (usually mathematical) dive-ins in Statistical Rethinking. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>A Tutorial on Varying Intercepts Models with TensorFlow Probability</title>
      <link>https://adamhaber.github.io/post/varying-intercepts/</link>
      <pubDate>Mon, 08 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://adamhaber.github.io/post/varying-intercepts/</guid>
      <description>&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;p&gt;This post is about building varying intercepts models using TensorFlow Probability (&amp;ldquo;TFP&amp;rdquo;). It&amp;rsquo;s basically my attempt to translate Sigrid Keydana&amp;rsquo;s wonderful &lt;a href=&#34;https://blogs.rstudio.com/tensorflow/posts/2019-05-06-tadpoles-on-tensorflow/&#34;&gt;blog post&lt;/a&gt; from R to Python. I&amp;rsquo;m doing this for a couple of reasons: First, I&amp;rsquo;ve played with TFP before, was quite impressed by its performance and flexibility, and wanted to learn more about it; Second, I wanted to start blogging, and this seemed like an easy start; Last, TFP is rather new, and there aren&amp;rsquo;t a whole lot of resources and tutorials about it - so this might even prove useful to someone, someday.&lt;/p&gt;
&lt;p&gt;Sigrid dedicated her post to &lt;a href=&#34;https://twitter.com/rlmcelreath&#34;&gt;Richard McElreath&lt;/a&gt; and his book; I&amp;rsquo;d like to join her on that. I was looking for a good introduction to Bayesian stats for quite some time. BDA3 was too technical for me at that point, Kruschke&amp;rsquo;s was excellent but didn&amp;rsquo;t really dive into the more sophisticated topics I wanted to learn. Statistical Rethinking was spot on - interesting, fun to read, and super helpful. It&amp;rsquo;s very code-oriented, and has already been re-written in pure stan, brms, pymc3, julia and probably many others.&lt;/p&gt;
&lt;p&gt;Stats-wise, this post is going to be about varying intercepts models, which are perhaps the simplest kind of a multilevel model. The main idea behind them - called partial pooling - is simple and beautiful, but here I want to focus on the code, not the stats; for a nice introductory demo, check out &lt;a href=&#34;http://mfviz.com/hierarchical-models/&#34;&gt;this&lt;/a&gt; beautiful visualization, or &lt;a href=&#34;http://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/&#34;&gt;this&lt;/a&gt; one. Better yet, get a copy of Statistical Rethinking and read the original. :-)&lt;/p&gt;
&lt;h1 id=&#34;the-data&#34;&gt;The data&lt;/h1&gt;
&lt;p&gt;We&amp;rsquo;re given data about 48 different tanks containing tadpoles (pre-frogs). Each tank has a &lt;code&gt;density&lt;/code&gt; (the initial number of tadpoles in it), a categorical feature &lt;code&gt;pred&lt;/code&gt; (whether the tank contained a predator or not), a categorical feature &lt;code&gt;size&lt;/code&gt; (big tank or small tank), the number of surviving tadpoles &lt;code&gt;surv&lt;/code&gt; and the proportion of surviving tadpoles &lt;code&gt;propsurv&lt;/code&gt; (which is simply &lt;code&gt;surv&lt;/code&gt;/&lt;code&gt;density&lt;/code&gt;). The original data came with the book&amp;rsquo;s R package; Luckily, it&amp;rsquo;s hosted in Osvaldo Martin&amp;rsquo;s &lt;a href=&#34;https://github.com/aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3&#34;&gt;repo&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;https://raw.githubusercontent.com/aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3/master/Data/reedfrogs.csv&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;Tank&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;density&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;pred&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;size&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;surv&lt;/th&gt;
&lt;th&gt;propsurv&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td&gt;0.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;big&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;no&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Tank densities are either 10, 25 or 35.&lt;/p&gt;
&lt;h1 id=&#34;the-model&#34;&gt;The model&lt;/h1&gt;
&lt;p&gt;Our goal is to compute the probability of survival in each of the tanks. &lt;code&gt;propsurv&lt;/code&gt; is one way to do this, which is straightforward and intuitive - simply compute the per-tank ratio of surviving tadpoles. But this doesn&amp;rsquo;t make much sense, especially if you consider the small sample sizes - if I&amp;rsquo;d give you a tank with &lt;code&gt;density=1&lt;/code&gt;, would you feel comfortable with saying that the probability of survival is either 0% (&lt;code&gt;surv=0&lt;/code&gt;) or 100% (&lt;code&gt;surv=1&lt;/code&gt;)? Probably not.&lt;/p&gt;
&lt;p&gt;A different approach would be to ignore between-tanks variations, and assume all tanks have exactly the same probability of survival. Our best estimate is then the ratio of all the surviving tadpoles (in all tanks, combined) - or &lt;code&gt;sum(surv)/sum(density)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A varying intercept model is somewhat in between - it assumes each tank has its own probability of survival, but that all these probabilities are coming from some distribution over &amp;ldquo;probabilities of survival&amp;rdquo;. This is how it looks like:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\bar{\alpha} &amp;amp; \sim \text{Normal}(0,1.5) \\\&lt;br&gt;
\sigma &amp;amp; \sim \text{Exponential}(1) \\\&lt;br&gt;
\text{logit}\left(p_i\right) &amp;amp; \sim \text{Normal}\left(\bar{\alpha},\sigma\right) \\\&lt;br&gt;
s_i &amp;amp; \sim \text{Binomial}(n_i,p_i) \\\&lt;br&gt;
\end{align}
$$&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s all this? In short - we assume the logits of the survival probabilities are sampled from some normal distribution, whose parameters (often called &amp;ldquo;hyperparameters&amp;rdquo;) we&amp;rsquo;re trying to infer. &lt;code&gt;a_bar&lt;/code&gt; is the mean of this normal distribution, and we put a generic weakly informative prior on it - normal(0,1.5). &lt;code&gt;sigma&lt;/code&gt; is the standard deviation of this normal distribution, and we put an exponential prior on it. After sampling these two numbers, we plug them into the logits distribution, sample 48 different logit values, transform them to probabilities and sample 48 survival predictions from the binomial distributions (one per tank).  Now to the code itself. We begin with the necessary imports:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow_probability &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tfp
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt 
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
tfd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distributions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For ease-of-use, we&amp;rsquo;re using TensorFlow in Eager mode, which allows a more interactive and iterative workflow.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;v1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;enable_eager_execution()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;some-tfps-pre-requisites&#34;&gt;Some TFP&amp;rsquo;s pre-requisites&lt;/h2&gt;
&lt;p&gt;Before we start implementing the model itself, we need to cover some of the basic terminology around a &lt;code&gt;TensorFlow Distribution&lt;/code&gt;. For the purposes of this introductory post, you can think of a distribution as an object with the following two methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sample()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;log_prob()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both are pretty straightforward - &lt;code&gt;sample()&lt;/code&gt; allows you to generate samples from a given distribution; &lt;code&gt;log_prob()&lt;/code&gt; allows you to calculate the log-probability of a given value(s). There are other methods, of course, but these are the important ones for us.
There are two more attributes we need to mention:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;event_shape&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch_shape&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These were, at least for me, quite confusing (despite their pretty good &lt;a href=&#34;https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Distributions_Tutorial.ipynb&#34;&gt;docs&lt;/a&gt;). &lt;code&gt;event_shape&lt;/code&gt; is the simpler of the two - if I have some joint probability distribution over N random variables, its &lt;code&gt;event_shape&lt;/code&gt; is N. For example, a bivariate gaussian would have an event shape of 2.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;batch_shape&lt;/code&gt; is trickier: TFP allows you to create a single Distribution object, which actually contains multiple, independent distributions. For example, &lt;code&gt;tfd.Bernoulli(probs=[.3, .5, .7])&lt;/code&gt; is a Distribution object composed of 3 different Bernoulli random variables (RVs) with probabilities of success .3, .5 and .7. The number of the independent distributions contained in this single object is its &lt;code&gt;batch_shape&lt;/code&gt;. Why do this? My best guess is that it gives TFP the ability to make use of the underlying TF infrastructure, in which batching (and broadcasting along a batch dimension) is a fundamental operation. We&amp;rsquo;ll get back to this in the code below.&lt;/p&gt;
&lt;p&gt;Now we&amp;rsquo;ll go ahead and define the model itself using TFP&amp;rsquo;s &lt;code&gt;JointDistributionSequential&lt;/code&gt; API:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JointDistributionSequential(
    [
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, scale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;),
        tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Exponential(rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;),
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; sigma, a_bar: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sample(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normal(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;a_bar, scale&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sigma),sample_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]),
        &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; l: tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Independent(tfd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Binomial(total_count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;density&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;float32&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;), logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;l),
                                  reinterpreted_batch_ndims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    ]
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The main workhorse here is &lt;code&gt;tfd.JointDistributionSequential&lt;/code&gt;, which is very similar to &lt;code&gt;Sequential&lt;/code&gt; in Keras or PyTorch. It&amp;rsquo;s an object composed of list of Distribution-making functions (&lt;code&gt;tfd.Distribution&lt;/code&gt;s or Python callables that return a &lt;code&gt;tfd.Distribution&lt;/code&gt;). The idea of sequentially stacking distributions, and adding the dependencies between them (the fact that the values sampled from &lt;code&gt;tfd.Normal&lt;/code&gt; and &lt;code&gt;tfd.Exponential&lt;/code&gt; are &amp;lsquo;fed&amp;rsquo; into the 3rd distribution as its mean and standard deviation) is simple and intuitive, and fits nicely in the hierarchical modeling workflow; the code above is basically a 1-to-1 translation of the model specification.&lt;/p&gt;
&lt;p&gt;The tricky parts here are TFP&amp;rsquo;s &lt;code&gt;Sample&lt;/code&gt; and &lt;code&gt;Independent&lt;/code&gt;. What are these, then?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Sample&lt;/code&gt; - The third function receives the hyper-parameters &lt;code&gt;sigma&lt;/code&gt; and &lt;code&gt;a_bar&lt;/code&gt;, and should return one number per tank, drawn from a &lt;code&gt;normal(a_bar,sigma)&lt;/code&gt;. &lt;code&gt;tfd.Sample&lt;/code&gt; allows us to draw samples from the product distribution of all these 48 Gaussians; each sample from &lt;code&gt;Sample&lt;/code&gt; is a vector of 48 (uncorrelated) numbers, all with the same mean &lt;code&gt;a_bar&lt;/code&gt; and standard deviation &lt;code&gt;sigma&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Independent&lt;/code&gt; - the third distribution returns a vector of 48 numbers. If we simply write &lt;code&gt;tfd.Binomial(total_count=df.density.astype(&#39;float32&#39;), logits=l)&lt;/code&gt;, we&amp;rsquo;ll get a distribution with a &lt;code&gt;batch_shape&lt;/code&gt; of 48 and an &lt;code&gt;event_shape&lt;/code&gt; (), representing a scalar output. Wrapping this with &lt;code&gt;tfd.Independent&lt;/code&gt; transforms this output to be of &lt;code&gt;batch_shape&lt;/code&gt; () and &lt;code&gt;event_shape&lt;/code&gt; 48, representing a vector output, like we want it to be.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another possibly-confusing issue here is the order of the parameters in the lambda expressions. The first parameter is the output of the previous distribution in the list, the second parameter is the output of the previous-previous distribution, etc&amp;hellip; This is why they third distribution gets &lt;code&gt;sigma&lt;/code&gt; before &lt;code&gt;a_bar&lt;/code&gt; despite the fact &lt;code&gt;sigma&lt;/code&gt; is defined &lt;em&gt;after&lt;/em&gt; &lt;code&gt;a_bar&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I found this API somewhat different than the &amp;ldquo;natural&amp;rdquo; way to think about the problem; however, if this ends up with  superior performance, it&amp;rsquo;s probably worth the learning curve for a wide enough range of problems.&lt;/p&gt;
&lt;h1 id=&#34;sampling-from-a-model&#34;&gt;Sampling from a model&lt;/h1&gt;
&lt;p&gt;The model&amp;rsquo;s &lt;code&gt;sample()&lt;/code&gt; method gets a &lt;code&gt;sample_shape&lt;/code&gt; argument which determines the shape of the generated sample. This, in turn, will be used to tell the MCMC sampler how many chains to run in parallel.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n_chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;

initial_a, initial_s, initial_logits, init_surv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; m&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample(n_chains)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Since we&amp;rsquo;ve asked for 4 chains, &lt;code&gt;m.sample()&lt;/code&gt; returns 4 samples from the &lt;code&gt;a_bar&lt;/code&gt; hyperprior and 4 samples from the &lt;code&gt;sigma&lt;/code&gt; hyperprior; these, in turn, generate 4 new normal distributions, from which we sample 4x48 logit values. These values are then &amp;ldquo;pushed forward&amp;rdquo;, generating 4x48 samples from the binomial survival distributions. These survival predictions can (and probably should) be used to perform prior predictive checks, but we don&amp;rsquo;t need them to define the sampler, itself.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;initial_a&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, initial_s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, initial_logits&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, init_surv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(TensorShape([Dimension(4)]),
 TensorShape([Dimension(4)]),
 TensorShape([Dimension(4), Dimension(48)]),
 TensorShape([Dimension(4), Dimension(48)]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we create the sampler object. This step is composed of 3 different TFP objects. The first is the Hamiltonian Monte Carlo transition kernel, which uses the model&amp;rsquo;s &lt;code&gt;.log_prob()&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HamiltonianMonteCarlo(
    target_log_prob_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x,y,z : m&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log_prob([x,y,z,df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;surv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;float32&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)]),
    step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;,
    num_leapfrog_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that we&amp;rsquo;re not using the model&amp;rsquo;s &lt;code&gt;.log_prob()&lt;/code&gt; &lt;em&gt;as is&lt;/em&gt;; instead, we make sure that the log-probability is always computed with respect to the actual, observed survival data. This is the purpose of the &lt;code&gt;lambda&lt;/code&gt; function above. For the other two required parameters, I&amp;rsquo;m using the ones from Sigrid&amp;rsquo;s post.&lt;/p&gt;
&lt;p&gt;The second part is the &lt;code&gt;SimpleStepSizeAdaptation&lt;/code&gt; object, which takes the kernel defined above and returns a new kernel with dynamic step size adaptation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;kernel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SimpleStepSizeAdaptation(
    inner_kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inner_kernel,
    target_accept_prob &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;,
    num_adaptation_steps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Lastly, the sampling function. This object takes as input the initial states (and through them, number of chains to run), number of burnin steps, number of steps to run after burnin, a kernel (our augmented HMC kernel), and a trace function, which determines what kind of intermediate results we want to save. After sampling ends (this can take a while, depending on the complexity of your model), the function returns the samples (and traced results). Here I&amp;rsquo;ve decided not to save intermediate results, at all; the simple diagnostics I&amp;rsquo;m interested in can be computed from the samples themselves.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;a_bars, sigmas, logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample_chain(
    current_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[
        tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(initial_a), 
        tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones_like(initial_s),
        initial_logits
    ],
    num_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
    num_burnin_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,
    kernel&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kernel,
    trace_fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s have a look at the output shapes:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;a_bars&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, sigmas&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape, logits&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;(TensorShape([Dimension(500), Dimension(4)]),
 TensorShape([Dimension(500), Dimension(4)]),
 TensorShape([Dimension(500), Dimension(4), Dimension(48)]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sampler returned 500 samples per chain per parameter - exactly what we want.&lt;/p&gt;
&lt;p&gt;TFP provides standard MCMC diagnostics, such as effective sample size per logit parameter (we average over chains):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_mean(tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;effective_sample_size(logits),axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=1643926, shape=(48,), dtype=float32, numpy=
array([ 39.01448 ,  27.656044,  64.033554,  23.641933,  38.67304 ,
        43.81818 ,  27.42485 ,  56.60047 ,  86.46597 ,  53.400955,
        62.463234,  68.98154 ,  71.84833 ,  85.98772 ,  53.90014 ,
        45.368874,  57.142807,  64.70456 ,  80.501144,  30.96955 ,
        51.123882,  90.971016,  83.67827 , 133.95776 , 147.53087 ,
       237.56706 , 124.73306 , 213.96054 , 255.63586 , 127.86496 ,
       169.16728 , 222.58665 ,  57.26799 ,  62.313004,  59.934887,
       140.44281 , 126.62906 ,  44.229973,  80.57881 , 100.344055,
       102.71631 , 307.0775  , 298.0421  , 298.77765 , 275.2672  ,
       241.8357  , 134.39154 , 334.7177  ], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And R-hat values:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;tfp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mcmc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;potential_scale_reduction(logits)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: id=1643986, shape=(48,), dtype=float32, numpy=
array([1.0393666, 1.0419586, 1.014595 , 1.0326122, 1.0066991, 1.0365033,
       1.1032237, 1.0193528, 1.0026469, 1.03286  , 1.0212902, 1.0046616,
       1.0046593, 1.0190336, 1.0491707, 1.0185002, 1.0236404, 1.0240865,
       1.0135043, 1.0091226, 1.0240618, 1.0212263, 1.0040884, 1.0057993,
       1.0115193, 1.0074626, 1.0053723, 1.0013644, 1.0038955, 1.0128344,
       1.0199273, 1.0040274, 1.1276014, 1.0033313, 1.0127679, 1.0017091,
       1.0118763, 1.0570774, 1.04308  , 1.0189458, 1.0144566, 1.0009695,
       1.0063009, 1.0008804, 1.0011569, 1.0057343, 1.0079254, 1.0071955],
      dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can easily inspect the traceplots of the hyperparameters (each color stands for a different chain):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;121&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(a_bars&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(),alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;122&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(sigmas&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(),alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_34_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We get nicely mixed chains, which is good. We can also plot the posterior distributions of the logits for the different tanks:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]):
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n_chains):
        sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kdeplot(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(logits[:,j,i]))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_36_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here, each subplot corresponds to one tank, and different colors represent different chains. Just by eye-balling the posteriors, we can see a lot of variability between tanks; this is obvious when we compute posterior survival probabilities themselves:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;ps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sigmoid(logits)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()

plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]):
    current_ps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ps[:,:,i]
    pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;errorbar(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[i],y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[current_ps&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()],
                     yerr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([current_ps&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;quantile(current_ps,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;),
                                    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;quantile(current_ps,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.75&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;current_ps&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
                     fmt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;o&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
    act &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(i,df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;propsurv&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Tank number&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Survival probability&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axhline(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;surv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;density&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(),lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; density_change &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;density&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;diff())[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:]:
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(density_change,ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend([pred,act],[&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;50&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; Prediction Interval&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;propsurv&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_38_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The black dots are the posterior mean probabilities, the errorbars represent the interquartile range, the red dots are &lt;code&gt;propsurv&lt;/code&gt; (the no-pooling estimate), and the blue horizontal line is the grand mean (the complete-pooling estimate). Vertical lines split the tanks to densities 10, 25 and 35. We can see that, as expected, posterior probabilities are shrunk towards the grand mean. We can also plot the difference between the posterior means and &lt;code&gt;propsurv&lt;/code&gt;, to observe that shrinkage is indeed larger when the sample size is smaller:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]):
    current_ps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ps[:,:,i]
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(i,(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[i,&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;propsurv&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;current_ps&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()),c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axhline(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; density_change &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;density&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;diff())[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:]:
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axvline(density_change,ls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;--&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;k&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;,lw&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Tank number&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Shrinkage&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;,fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;output_40_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h1&gt;
&lt;p&gt;TFP certainly has a different feel to it compared to other probabilistic programming frameworks like PyMC3 or Stan; specifically, the introduction of batching semantics, and the complexity of the API that is exposed, are very different and pose a real learning curve. The slope, I guess, depends on one&amp;rsquo;s background.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
